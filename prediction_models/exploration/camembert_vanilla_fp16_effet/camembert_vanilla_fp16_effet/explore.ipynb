{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass, field\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-30-3c6ca677768e>, line 20)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-3c6ca677768e>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    if sort:\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Example:\n",
    "    text: str\n",
    "    label: int\n",
    "\n",
    "\n",
    "\n",
    "def load_train_data(path: str, sort: bool) -> List[Example]:\n",
    "    sentences = list()\n",
    "    with open(path) as f:\n",
    "        first = False\n",
    "        for line in f:\n",
    "            if not first:\n",
    "                first = True\n",
    "                continue\n",
    "            text1, text2, label = line.rstrip().split(\"|\")\n",
    "            concat_text = text1+'. '+text2\n",
    "            lab = len(concat_text)\n",
    "            sentences.append((lab, Example(text=concat_text, label=float(label))))\n",
    "    if sort:\n",
    "        sentences.sort(key=lambda x: x[0])\n",
    "\n",
    "    return [e for (_, e) in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "examples = load_train_data('data/train_test/train.csv', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Example(text='sonde attain performa. le guide est resté coincé à lintérieur de la sonde, on ne peut plus le bouger. changement de sonde', label='2851.0')"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(74019, 24)\nmax GRAVITE    SEVER\ndtype: object\nmin GRAVITE    CRITI\ndtype: object\nSEVER    19978\nMOYEN    10466\nMINEU     4894\nCRITI     1138\nNULLE      340\nName: GRAVITE, dtype: int64\nSEVER    0.549149\nMOYEN    0.283299\nMINEU    0.126585\nCRITI    0.029587\nNULLE    0.011380\nName: GRAVITE, dtype: float64\n                                             produit  ... GRAVITE\n0                              sonde attain performa  ...   MOYEN\n1              tensoban bande de protection adhesive  ...   MOYEN\n2                        sphincterotome dreamtome rx  ...   NULLE\n5          pince kocher dans la trousse accouchement  ...   MOYEN\n9  tubulure pack avec enfit pour pompe flocare in...  ...   MINEU\n\n[5 rows x 3 columns]\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import re\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Constructed with analysis of embedding coverage\n",
    "misspell_dict = {\"cest\":\"c'est\",\n",
    "                \"desaturation\": \"désaturation\",\n",
    "                \"controlaterale\":\"controlatérale\",\n",
    "                '\\x9cdème':\"oedème\",\n",
    "                '\\x9cdèmes':\"oedèmes\",\n",
    "                'léchographie': \"échographie\",\n",
    "                \"desaturation\":\"désaturation\",\n",
    "                '\\x9cil':\"oeil\",\n",
    "                \"limplant\":\"implant\",\n",
    "                \"hemorragiques\":\"hémorragiques\",\n",
    "                \"hypoglycemie\":\"hypoglycémie\",\n",
    "                \"lautomate\" : 'automate',\n",
    "                'l\\x9cil' : 'oeil',\n",
    "                'adenopathie':'adénopathie',\n",
    "                'prothetique':'prothétique',\n",
    "                'inapproprie': \"inapproprié\",\n",
    "                'lartère':'artère',\n",
    "                'asthenie':'asthénie',\n",
    "                'man\\x9cuvre': 'manoeuvre',\n",
    "                'lexplantation': 'explantation',\n",
    "                'lymphoree':'lymphorée',\n",
    "                'salpyngectomie':'salpingectomie',\n",
    "                'burnaout':'burnout',\n",
    "                'lnterventlon': 'intervention',\n",
    "                'pericardique': 'péricardique',\n",
    "                'lendométriose':'endométriose',\n",
    "                'daudition': 'audition',\n",
    "                'désaltére': 'désaltéré',\n",
    "                'cephalee':'céphalée',\n",
    "                'salpaginctomie': 'salpingectomie',\n",
    "                'menauposée':'ménopausée',\n",
    "                'deczéma':'eczéma',\n",
    "                'peritonite': 'péritonite',\n",
    "                'lablation':'ablation',\n",
    "                'microjyste': 'microkyste',\n",
    "                'généralié': 'généralité',\n",
    "                'débriété': 'ébriété',\n",
    "                'acidocetose': 'acidocétose',\n",
    "                'dhéparine':'héparine',\n",
    "                'dincident':'incident',\n",
    "                'daiguille':'aiguille',\n",
    "                'materiovigilance':'matériovigilance',\n",
    "                'adenomyose': 'adénomyose'\n",
    "                    }\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text: str) -> str:\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_dict.keys()))\n",
    "\n",
    "    def replace(match):\n",
    "        return misspell_dict[match.group(0)]\n",
    "\n",
    "    return misspell_re.sub(replace, text)\n",
    "\n",
    "\n",
    "puncts = ['\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']',\n",
    "          '>', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£', '·', '_', '{', '}', '©',\n",
    "          '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█',\n",
    "          '½', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶',\n",
    "          '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼',\n",
    "          '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', '¯', '♦', '¤', '▲',\n",
    "          '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪',\n",
    "          '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
    "\n",
    "bad_char = ['\\x85']\n",
    "\n",
    "carriage = [r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\", \"\\r\\r\\n\"]\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "\n",
    "    text = str(text)\n",
    "    text = text.replace('\\x9c', 'oe')\n",
    "    text = text.replace('\\x92', \"'\")\n",
    "    for carr in carriage:\n",
    "        if carr in text:\n",
    "            text = text.replace(carr, ' ')\n",
    "    for bc in bad_char:\n",
    "        if bc in text:\n",
    "            text = text.replace(bc, '')\n",
    "    for punct in puncts:\n",
    "         if punct in text:\n",
    "            text = text.replace(punct, '')\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_numbers(text: str) -> str:\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = clean_text(text)\n",
    "        text = clean_numbers(text)\n",
    "        text = replace_typical_misspell(text)\n",
    "        text = text.strip()\n",
    "        text = re.sub(' +', ' ', text)\n",
    "\n",
    "    else:\n",
    "        text = \"\"\n",
    "    return text\n",
    "\n",
    "# Create train and test\n",
    "\n",
    "\n",
    "X_cols = ['NUMERO_DECLARATION','LIBELLE_COMMERCIAL','DESCRIPTION_INCIDENT', 'ETAT_PATIENT', 'FABRICANT', 'DISTRIBUTEUR']\n",
    "y_col = ['GRAVITE']\n",
    "\n",
    "df = pd.read_csv('data/declaration_mrv.csv', sep=\";\", encoding='latin1')\n",
    "\n",
    "\n",
    "# Drop all nan values in the target\n",
    "\n",
    "df = df.dropna(subset=y_col)\n",
    "print(df.shape)\n",
    "\n",
    "# Fill na values in text fiels with vide\n",
    "\n",
    "df['DESCRIPTION_INCIDENT'] = df['DESCRIPTION_INCIDENT'].fillna(\"\")\n",
    "df['ETAT_PATIENT'] = df['TYPE_EFFET'].fillna(\"\")\n",
    "df['LIBELLE_COMMERCIAL'] = df['LIBELLE_COMMERCIAL'].fillna(\"\")\n",
    "df['FABRICANT'] = df['FABRICANT'].fillna(\"\")\n",
    "df['DISTRIBUTEUR'] = df['DISTRIBUTEUR'].fillna(\"\")\n",
    "\n",
    "\n",
    "df_subset['produit'] = df_subset['LIBELLE_COMMERCIAL'] \n",
    "df_subset['incident'] = df_subset['DESCRIPTION_INCIDENT']+' '+df_subset['ETAT_PATIENT']\n",
    "\n",
    "df_subset = df_subset.drop_duplicates(subset='incident')\n",
    "\n",
    "# Encode label\n",
    "le = LabelEncoder()\n",
    "\n",
    "#df_subset[y_col] = le.fit_transform(df_subset[y_col].values)\n",
    "\n",
    "\n",
    "print(\"max\",df_subset[y_col].max())\n",
    "print(\"min\",df_subset[y_col].min())\n",
    "\n",
    "\n",
    "train_index, test_index = next(GroupShuffleSplit(random_state=1029).split(df_subset, groups=df_subset['NUMERO_DECLARATION']))\n",
    "\n",
    "train = df_subset.iloc[train_index]\n",
    "test = df_subset.iloc[test_index]\n",
    "\n",
    "print(train['GRAVITE'].value_counts(normalize=False))\n",
    "print(test['GRAVITE'].value_counts(normalize=True))\n",
    "# Clean\n",
    "text_columns = ['produit', 'incident']\n",
    "train.loc[:, text_columns] = train.loc[:, text_columns].applymap(preprocess_text)\n",
    "test.loc[:, text_columns] = test.loc[:, text_columns].applymap(preprocess_text)\n",
    "\n",
    "train = train[['produit', 'incident', 'GRAVITE']]\n",
    "test = test[['produit', 'incident', 'GRAVITE']]\n",
    "\n",
    "print(train.head())\n",
    "train.to_csv('data/train_test/train_gravite.csv', index=False, sep='|')\n",
    "test.to_csv('data/train_test/test_gravite.csv', index=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(36816, 3)\n"
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0028735632183908046"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "1. / 348"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectname",
   "language": "python",
   "name": "projectname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}