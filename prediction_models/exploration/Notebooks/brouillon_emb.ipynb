{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction d'un embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import FastText, KeyedVectors\n",
    "import numpy as np\n",
    "import gensim\n",
    "import sys\n",
    "import clean_text\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(data = {'pipeline 1' : [0,0,0],'pipeline 2' : [0,0,0],'pipeline 3' : [0,0,0]},index=['accuracy','ballanced accuracy','f1-weighted']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>ballanced accuracy</th>\n",
       "      <th>f1-weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pipeline 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pipeline 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pipeline 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accuracy  ballanced accuracy  f1-weighted\n",
       "pipeline 1         0                   0            0\n",
       "pipeline 2         0                   0            0\n",
       "pipeline 3         0                   0            0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "lang ='french'\n",
    "\n",
    "import clean_text\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import TruncatedSVD,IncrementalPCA,SparsePCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import spacy\n",
    "nlp =spacy.load('fr')\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/DGS-env/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "df_declaration_mrv = pd.read_csv(\"data/data_mrv/declaration_mrv.csv\",delimiter=';',encoding='ISO-8859-1')\n",
    "id_to_dco = pd.read_csv(\"data/ref_MRV/referentiel_dispositif.csv\",delimiter=';',encoding='ISO-8859-1')\n",
    "\n",
    "df = df_declaration_mrv[['DESCRIPTION_INCIDENT','LIBELLE_COMMERCIAL','DCO_ID']]\n",
    "\n",
    "\n",
    "df['Text'] = df['LIBELLE_COMMERCIAL']+ ' ' + df['DESCRIPTION_INCIDENT']\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.83 s, sys: 72 ms, total: 9.9 s\n",
      "Wall time: 9.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.Text = df.Text.map(lambda x: clean_text.preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCES = df.Text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 24s, sys: 27.2 s, total: 13min 51s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dco = FastText(sentences=SENTENCES,size=300,window=5,negative=10,sg=0,min_n=5,max_n=4,workers=32) \n",
    "model_dco.save('emb_Text.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class  ReshapeVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.model = model\n",
    "        self.dim = 768\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.model[w] for w in words if w in self.model]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_raw_by_nb_obs(df:pd.DataFrame, seuil:int)->pd.DataFrame :\n",
    "    \"\"\"\n",
    "    Renvoie les lignes ou le nombre d'observations est supérieur au seuil entrée\n",
    "    \"\"\"\n",
    "    S = df.groupby('DCO_ID').count()>seuil\n",
    "    liste_DCO =S[S['Text']==True].index\n",
    "    df_utilisable= df[df['DCO_ID'].isin(liste_DCO)]\n",
    "    #df_reduit = df_utilisale[df_utilisale['DCO_ID']>2900]\n",
    "    #print(len(df_reduit))\n",
    "    return(df_utilisable)\n",
    "\n",
    "df_10 = select_raw_by_nb_obs(df,10)\n",
    "df_10_unique = df_10.drop_duplicates('DESCRIPTION_INCIDENT') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/DGS-env/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/user1/DGS-env/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/user1/DGS-env/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/user1/DGS-env/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/user1/DGS-env/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "précison: 0.22256449749711205\n",
      "Balanced_accuracy :  0.15640627051102393\n",
      "CPU times: user 1h 15s, sys: 15.4 s, total: 1h 30s\n",
      "Wall time: 1h 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/DGS-env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"embeddings\", FasttextVectorTransformer(model_dco)),\n",
    "        (\"classifier\", LinearSVC(class_weight='balanced')),\n",
    "    ]\n",
    ")\n",
    "X_train_u, X_test_u, y_train_u, y_test_u = train_test_split(df_10_unique['LIBELLE_COMMERCIAL'],df_10_unique.DCO_ID,test_size=0.25)\n",
    "embeddings_pipeline.fit(X_train_u, y_train_u)\n",
    "y_pred_u = embeddings_pipeline.predict(X_test_u)\n",
    "\n",
    "print(\"précison:\", accuracy_score(y_test_u,y_pred_u) )\n",
    "print(\"Balanced_accuracy : \", balanced_accuracy_score(y_test_u,y_pred_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGS-env",
   "language": "python",
   "name": "dgs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
