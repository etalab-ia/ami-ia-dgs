{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "lang ='french'\n",
    "\n",
    "import clean_text\n",
    "import skmultilearn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score,f1_score,classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import TruncatedSVD,IncrementalPCA,SparsePCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import spacy\n",
    "nlp =spacy.load('fr')\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annalyse des signalement de la DGS grace aux techniques de l'inteligence artificielle\n",
    "\n",
    "## Description\n",
    "\n",
    "### Le projet\n",
    "Le projet se déroule sur 8 mois d'Avril à Novembre 2020 et il se compose de 4 livrables distincts : \n",
    "- Livrable 1 : SOCLE TECHNIQUE D’INGESTION DES DONNEES\n",
    "- Livrable 2 : ALGORITHMES DE CLASSIFICATION DES SIGNALEMENTS\n",
    "- Livrable 3 : ALGORITHME DE REGROUPEMENT DES SIGNALEMENTS\n",
    "- Livrable 4 : INTERFACE DE TRAITEMENTS DES SIGNALEMENTS\n",
    "\n",
    "Une description plus complète de chacun des livrables se trouve dans la réponse à l'appel d'offre.\n",
    "\n",
    "### Organisation du GitLab\n",
    "Ce répetroire git est organisé en 3 branches différentes : \n",
    "- **Exploration :** \n",
    "Cette branche est essentiellement composée de notebook retraçant les différentes pistes que nous avons suivies pour arriver à la solution finale. Cette branche permet de rendre compte de la démarche suivie et ainsi de justifier de la qualité scientifique du livrable.  A travers ces notebooks d'exploration, nous pourrons également envisager les directions futures pour améliorer les performances\n",
    "\n",
    "- **Demonstrateur :**\n",
    "Cette branche contient un démonstrateur permettant de visualiser les résultats des modèles. Cette branche est un livrable intermédiaire qui nous permet de dialoguer avec les personnes de la DGS et ainsi de co-construire les livrables 2, 3 et 4 en mettant en évidence les besoins de la DGS.\n",
    "\n",
    "- **Develop ,** Cette branche contient les livrables dans différents dossiers : \n",
    "    - __extractor__: le script qui permet d'ingérer les données PDF (Livrable 1)\n",
    "    - __inference__: Le script et les modèles d'inférence de la DCO, de la TYPOLOGIE et de la GRAVITÉ pour une base de fichier PDF ou XML (Livrable 2)\n",
    "    - __regroupement__ : Les algorithmes et les modèles pour le regroupement des signalements (Livrable 3)\n",
    "    - __application__  : Le code source pour l'interface de traitement (Livrable 4)\n",
    "\n",
    "## Pour Commencer(a faire)\n",
    "\n",
    "\n",
    "\n",
    "## Authors\n",
    "\n",
    "* **Robin Quillivic**  \n",
    "* **Louise Remot**  \n",
    "* **Boris Sanchot**  \n",
    "\n",
    "## License\n",
    "\n",
    "Ce projet est privé.\n",
    "This project is completely private.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrv = pd.read_csv('data/data_mrv/declaration_mrv_complet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'NUMERO_DECLARATION', 'TYPE_DECLARATION',\n",
       "       'TYPE_DECLARANT', 'NB_PATIENT_CONCERNE', 'NB_DISPOSITIF_CONCERNE',\n",
       "       'DESCRIPTION_INCIDENT', 'ETAT_PATIENT', 'ACTION_PATIENT', 'DCO_ID',\n",
       "       'DCO', 'LIBELLE_COMMERCIAL', 'REFERENCE_COMMERCIALE', 'NUMERO_SERIE',\n",
       "       'NUMERO_LOT', 'FABRICANT', 'MANDATAIRE', 'DISTRIBUTEUR', 'TDY_ID',\n",
       "       'TYPE_DYSFONCTIONNEMENT', 'CDY_ID', 'CONSEQUENCE_DYSFONCTIONNEMENT',\n",
       "       'TEF_ID', 'TYPE_EFFET', 'GRAVITE', 'NUMERO', 'TYPE_VIGILANCE',\n",
       "       'CLASSIFICATION'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62277"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mrv[mrv.MANDATAIRE.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26324, 14) (6580, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import clean_text\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "directory = './data_split/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Chargement des données\n",
    "mrv = pd.read_csv('data/data_mrv/declaration_mrv_complet.csv',\n",
    "                 usecols=['NUMERO_DECLARATION',\"DESCRIPTION_INCIDENT\",\"ETAT_PATIENT\",\"FABRICANT\", \"CLASSIFICATION\", 'ACTION_PATIENT',\n",
    "                          'DCO_ID','LIBELLE_COMMERCIAL','REFERENCE_COMMERCIALE','TEF_ID',\n",
    "                          'TDY_ID','CDY_ID','GRAVITE'])\n",
    "\n",
    "# 1) On gère nana pour les collones contenant du text\n",
    "text_columns =  [\"DESCRIPTION_INCIDENT\",\"ETAT_PATIENT\",\"FABRICANT\", 'ACTION_PATIENT','LIBELLE_COMMERCIAL']\n",
    "\n",
    "\n",
    "mrv[text_columns] = mrv[text_columns].fillna('NON RENSEIGNE')\n",
    "\n",
    "# 2) on gère les NaN pour chaque Collones\n",
    "mrv['NUMERO_DECLARATION'] = mrv['NUMERO_DECLARATION'].fillna('NON RENSEIGNE')\n",
    "mrv['DESCRIPTION_INCIDENT'] = mrv['DESCRIPTION_INCIDENT'].fillna('NON RENSEIGNE')\n",
    "mrv['ETAT_PATIENT'] = mrv['ETAT_PATIENT'].fillna('NON RENSEIGNE')              \n",
    "mrv['CLASSIFICATION'] = mrv['CLASSIFICATION'].fillna('NON RENSEIGNE')\n",
    "mrv['FABRICANT'] = mrv['FABRICANT'].fillna('NON RENSEIGNE')\n",
    "mrv['LIBELLE_COMMERCIAL'] = mrv['LIBELLE_COMMERCIAL'].fillna('NON RENSEIGNE')\n",
    "mrv['REFERENCE_COMMERCIALE'] = mrv['REFERENCE_COMMERCIALE'].fillna('NON RENSEIGNE')\n",
    "\n",
    "\n",
    "\n",
    "#Effet\n",
    "mrv['TEF_ID']= mrv['TEF_ID'].fillna('E1213')\n",
    "#DYSFOCNTIONNEMENT\n",
    "mrv['TDY_ID']  = mrv['TDY_ID'].fillna(\"D0\")\n",
    "#CONSEQUENCES\n",
    "mrv['CDY_ID']  = mrv['CDY_ID'].fillna(\"C0\")\n",
    "\n",
    "#Construction de nouvelles variables\n",
    "\n",
    "mrv[\"text\"] = mrv['DESCRIPTION_INCIDENT']+' '+mrv['ETAT_PATIENT']\n",
    "\n",
    "\n",
    "# Encodage des variables catégorielles et sauvegarde des données associé\n",
    "\n",
    "le = LabelEncoder()\n",
    "mrv[\"CLASSIFICATION\"] = le.fit_transform(mrv[\"CLASSIFICATION\"])\n",
    "joblib.dump(le, './data_split/classification_encodeur.sav')\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "mrv[\"CDY_ID\"] = le.fit_transform(mrv[\"CDY_ID\"])\n",
    "joblib.dump(le, './data_split/CDY_ID_encodeur.sav')\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "mrv[\"TEF_ID\"] = le.fit_transform(mrv[\"TEF_ID\"])\n",
    "joblib.dump(le, './data_split/TEF_ID_encodeur.sav')\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "mrv[\"TDY_ID\"] = le.fit_transform(mrv[\"TDY_ID\"])\n",
    "joblib.dump(le, './data_split/TDY_ID_encodeur.sav')\n",
    "\n",
    "\n",
    "\n",
    "# La typologie est en génrale multilabel\n",
    "\n",
    "mrv_id = mrv.groupby('text').agg({'TEF_ID':lambda x: list(set(x)),\n",
    "                               'CDY_ID':lambda x: list(set(x)),\n",
    "                               'TDY_ID':lambda x:list(set(x))\n",
    "                            })\n",
    "\n",
    "#On fusionne les multilabels et on supprime les doublons\n",
    "mrv = mrv.drop(['TEF_ID','CDY_ID','TDY_ID'],axis=1)\n",
    "mrv = pd.merge(mrv,mrv_id, on = 'text')\n",
    "mrv = mrv.drop_duplicates('text')\n",
    "mrv = mrv.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#On remplace les strings vide\n",
    "mrv.replace('', 'NON RENSEIGNE', inplace=True)\n",
    "# Sauvegarde des données nettoyées\n",
    "mrv.to_pickle('./data_split/all_data.pkl')\n",
    "\n",
    "\n",
    "# Split data\n",
    "\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1029)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "for train_index, test_index in msss.split(mrv['text'], mlb.fit_transform(mrv['TEF_ID'])):\n",
    "    train, test = mrv.loc[train_index],  mrv.loc[test_index]\n",
    "\n",
    "train.to_pickle('./data_split/train.pkl')\n",
    "test.to_pickle('./data_split/test.pkl')\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrv_id[['TEF_ID','CDY_ID','TDY_ID']]=mrv_id[['TEF_ID','CDY_ID','TDY_ID']].apply(lambda x :np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32731, 273)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "a = mlb.fit_transform(mrv_id['TEF_ID'])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DESCRIPTION_INCIDENT        0\n",
       "ETAT_PATIENT                0\n",
       "ACTION_PATIENT              0\n",
       "DCO_ID                      6\n",
       "LIBELLE_COMMERCIAL          0\n",
       "REFERENCE_COMMERCIALE       0\n",
       "FABRICANT                   0\n",
       "GRAVITE                  1290\n",
       "CLASSIFICATION              0\n",
       "text                        0\n",
       "TEF_ID                      0\n",
       "CDY_ID                      0\n",
       "TDY_ID                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrv.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mrv[mrv['ETAT_PATIENT']==''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DESCRIPTION_INCIDENT        0\n",
       "ETAT_PATIENT                0\n",
       "ACTION_PATIENT              0\n",
       "DCO_ID                      6\n",
       "LIBELLE_COMMERCIAL          0\n",
       "REFERENCE_COMMERCIALE       0\n",
       "FABRICANT                   0\n",
       "GRAVITE                  1290\n",
       "CLASSIFICATION              0\n",
       "text                        0\n",
       "TEF_ID                      0\n",
       "CDY_ID                      0\n",
       "TDY_ID                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrv.to_pickle('test.pkl')\n",
    "data = pd.read_pickle('test.pkl')\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESCRIPTION_INCIDENT</th>\n",
       "      <th>ETAT_PATIENT</th>\n",
       "      <th>ACTION_PATIENT</th>\n",
       "      <th>DCO_ID</th>\n",
       "      <th>LIBELLE_COMMERCIAL</th>\n",
       "      <th>REFERENCE_COMMERCIALE</th>\n",
       "      <th>FABRICANT</th>\n",
       "      <th>TYPE_DYSFONCTIONNEMENT</th>\n",
       "      <th>CONSEQUENCE_DYSFONCTIONNEMENT</th>\n",
       "      <th>TYPE_EFFET</th>\n",
       "      <th>GRAVITE</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>text</th>\n",
       "      <th>TEF_ID</th>\n",
       "      <th>CDY_ID</th>\n",
       "      <th>TDY_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparition de nombreux boutons</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3268.0</td>\n",
       "      <td>tensoban - bande de protection adhesive</td>\n",
       "      <td>..</td>\n",
       "      <td>bsn medical</td>\n",
       "      <td>NON RENSEIGNE</td>\n",
       "      <td>PAS DE CONSEQUENCE</td>\n",
       "      <td>REACTION ALLERGIQUE</td>\n",
       "      <td>MOYEN</td>\n",
       "      <td>1</td>\n",
       "      <td>apparition de nombreux boutons</td>\n",
       "      <td>[123]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>le sphinctérotome , à la sortie de son emballa...</td>\n",
       "      <td>. .</td>\n",
       "      <td></td>\n",
       "      <td>2497.0</td>\n",
       "      <td>sphincterotome dreamtome rx</td>\n",
       "      <td>M00584050</td>\n",
       "      <td>boston scientific</td>\n",
       "      <td>NON EFFICACITE DM</td>\n",
       "      <td>PAS DE CONSEQUENCE</td>\n",
       "      <td>PAS D'EFFET NEFASTE DECLARE</td>\n",
       "      <td>NULLE</td>\n",
       "      <td>1</td>\n",
       "      <td>le sphinctérotome , à la sortie de son emballa...</td>\n",
       "      <td>[106]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mandrin bloqué dans la sonde et impossibilité ...</td>\n",
       "      <td>. .</td>\n",
       "      <td>matériel à dispo au sce économat .</td>\n",
       "      <td>2851.0</td>\n",
       "      <td>quartet</td>\n",
       "      <td>1456Q86</td>\n",
       "      <td>abbott medical france sas</td>\n",
       "      <td>IMPOSSIBILITE / DIFFICULTE DE POSE / MISE EN P...</td>\n",
       "      <td>PAS DE CONSEQUENCE</td>\n",
       "      <td>PAS D'EFFET NEFASTE DECLARE</td>\n",
       "      <td>MOYEN</td>\n",
       "      <td>1</td>\n",
       "      <td>mandrin bloqué dans la sonde et impossibilité ...</td>\n",
       "      <td>[106]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[286]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la pince kocher présente dans la trousse a été...</td>\n",
       "      <td>perte sanguine du bébé , la pince ne réalisant...</td>\n",
       "      <td>un clamp ombilical a été mis en urgence .</td>\n",
       "      <td>4841.0</td>\n",
       "      <td>pince kocher dans la trousse accouchement</td>\n",
       "      <td>0007255334</td>\n",
       "      <td>vygon</td>\n",
       "      <td>PROBLEME OUVERTURE / FERMETURE DE LA PINCE</td>\n",
       "      <td>PAS DE CONSEQUENCE</td>\n",
       "      <td>PERTE DE SANG</td>\n",
       "      <td>MOYEN</td>\n",
       "      <td>1</td>\n",
       "      <td>la pince kocher présente dans la trousse a été...</td>\n",
       "      <td>[113]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[521]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lors de ouverture un pack cataracte ( personna...</td>\n",
       "      <td>pas de conséquences car non utilisation du dm .</td>\n",
       "      <td>changements de couteaux .</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>couteau standart ° droit st</td>\n",
       "      <td>..</td>\n",
       "      <td>bausch &amp; lomb france</td>\n",
       "      <td>DM INCOMPLET / DETERIORE AVANT UTILISATION</td>\n",
       "      <td>PAS DE CONSEQUENCE</td>\n",
       "      <td>PAS D'EFFET NEFASTE DECLARE</td>\n",
       "      <td>MINEU</td>\n",
       "      <td>1</td>\n",
       "      <td>lors de ouverture un pack cataracte ( personna...</td>\n",
       "      <td>[106]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[395, 206]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                DESCRIPTION_INCIDENT  \\\n",
       "1                     apparition de nombreux boutons   \n",
       "2  le sphinctérotome , à la sortie de son emballa...   \n",
       "3  mandrin bloqué dans la sonde et impossibilité ...   \n",
       "4  la pince kocher présente dans la trousse a été...   \n",
       "5  lors de ouverture un pack cataracte ( personna...   \n",
       "\n",
       "                                        ETAT_PATIENT  \\\n",
       "1                                                      \n",
       "2                                                . .   \n",
       "3                                                . .   \n",
       "4  perte sanguine du bébé , la pince ne réalisant...   \n",
       "5    pas de conséquences car non utilisation du dm .   \n",
       "\n",
       "                              ACTION_PATIENT  DCO_ID  \\\n",
       "1                                             3268.0   \n",
       "2                                             2497.0   \n",
       "3         matériel à dispo au sce économat .  2851.0   \n",
       "4  un clamp ombilical a été mis en urgence .  4841.0   \n",
       "5                  changements de couteaux .  2902.0   \n",
       "\n",
       "                          LIBELLE_COMMERCIAL REFERENCE_COMMERCIALE  \\\n",
       "1    tensoban - bande de protection adhesive                    ..   \n",
       "2                sphincterotome dreamtome rx             M00584050   \n",
       "3                                    quartet               1456Q86   \n",
       "4  pince kocher dans la trousse accouchement            0007255334   \n",
       "5                couteau standart ° droit st                    ..   \n",
       "\n",
       "                   FABRICANT  \\\n",
       "1                bsn medical   \n",
       "2          boston scientific   \n",
       "3  abbott medical france sas   \n",
       "4                      vygon   \n",
       "5       bausch & lomb france   \n",
       "\n",
       "                              TYPE_DYSFONCTIONNEMENT  \\\n",
       "1                                      NON RENSEIGNE   \n",
       "2                                  NON EFFICACITE DM   \n",
       "3  IMPOSSIBILITE / DIFFICULTE DE POSE / MISE EN P...   \n",
       "4         PROBLEME OUVERTURE / FERMETURE DE LA PINCE   \n",
       "5         DM INCOMPLET / DETERIORE AVANT UTILISATION   \n",
       "\n",
       "  CONSEQUENCE_DYSFONCTIONNEMENT                   TYPE_EFFET GRAVITE  \\\n",
       "1            PAS DE CONSEQUENCE          REACTION ALLERGIQUE   MOYEN   \n",
       "2            PAS DE CONSEQUENCE  PAS D'EFFET NEFASTE DECLARE   NULLE   \n",
       "3            PAS DE CONSEQUENCE  PAS D'EFFET NEFASTE DECLARE   MOYEN   \n",
       "4            PAS DE CONSEQUENCE                PERTE DE SANG   MOYEN   \n",
       "5            PAS DE CONSEQUENCE  PAS D'EFFET NEFASTE DECLARE   MINEU   \n",
       "\n",
       "   CLASSIFICATION                                               text TEF_ID  \\\n",
       "1               1                    apparition de nombreux boutons   [123]   \n",
       "2               1  le sphinctérotome , à la sortie de son emballa...  [106]   \n",
       "3               1  mandrin bloqué dans la sonde et impossibilité ...  [106]   \n",
       "4               1  la pince kocher présente dans la trousse a été...  [113]   \n",
       "5               1  lors de ouverture un pack cataracte ( personna...  [106]   \n",
       "\n",
       "  CDY_ID      TDY_ID  \n",
       "1    [0]       [337]  \n",
       "2    [0]       [329]  \n",
       "3    [0]       [286]  \n",
       "4    [0]       [521]  \n",
       "5    [0]  [395, 206]  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_mrv/declaration_mrv_complet.csv',\n",
    "                 usecols=[\"DESCRIPTION_INCIDENT\",\"ETAT_PATIENT\",\"FABRICANT\", \"CLASSIFICATION\", 'ACTION_PATIENT',\n",
    "                          'DCO_ID','LIBELLE_COMMERCIAL','REFERENCE_COMMERCIALE','TYPE_EFFET','TEF_ID','TYPE_DYSFONCTIONNEMENT',\n",
    "                          'TDY_ID','CONSEQUENCE_DYSFONCTIONNEMENT','CDY_ID','GRAVITE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32452"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"] = data['DESCRIPTION_INCIDENT']+' '+data['ETAT_PATIENT']\n",
    "data_id = data.groupby('text')\n",
    "len(data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['DCO_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8649, 266) (2099, 266) (8649, 4) (2099, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[[\"DESCRIPTION_INCIDENT\",\"ETAT_PATIENT\",\"FABRICANT\",\"CLASSIFICATION\"]]\n",
    "X_test = test[[\"DESCRIPTION_INCIDENT\",\"ETAT_PATIENT\",\"FABRICANT\",\"CLASSIFICATION\"]]\n",
    "y_train = mlb.transform(train['TEF_ID'])\n",
    "y_test = mlb.transform(test['TEF_ID'])\n",
    "print(y_train.shape, y_test.shape, X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(11627, 269) (2896, 269) (11627, 4) (2896, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11627+2896 - len(mrv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1752"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['len'] = X_train['FABRICANT'].map(lambda x : len(x))\n",
    "X_train[X_train['len']>1]['len'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 4 ms, total: 12 ms\n",
      "Wall time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preprocess = ColumnTransformer(\n",
    "    [('description_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 10000,norm = 'l2'), 'DESCRIPTION_INCIDENT'),\n",
    "     \n",
    "     ('etat_pat_tfidf', TfidfVectorizer(sublinear_tf=True, min_df=3,ngram_range=(1, 1),\n",
    "                                       stop_words=STOP_WORDS,\n",
    "                                       max_features = 10000,norm = 'l2'), 'ETAT_PATIENT'),\n",
    "     \n",
    "     ('fabricant_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 5000,norm = 'l2'), 'FABRICANT'),\n",
    "    \n",
    "    ('classification_enc', TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 100,norm = 'l2'),'CLASSIFICATION')\n",
    "     ],\n",
    "    \n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[1;32m    466\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[0;32m--> 467\u001b[0;31m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \"\"\"\n\u001b[1;32m   1839\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1199\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.fit(X_train,y_train)\n",
    "Y_pred_ovr = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test , Y_pred_ovr,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.43      0.55         7\n",
      "           1       1.00      0.25      0.40         4\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.43      0.50      0.46         6\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.50      0.12      0.20         8\n",
      "           7       0.62      0.45      0.53        33\n",
      "           8       0.25      0.19      0.22        36\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.33      0.14      0.20         7\n",
      "          12       0.33      0.06      0.10        18\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       1.00      0.33      0.50         9\n",
      "          15       1.00      0.12      0.22         8\n",
      "          16       1.00      0.14      0.25         7\n",
      "          17       1.00      0.12      0.22         8\n",
      "          18       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         5\n",
      "          21       0.82      0.72      0.76        81\n",
      "          22       1.00      0.33      0.50         9\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       1.00      0.40      0.57        10\n",
      "          25       0.68      0.80      0.74        35\n",
      "          26       1.00      0.33      0.50         3\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.50      0.17      0.25         6\n",
      "          31       0.00      0.00      0.00         3\n",
      "          32       0.62      0.48      0.54        21\n",
      "          33       0.50      0.50      0.50        12\n",
      "          34       0.54      0.74      0.62        19\n",
      "          35       0.67      0.75      0.71        16\n",
      "          36       0.84      0.71      0.77        51\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.40      0.20      0.27        10\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         9\n",
      "          43       0.00      0.00      0.00         3\n",
      "          44       0.00      0.00      0.00        10\n",
      "          45       0.67      0.59      0.63       135\n",
      "          46       0.67      0.27      0.38        15\n",
      "          47       0.00      0.00      0.00         8\n",
      "          48       0.20      0.04      0.07        23\n",
      "          49       0.50      0.33      0.40         3\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.83      0.50      0.62        10\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.56      0.43      0.49        21\n",
      "          54       1.00      0.17      0.29         6\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      0.33      0.50         3\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.35      0.44      0.39        32\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.50      0.33      0.40         3\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       1.00      0.25      0.40         4\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       0.50      0.20      0.29         5\n",
      "          69       1.00      0.83      0.91        12\n",
      "          70       0.00      0.00      0.00         2\n",
      "          71       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.73      0.79      0.76        42\n",
      "          74       1.00      0.80      0.89        10\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.62      0.62      0.62         8\n",
      "          78       1.00      0.40      0.57         5\n",
      "          79       1.00      0.33      0.50         3\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.58      0.23      0.33        47\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.60      0.39      0.47        64\n",
      "          84       0.20      0.09      0.13        11\n",
      "          85       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00        13\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.56      0.56      0.56         9\n",
      "          92       1.00      0.50      0.67         2\n",
      "          93       0.67      0.50      0.57         4\n",
      "          94       0.00      0.00      0.00         3\n",
      "          95       1.00      0.20      0.33         5\n",
      "          96       1.00      0.20      0.33         5\n",
      "          97       1.00      0.50      0.67         6\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       1.00      0.33      0.50         3\n",
      "         100       0.00      0.00      0.00         2\n",
      "         101       0.67      0.33      0.44        18\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00        14\n",
      "         105       0.00      0.00      0.00         2\n",
      "         106       0.00      0.00      0.00         2\n",
      "         107       0.00      0.00      0.00         2\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.78      0.74      0.76        80\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         1\n",
      "         112       0.00      0.00      0.00         2\n",
      "         113       1.00      0.14      0.25         7\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         0\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.85      0.85      0.85       107\n",
      "         120       1.00      0.50      0.67         6\n",
      "         121       0.00      0.00      0.00         2\n",
      "         122       0.33      0.33      0.33         3\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       0.00      0.00      0.00         3\n",
      "         125       0.62      0.38      0.47        34\n",
      "         126       0.59      0.65      0.62       231\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.64      0.30      0.41        23\n",
      "         129       0.68      0.66      0.67       154\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.75      0.38      0.50         8\n",
      "         132       1.00      0.50      0.67         2\n",
      "         133       1.00      0.60      0.75        10\n",
      "         134       1.00      0.17      0.29         6\n",
      "         135       0.00      0.00      0.00         5\n",
      "         136       0.00      0.00      0.00         2\n",
      "         137       0.00      0.00      0.00         1\n",
      "         138       0.67      0.33      0.44         6\n",
      "         139       0.33      0.21      0.26        47\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       0.00      0.00      0.00         3\n",
      "         142       1.00      1.00      1.00         3\n",
      "         143       0.00      0.00      0.00         3\n",
      "         144       0.00      0.00      0.00         2\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         2\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       0.50      0.10      0.17        10\n",
      "         149       0.93      0.98      0.95       297\n",
      "         150       1.00      0.14      0.25         7\n",
      "         151       0.38      0.50      0.43        10\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.83      0.71      0.77        28\n",
      "         156       0.67      0.67      0.67         3\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       0.51      0.53      0.52       137\n",
      "         159       0.73      0.39      0.51        28\n",
      "         160       0.00      0.00      0.00         0\n",
      "         161       0.00      0.00      0.00         2\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         0\n",
      "         164       0.59      0.44      0.50        39\n",
      "         165       0.61      0.69      0.65       158\n",
      "         166       0.71      0.85      0.77       191\n",
      "         167       0.64      0.61      0.63        70\n",
      "         168       0.67      0.72      0.70        83\n",
      "         169       0.62      0.67      0.65        94\n",
      "         170       0.62      0.33      0.43        40\n",
      "         171       0.62      0.66      0.64        73\n",
      "         172       0.64      0.86      0.74       169\n",
      "         173       0.75      0.29      0.41        21\n",
      "         174       0.00      0.00      0.00         8\n",
      "         175       1.00      0.33      0.50         9\n",
      "         176       0.89      0.50      0.64        16\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       1.00      0.20      0.33         5\n",
      "         179       0.67      0.32      0.43        19\n",
      "         180       0.00      0.00      0.00         6\n",
      "         181       0.58      0.47      0.52        53\n",
      "         182       0.55      0.53      0.54        53\n",
      "         183       0.69      0.33      0.45        33\n",
      "         184       1.00      0.12      0.22        16\n",
      "         185       0.00      0.00      0.00         4\n",
      "         186       0.00      0.00      0.00        14\n",
      "         187       0.00      0.00      0.00         3\n",
      "         188       1.00      0.43      0.60         7\n",
      "         189       0.00      0.00      0.00         2\n",
      "         190       0.67      0.24      0.35        17\n",
      "         191       0.38      0.39      0.39        28\n",
      "         192       0.66      0.63      0.64       243\n",
      "         193       0.74      0.48      0.58        48\n",
      "         194       1.00      0.33      0.50         3\n",
      "         195       0.45      0.40      0.43        75\n",
      "         196       0.33      0.22      0.27         9\n",
      "         197       0.00      0.00      0.00         3\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.50      0.40      0.44        20\n",
      "         203       0.80      0.25      0.38        16\n",
      "         204       0.75      0.23      0.35        13\n",
      "         205       0.80      0.33      0.47        12\n",
      "         206       1.00      0.50      0.67         4\n",
      "         207       0.00      0.00      0.00         1\n",
      "         208       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         1\n",
      "         210       0.50      0.50      0.50         2\n",
      "         211       0.00      0.00      0.00         1\n",
      "         212       0.00      0.00      0.00         1\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         3\n",
      "         215       0.50      0.67      0.57         3\n",
      "         216       0.00      0.00      0.00         1\n",
      "         217       0.00      0.00      0.00         1\n",
      "         218       0.00      0.00      0.00         2\n",
      "         219       0.00      0.00      0.00         3\n",
      "         220       0.00      0.00      0.00         1\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.00      0.00      0.00         0\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00         0\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         2\n",
      "         230       1.00      0.20      0.33         5\n",
      "         231       1.00      0.25      0.40         4\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       1.00      0.50      0.67         2\n",
      "         234       1.00      1.00      1.00         1\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         2\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         0\n",
      "         239       0.00      0.00      0.00         1\n",
      "         240       0.00      0.00      0.00         1\n",
      "         241       0.00      0.00      0.00         0\n",
      "         242       0.00      0.00      0.00         0\n",
      "         243       0.00      0.00      0.00         1\n",
      "         244       0.00      0.00      0.00         0\n",
      "         245       0.00      0.00      0.00         0\n",
      "         246       0.00      0.00      0.00         1\n",
      "         247       0.00      0.00      0.00         4\n",
      "         248       0.00      0.00      0.00         0\n",
      "         249       0.00      0.00      0.00         1\n",
      "         250       0.00      0.00      0.00         1\n",
      "         251       0.00      0.00      0.00         0\n",
      "         252       1.00      0.25      0.40         4\n",
      "         253       0.00      0.00      0.00         0\n",
      "         254       0.00      0.00      0.00         3\n",
      "         255       0.00      0.00      0.00         0\n",
      "         256       0.00      0.00      0.00         1\n",
      "         257       0.67      0.20      0.31        10\n",
      "         258       0.00      0.00      0.00         0\n",
      "         259       0.00      0.00      0.00         1\n",
      "         260       0.00      0.00      0.00         0\n",
      "         261       0.00      0.00      0.00         1\n",
      "         262       0.00      0.00      0.00         4\n",
      "         263       0.00      0.00      0.00         0\n",
      "         264       0.00      0.00      0.00         2\n",
      "         265       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       0.67      0.56      0.61      4102\n",
      "   macro avg       0.32      0.19      0.22      4102\n",
      "weighted avg       0.63      0.56      0.58      4102\n",
      " samples avg       0.54      0.54      0.51      4102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test , Y_pred_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.5264524271227642\n",
      "CPU times: user 17.9 s, sys: 116 ms, total: 18 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.fit(X_train,y_train)\n",
    "Y_pred_ovr = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test , Y_pred_ovr,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.69      0.64      0.67        14\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.25      0.10      0.14        10\n",
      "           7       0.56      0.55      0.55        44\n",
      "           8       0.41      0.23      0.29        48\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.67      0.25      0.36         8\n",
      "          12       0.30      0.15      0.20        20\n",
      "          13       1.00      0.40      0.57         5\n",
      "          14       1.00      0.11      0.20         9\n",
      "          15       0.33      0.11      0.17         9\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.67      0.25      0.36         8\n",
      "          18       1.00      0.20      0.33         5\n",
      "          19       0.00      0.00      0.00         3\n",
      "          20       0.50      0.20      0.29         5\n",
      "          21       0.77      0.74      0.76        97\n",
      "          22       0.50      0.08      0.13        13\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.60      0.25      0.35        12\n",
      "          25       0.67      0.67      0.67        39\n",
      "          26       0.50      0.25      0.33         4\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       1.00      0.38      0.55         8\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.51      0.60      0.55        30\n",
      "          33       0.51      0.69      0.59        35\n",
      "          34       0.71      0.89      0.79        57\n",
      "          35       0.91      0.81      0.85        36\n",
      "          36       0.85      0.75      0.80        71\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.67      0.60      0.63        10\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.43      0.25      0.32        12\n",
      "          43       0.00      0.00      0.00         4\n",
      "          44       0.14      0.09      0.11        11\n",
      "          45       0.60      0.60      0.60       178\n",
      "          46       0.25      0.06      0.09        18\n",
      "          47       0.00      0.00      0.00         9\n",
      "          48       0.21      0.11      0.15        27\n",
      "          49       1.00      0.25      0.40         4\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       1.00      0.45      0.62        11\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.48      0.59      0.53        34\n",
      "          54       0.45      0.45      0.45        11\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         2\n",
      "          57       1.00      1.00      1.00         3\n",
      "          58       0.00      0.00      0.00         2\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.30      0.59      0.40        64\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       1.00      0.33      0.50         3\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       1.00      0.20      0.33         5\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.71      0.56      0.63         9\n",
      "          70       0.90      0.86      0.88        22\n",
      "          71       0.50      0.33      0.40         3\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.76      0.83      0.79        69\n",
      "          75       0.56      0.33      0.42        15\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.62      0.50      0.56        10\n",
      "          79       0.33      0.17      0.22         6\n",
      "          80       1.00      0.50      0.67         4\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.72      0.43      0.54        61\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.62      0.51      0.56        88\n",
      "          85       0.14      0.06      0.08        17\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         0\n",
      "          90       0.00      0.00      0.00        17\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.75      0.60      0.67        10\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       0.78      0.64      0.70        11\n",
      "          95       0.00      0.00      0.00         5\n",
      "          96       0.00      0.00      0.00         5\n",
      "          97       0.67      0.33      0.44         6\n",
      "          98       0.00      0.00      0.00         0\n",
      "          99       1.00      0.25      0.40         8\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.00      0.00      0.00         3\n",
      "         102       0.00      0.00      0.00         3\n",
      "         103       0.67      0.19      0.30        21\n",
      "         104       0.00      0.00      0.00         1\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.75      0.38      0.50        16\n",
      "         107       0.00      0.00      0.00         2\n",
      "         108       1.00      0.67      0.80         3\n",
      "         109       0.00      0.00      0.00         3\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.76      0.59      0.66        90\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         3\n",
      "         115       1.00      0.25      0.40         8\n",
      "         116       0.00      0.00      0.00         1\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       0.82      0.87      0.84       141\n",
      "         122       0.00      0.00      0.00         7\n",
      "         123       0.00      0.00      0.00         2\n",
      "         124       1.00      0.33      0.50         3\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         3\n",
      "         127       0.50      0.33      0.39        40\n",
      "         128       0.63      0.65      0.64       268\n",
      "         129       0.00      0.00      0.00         1\n",
      "         130       0.43      0.11      0.18        27\n",
      "         131       0.67      0.66      0.66       204\n",
      "         132       0.00      0.00      0.00         2\n",
      "         133       0.62      0.67      0.65        15\n",
      "         134       1.00      0.50      0.67         2\n",
      "         135       1.00      0.67      0.80        12\n",
      "         136       0.71      0.71      0.71         7\n",
      "         137       1.00      0.33      0.50         6\n",
      "         138       0.50      0.33      0.40         3\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       1.00      0.88      0.93         8\n",
      "         141       0.40      0.21      0.28        57\n",
      "         142       1.00      0.50      0.67         2\n",
      "         143       0.00      0.00      0.00         3\n",
      "         144       0.67      0.67      0.67         3\n",
      "         145       0.00      0.00      0.00         3\n",
      "         146       0.00      0.00      0.00         2\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       1.00      0.50      0.67         2\n",
      "         149       0.00      0.00      0.00         1\n",
      "         150       1.00      0.09      0.17        11\n",
      "         151       0.91      0.98      0.94       435\n",
      "         152       1.00      0.11      0.20         9\n",
      "         153       0.43      0.76      0.55        38\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.86      0.56      0.68        32\n",
      "         158       1.00      0.50      0.67         4\n",
      "         159       0.00      0.00      0.00         2\n",
      "         160       0.40      0.55      0.46       229\n",
      "         161       0.66      0.62      0.64        40\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         3\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       0.49      0.38      0.43        50\n",
      "         167       0.62      0.77      0.69       223\n",
      "         168       0.67      0.85      0.75       281\n",
      "         169       0.62      0.75      0.68        97\n",
      "         170       0.59      0.70      0.64       115\n",
      "         171       0.54      0.71      0.61       127\n",
      "         172       0.68      0.45      0.54        55\n",
      "         173       0.55      0.58      0.56        99\n",
      "         174       0.67      0.82      0.74       248\n",
      "         175       0.38      0.19      0.26        26\n",
      "         176       1.00      0.30      0.46        10\n",
      "         177       0.86      0.46      0.60        13\n",
      "         178       0.86      0.63      0.73        19\n",
      "         179       0.00      0.00      0.00         0\n",
      "         180       1.00      0.20      0.33         5\n",
      "         181       0.63      0.44      0.52        27\n",
      "         182       1.00      0.12      0.22         8\n",
      "         183       0.66      0.64      0.65        77\n",
      "         184       0.48      0.45      0.46        74\n",
      "         185       0.53      0.36      0.43        44\n",
      "         186       0.36      0.18      0.24        22\n",
      "         187       1.00      0.20      0.33         5\n",
      "         188       0.83      0.56      0.67        18\n",
      "         189       0.50      0.29      0.36         7\n",
      "         190       0.86      0.92      0.89        13\n",
      "         191       0.00      0.00      0.00         2\n",
      "         192       0.36      0.23      0.28        22\n",
      "         193       0.55      0.48      0.52        33\n",
      "         194       0.62      0.71      0.66       314\n",
      "         195       0.55      0.54      0.54        56\n",
      "         196       1.00      1.00      1.00         3\n",
      "         197       0.39      0.31      0.35        89\n",
      "         198       1.00      0.11      0.20         9\n",
      "         199       1.00      0.25      0.40         4\n",
      "         200       0.00      0.00      0.00         1\n",
      "         201       1.00      1.00      1.00         1\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.69      0.48      0.56        23\n",
      "         205       0.75      0.32      0.44        19\n",
      "         206       0.75      0.43      0.55        14\n",
      "         207       0.75      0.21      0.33        14\n",
      "         208       0.00      0.00      0.00         5\n",
      "         209       0.00      0.00      0.00         1\n",
      "         210       0.00      0.00      0.00         1\n",
      "         211       1.00      0.50      0.67         2\n",
      "         212       0.00      0.00      0.00         2\n",
      "         213       0.00      0.00      0.00         1\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       1.00      1.00      1.00         3\n",
      "         217       0.00      0.00      0.00         3\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         2\n",
      "         220       0.00      0.00      0.00         2\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.00      0.00      0.00         3\n",
      "         223       0.00      0.00      0.00         1\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       0.00      0.00      0.00         0\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.00      0.00      0.00         1\n",
      "         231       0.00      0.00      0.00         0\n",
      "         232       1.00      0.33      0.50         3\n",
      "         233       0.00      0.00      0.00         5\n",
      "         234       0.75      0.60      0.67         5\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         2\n",
      "         237       1.00      1.00      1.00         1\n",
      "         238       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         3\n",
      "         240       0.00      0.00      0.00         0\n",
      "         241       0.00      0.00      0.00         0\n",
      "         242       0.00      0.00      0.00         1\n",
      "         243       0.00      0.00      0.00         1\n",
      "         244       0.00      0.00      0.00         0\n",
      "         245       0.00      0.00      0.00         0\n",
      "         246       0.50      1.00      0.67         1\n",
      "         247       0.00      0.00      0.00         0\n",
      "         248       0.00      0.00      0.00         1\n",
      "         249       0.00      0.00      0.00         2\n",
      "         250       0.00      0.00      0.00         5\n",
      "         251       0.00      0.00      0.00         0\n",
      "         252       0.00      0.00      0.00         1\n",
      "         253       0.00      0.00      0.00         1\n",
      "         254       0.00      0.00      0.00         0\n",
      "         255       0.00      0.00      0.00         5\n",
      "         256       0.00      0.00      0.00         0\n",
      "         257       0.00      0.00      0.00         3\n",
      "         258       0.00      0.00      0.00         0\n",
      "         259       0.00      0.00      0.00         1\n",
      "         260       0.50      0.08      0.14        12\n",
      "         261       0.00      0.00      0.00         0\n",
      "         262       1.00      0.50      0.67         2\n",
      "         263       0.00      0.00      0.00         0\n",
      "         264       1.00      0.50      0.67         2\n",
      "         265       0.00      0.00      0.00         4\n",
      "         266       0.00      0.00      0.00         0\n",
      "         267       0.33      0.25      0.29         4\n",
      "         268       1.00      0.33      0.50         3\n",
      "\n",
      "   micro avg       0.63      0.61      0.62      5581\n",
      "   macro avg       0.34      0.23      0.25      5581\n",
      "weighted avg       0.62      0.61      0.60      5581\n",
      " samples avg       0.53      0.58      0.53      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test , Y_pred_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.9016472532225805\n",
      "CPU times: user 2min 8s, sys: 284 ms, total: 2min 9s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.fit(X_train,y_train)\n",
    "Y_pred_ovr = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test , Y_pred_ovr,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9014, 269) (9014, 269)\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred_ovr.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        39\n",
      "           1       1.00      0.29      0.44         7\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00        19\n",
      "           4       0.92      0.97      0.94        68\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       0.95      0.91      0.93        22\n",
      "           7       0.91      0.91      0.91        89\n",
      "           8       0.97      0.99      0.98       365\n",
      "           9       1.00      0.25      0.40         4\n",
      "          10       1.00      1.00      1.00        16\n",
      "          11       1.00      0.87      0.93        30\n",
      "          12       0.86      0.82      0.84        45\n",
      "          13       1.00      0.82      0.90        11\n",
      "          14       1.00      0.93      0.97        30\n",
      "          15       1.00      0.83      0.90        23\n",
      "          16       0.89      0.67      0.76        12\n",
      "          17       1.00      0.83      0.91        24\n",
      "          18       1.00      0.60      0.75        10\n",
      "          19       1.00      0.50      0.67         4\n",
      "          20       1.00      0.75      0.86         8\n",
      "          21       0.92      0.92      0.92       219\n",
      "          22       0.98      0.89      0.93        56\n",
      "          23       1.00      1.00      1.00         7\n",
      "          24       0.91      0.95      0.93        41\n",
      "          25       0.88      0.95      0.91        77\n",
      "          26       1.00      1.00      1.00        17\n",
      "          27       1.00      1.00      1.00         3\n",
      "          28       1.00      1.00      1.00         1\n",
      "          29       1.00      1.00      1.00         6\n",
      "          30       0.86      0.75      0.80        16\n",
      "          31       0.89      1.00      0.94         8\n",
      "          32       0.79      0.93      0.85        82\n",
      "          33       0.78      0.92      0.85        87\n",
      "          34       0.86      0.98      0.92       169\n",
      "          35       0.97      0.98      0.97       118\n",
      "          36       0.98      0.98      0.98       224\n",
      "          37       0.00      0.00      0.00         0\n",
      "          38       1.00      1.00      1.00         1\n",
      "          39       0.92      1.00      0.96        35\n",
      "          40       1.00      1.00      1.00         7\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       0.89      0.85      0.87        20\n",
      "          43       1.00      1.00      1.00        18\n",
      "          44       1.00      0.63      0.77        38\n",
      "          45       0.89      0.94      0.91       642\n",
      "          46       0.90      0.80      0.85        56\n",
      "          47       1.00      0.96      0.98        45\n",
      "          48       0.96      0.93      0.94        70\n",
      "          49       0.87      1.00      0.93        13\n",
      "          50       1.00      1.00      1.00         5\n",
      "          51       0.97      1.00      0.99        37\n",
      "          52       1.00      1.00      1.00         8\n",
      "          53       0.87      1.00      0.93       156\n",
      "          54       0.82      0.88      0.85        26\n",
      "          55       1.00      0.40      0.57         5\n",
      "          56       1.00      1.00      1.00         8\n",
      "          57       1.00      0.91      0.95        11\n",
      "          58       1.00      0.50      0.67         4\n",
      "          59       1.00      1.00      1.00         2\n",
      "          60       0.53      0.96      0.68       135\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       1.00      0.50      0.67         2\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       1.00      1.00      1.00        19\n",
      "          65       1.00      0.57      0.73         7\n",
      "          66       0.89      0.80      0.84        10\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      1.00      1.00         1\n",
      "          69       0.95      0.98      0.96        41\n",
      "          70       0.95      0.99      0.97        72\n",
      "          71       0.50      0.50      0.50         6\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       0.88      0.96      0.91       117\n",
      "          75       0.85      0.74      0.79        23\n",
      "          76       1.00      1.00      1.00         3\n",
      "          77       1.00      1.00      1.00         3\n",
      "          78       0.92      0.90      0.91        40\n",
      "          79       0.93      1.00      0.96        13\n",
      "          80       1.00      1.00      1.00        26\n",
      "          81       1.00      0.73      0.84        11\n",
      "          82       0.97      0.97      0.97       301\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.97      0.99      0.98       728\n",
      "          85       0.89      0.96      0.93        52\n",
      "          86       1.00      0.83      0.91         6\n",
      "          87       1.00      1.00      1.00         1\n",
      "          88       1.00      1.00      1.00         2\n",
      "          89       1.00      1.00      1.00         1\n",
      "          90       0.97      0.79      0.87        48\n",
      "          91       1.00      1.00      1.00         3\n",
      "          92       0.98      0.93      0.95        44\n",
      "          93       1.00      1.00      1.00         6\n",
      "          94       0.96      0.98      0.97        49\n",
      "          95       1.00      1.00      1.00        38\n",
      "          96       1.00      0.93      0.96        29\n",
      "          97       1.00      0.91      0.95        33\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       1.00      0.92      0.96        24\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       0.92      0.86      0.89        14\n",
      "         102       1.00      0.90      0.95        10\n",
      "         103       0.99      0.97      0.98        96\n",
      "         104       1.00      1.00      1.00         2\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.97      0.88      0.92        73\n",
      "         107       1.00      0.86      0.92         7\n",
      "         108       1.00      0.75      0.86         8\n",
      "         109       0.67      0.50      0.57         4\n",
      "         110       1.00      1.00      1.00        26\n",
      "         111       0.95      0.97      0.96       209\n",
      "         112       0.00      0.00      0.00         0\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       1.00      0.90      0.95        10\n",
      "         115       1.00      1.00      1.00        34\n",
      "         116       1.00      1.00      1.00         2\n",
      "         117       1.00      1.00      1.00         2\n",
      "         118       1.00      1.00      1.00         1\n",
      "         119       1.00      1.00      1.00         2\n",
      "         120       1.00      0.67      0.80         3\n",
      "         121       0.91      0.94      0.93       272\n",
      "         122       0.75      0.71      0.73        17\n",
      "         123       1.00      0.80      0.89         5\n",
      "         124       1.00      0.86      0.92         7\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       1.00      1.00      1.00        25\n",
      "         127       0.83      0.76      0.79        78\n",
      "         128       0.84      0.89      0.86       547\n",
      "         129       1.00      1.00      1.00         4\n",
      "         130       0.81      0.69      0.74        51\n",
      "         131       0.99      0.99      0.99      2003\n",
      "         132       1.00      1.00      1.00        25\n",
      "         133       0.96      0.99      0.98        82\n",
      "         134       1.00      1.00      1.00         4\n",
      "         135       0.87      0.76      0.81        17\n",
      "         136       0.88      0.92      0.90        24\n",
      "         137       1.00      0.92      0.96        26\n",
      "         138       1.00      1.00      1.00        17\n",
      "         139       1.00      1.00      1.00         2\n",
      "         140       1.00      0.90      0.95        21\n",
      "         141       0.90      0.80      0.85       116\n",
      "         142       1.00      0.83      0.91         6\n",
      "         143       1.00      0.86      0.92         7\n",
      "         144       0.75      0.75      0.75         4\n",
      "         145       0.00      0.00      0.00         5\n",
      "         146       1.00      1.00      1.00         8\n",
      "         147       1.00      1.00      1.00         1\n",
      "         148       1.00      0.86      0.92         7\n",
      "         149       1.00      1.00      1.00         6\n",
      "         150       0.98      0.93      0.96        46\n",
      "         151       0.99      1.00      0.99      3529\n",
      "         152       0.97      0.81      0.88        37\n",
      "         153       0.51      0.88      0.64        67\n",
      "         154       1.00      1.00      1.00         2\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       1.00      1.00      1.00        10\n",
      "         157       0.88      0.80      0.84        61\n",
      "         158       0.97      1.00      0.98        31\n",
      "         159       1.00      1.00      1.00         4\n",
      "         160       0.72      0.91      0.80       582\n",
      "         161       0.84      0.87      0.85        83\n",
      "         162       1.00      1.00      1.00         2\n",
      "         163       1.00      0.95      0.98        22\n",
      "         164       1.00      1.00      1.00         1\n",
      "         165       1.00      1.00      1.00         1\n",
      "         166       0.99      1.00      1.00       749\n",
      "         167       0.98      0.99      0.99      2289\n",
      "         168       0.98      1.00      0.99      3033\n",
      "         169       0.99      1.00      0.99      1356\n",
      "         170       0.99      1.00      1.00      1642\n",
      "         171       0.99      1.00      0.99      1760\n",
      "         172       1.00      1.00      1.00       749\n",
      "         173       0.99      1.00      0.99      1534\n",
      "         174       0.98      1.00      0.99      2784\n",
      "         175       1.00      1.00      1.00       505\n",
      "         176       1.00      0.99      1.00       200\n",
      "         177       1.00      0.98      0.99       172\n",
      "         178       1.00      1.00      1.00       249\n",
      "         179       1.00      1.00      1.00         7\n",
      "         180       1.00      1.00      1.00        72\n",
      "         181       0.99      1.00      1.00       468\n",
      "         182       1.00      1.00      1.00       108\n",
      "         183       0.99      1.00      0.99       949\n",
      "         184       0.99      1.00      0.99       945\n",
      "         185       1.00      1.00      1.00       692\n",
      "         186       1.00      1.00      1.00       402\n",
      "         187       1.00      1.00      1.00        52\n",
      "         188       1.00      1.00      1.00       478\n",
      "         189       0.98      1.00      0.99        52\n",
      "         190       0.98      0.96      0.97        46\n",
      "         191       1.00      1.00      1.00         9\n",
      "         192       0.94      1.00      0.97        66\n",
      "         193       0.88      0.96      0.92       104\n",
      "         194       0.88      0.95      0.91       872\n",
      "         195       0.91      0.91      0.91       153\n",
      "         196       1.00      1.00      1.00        13\n",
      "         197       0.84      0.93      0.88       246\n",
      "         198       0.90      0.78      0.84        23\n",
      "         199       1.00      0.93      0.96        14\n",
      "         200       1.00      1.00      1.00         2\n",
      "         201       1.00      1.00      1.00         1\n",
      "         202       1.00      1.00      1.00         3\n",
      "         203       1.00      1.00      1.00         1\n",
      "         204       0.97      0.95      0.96        92\n",
      "         205       0.95      0.97      0.96        71\n",
      "         206       0.98      0.98      0.98        64\n",
      "         207       0.97      0.88      0.93        43\n",
      "         208       1.00      1.00      1.00        18\n",
      "         209       1.00      0.67      0.80         3\n",
      "         210       1.00      1.00      1.00         7\n",
      "         211       1.00      1.00      1.00        18\n",
      "         212       1.00      1.00      1.00        17\n",
      "         213       1.00      1.00      1.00         3\n",
      "         214       1.00      1.00      1.00         2\n",
      "         215       1.00      1.00      1.00         1\n",
      "         216       1.00      0.94      0.97        16\n",
      "         217       1.00      1.00      1.00        11\n",
      "         218       1.00      1.00      1.00         7\n",
      "         219       1.00      1.00      1.00         4\n",
      "         220       1.00      1.00      1.00         8\n",
      "         221       0.00      0.00      0.00         0\n",
      "         222       0.86      1.00      0.92        12\n",
      "         223       1.00      1.00      1.00         2\n",
      "         224       0.00      0.00      0.00         0\n",
      "         225       1.00      1.00      1.00         7\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       1.00      1.00      1.00         3\n",
      "         228       0.00      0.00      0.00         1\n",
      "         229       1.00      1.00      1.00         2\n",
      "         230       1.00      1.00      1.00         3\n",
      "         231       1.00      1.00      1.00         1\n",
      "         232       1.00      1.00      1.00        11\n",
      "         233       0.96      0.86      0.91        28\n",
      "         234       1.00      1.00      1.00        16\n",
      "         235       1.00      1.00      1.00        23\n",
      "         236       1.00      0.86      0.92         7\n",
      "         237       1.00      1.00      1.00         3\n",
      "         238       1.00      1.00      1.00         3\n",
      "         239       1.00      0.82      0.90        11\n",
      "         240       1.00      1.00      1.00         2\n",
      "         241       0.00      0.00      0.00         0\n",
      "         242       1.00      1.00      1.00         6\n",
      "         243       1.00      1.00      1.00         1\n",
      "         244       1.00      1.00      1.00         1\n",
      "         245       1.00      1.00      1.00         1\n",
      "         246       1.00      1.00      1.00        10\n",
      "         247       1.00      1.00      1.00         7\n",
      "         248       1.00      1.00      1.00         1\n",
      "         249       1.00      1.00      1.00         5\n",
      "         250       1.00      0.73      0.85        15\n",
      "         251       1.00      1.00      1.00         1\n",
      "         252       1.00      0.50      0.67         2\n",
      "         253       1.00      1.00      1.00         2\n",
      "         254       1.00      1.00      1.00         2\n",
      "         255       1.00      0.64      0.78        11\n",
      "         256       0.00      0.00      0.00         0\n",
      "         257       1.00      0.67      0.80        12\n",
      "         258       1.00      1.00      1.00         1\n",
      "         259       1.00      1.00      1.00         3\n",
      "         260       1.00      0.71      0.83        21\n",
      "         261       1.00      1.00      1.00         1\n",
      "         262       1.00      1.00      1.00         7\n",
      "         263       1.00      1.00      1.00         1\n",
      "         264       1.00      1.00      1.00         7\n",
      "         265       1.00      0.70      0.82        10\n",
      "         266       1.00      1.00      1.00         1\n",
      "         267       0.92      0.80      0.86        15\n",
      "         268       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.96      0.98      0.97     36925\n",
      "   macro avg       0.90      0.86      0.87     36925\n",
      "weighted avg       0.96      0.98      0.97     36925\n",
      " samples avg       0.89      0.93      0.90     36925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test , Y_pred_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11628"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.29 ms\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "train = pd.read_pickle('./data_split/train.pkl')\n",
    "# Pour faire un modèle sans le \n",
    "#train = train[~train['TEF_ID'].map(lambda x : 106 in x)]\n",
    "X_train = train[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "y_train = mlb.fit_transform(train['TEF_ID'])\n",
    "test =  pd.read_pickle('./data_split/test.pkl')\n",
    "#test = test[~test['TEF_ID'].map(lambda x : k in x)]\n",
    "X_test = test[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "y_test = mlb.transform(test['TEF_ID'])\n",
    "\n",
    "\n",
    "df_effets = pd.read_csv(\"data/ref_MRV/referentiel_dispositif_effets_connus.csv\",delimiter=';',encoding='ISO-8859-1')\n",
    "df_dys = pd.read_csv(\"data/ref_MRV/referentiel_dispositif_dysfonctionnement.csv\",delimiter=';',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [('description_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 10000,norm = 'l2'), 'DESCRIPTION_INCIDENT'),\n",
    "     \n",
    "     ('etat_pat_tfidf', TfidfVectorizer(sublinear_tf=True, min_df=3,ngram_range=(1, 1),\n",
    "                                       stop_words=STOP_WORDS,\n",
    "                                       max_features = 10000,norm = 'l2'), 'ETAT_PATIENT'),\n",
    "     \n",
    "     ('fabricant_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 5000,norm = 'l2'), 'FABRICANT')\n",
    "     ],\n",
    "    \n",
    "    remainder='passthrough')\n",
    "\n",
    "preprocess_2 = ColumnTransformer(\n",
    "    [('description_tfidf',CountVectorizer( min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 10000), 'DESCRIPTION_INCIDENT'),\n",
    "     \n",
    "     ('etat_pat_tfidf', CountVectorizer( min_df=3,ngram_range=(1, 1),\n",
    "                                       stop_words=STOP_WORDS,\n",
    "                                       max_features = 10000), 'ETAT_PATIENT'),\n",
    "     \n",
    "     ('fabricant_tfidf',CountVectorizer(min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 5000), 'FABRICANT')\n",
    "     ],\n",
    "    \n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('svd', TruncatedSVD(n_components=1000)),\n",
    "    ('clf', OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, class_weight=\"balanced\")))\n",
    "])\n",
    "\n",
    "pipeline_2 = Pipeline([\n",
    "    ('vect', preprocess_2),\n",
    "    ('svd', TruncatedSVD(n_components=1000)),\n",
    "    ('clf', OneVsRestClassifier(RandomForestClassifier(n_jobs=-1)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.578100646675142\n",
      "CPU times: user 7min 49s, sys: 3min 5s, total: 10min 55s\n",
      "Wall time: 30min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_pred =pipeline.predict(X_test)\n",
    "print(f1_score(y_test,y_pred, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5260033309590517\n",
      "CPU times: user 7.78 s, sys: 88 ms, total: 7.86 s\n",
      "Wall time: 7.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_2.fit(X_train,y_train)\n",
    "y_pred =pipeline_2.predict(X_test)\n",
    "print(f1_score(y_test,y_pred, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score,f1_score,classification_report,recall_score,precision_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp =spacy.load('fr')\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 28.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "train = pd.read_pickle('./data_split/train.pkl')\n",
    "# Pour faire un modèle sans le \n",
    "#train = train[~train['TEF_ID'].map(lambda x : 106 in x)]\n",
    "X_train = train[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "y_train = mlb.fit_transform(train['TEF_ID'])\n",
    "test =  pd.read_pickle('./data_split/test.pkl')\n",
    "#test = test[~test['TEF_ID'].map(lambda x : k in x)]\n",
    "X_test = test[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "y_test = mlb.transform(test['TEF_ID'])\n",
    "\n",
    "\n",
    "X_train_dgs = np.load('results/dgs_camenbert_train_vec.npy')\n",
    "X_test_dgs =np.load('results/dgs_camenbert_test_vec.npy')\n",
    "\n",
    "\n",
    "\n",
    "df_effets = pd.read_csv(\"data/ref_MRV/referentiel_dispositif_effets_connus.csv\",delimiter=';',encoding='ISO-8859-1')\n",
    "df_dys = pd.read_csv(\"data/ref_MRV/referentiel_dispositif_dysfonctionnement.csv\",delimiter=';',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-0cd7babd6f0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mPRED\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;34m\"not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[0;32m--> 245\u001b[0;31m             for i, column in enumerate(columns))\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[0;34m(estimator, X, y, classes)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    970\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# entrainons un modèle par classes\n",
    "n=1536\n",
    "dgs_desc_train, dgs_etat_train, dgs_fab_train,dgs_action_train  = X_train_dgs[:,:n],X_train_dgs[:,n:2*n], X_train_dgs[:,2*n:3*n], X_train_dgs[:,3*n:]\n",
    "dgs_desc_test, dgs_etat_test, dgs_fab_test,dgs_action_test  = X_test_dgs[:,:n],X_test_dgs[:,n:2*n], X_test_dgs[:,2*n:3*n], X_test_dgs[:,3*n:]\n",
    "\n",
    "train_list = [dgs_desc_train, dgs_etat_train, dgs_fab_train,dgs_action_train]\n",
    "test_list = [dgs_desc_test, dgs_etat_test, dgs_fab_test,dgs_action_test ]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('svd',TruncatedSVD(n_components=300)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])\n",
    "PRED= []\n",
    "for x_train,x_test in zip(train_list,test_list) :\n",
    "    pipeline.fit(x_train,y_train)\n",
    "    y_pred= pipeline.predict(x_test)\n",
    "    print(f1_score(y_test, y_pred, average='samples'))\n",
    "    PRED.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26324, 1536)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgs_desc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dgs = joblib.load('Effet_model_dgs_emb.sav')\n",
    "y_pred_dgs = pipeline_dgs.predict(X_test_dgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5602698959256718\n",
      "CPU times: user 25min 27s, sys: 6min 18s, total: 31min 46s\n",
      "Wall time: 23min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [('description_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 10000,norm = 'l2'), 'DESCRIPTION_INCIDENT'),\n",
    "     \n",
    "     ('etat_pat_tfidf', TfidfVectorizer(sublinear_tf=True, min_df=3,ngram_range=(1, 1),\n",
    "                                       stop_words=STOP_WORDS,\n",
    "                                       max_features = 10000,norm = 'l2'), 'ETAT_PATIENT'),\n",
    "     \n",
    "     ('fabricant_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 5000,norm = 'l2'), 'FABRICANT')\n",
    "     ],\n",
    "    \n",
    "    remainder='passthrough')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('svd',TruncatedSVD(n_components=1000)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_pred, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For threshold:  0.01\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.04\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.06\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.08\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.1\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.12\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.14\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.16\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.2\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.25\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.3\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.35\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.4\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.5\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5775, Recall: 0.7811, F1-measure: 0.6323\n",
      "For threshold:  0.6\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5727, Recall: 0.5757, F1-measure: 0.5627\n",
      "For threshold:  0.7\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5727, Recall: 0.5757, F1-measure: 0.5627\n"
     ]
    }
   ],
   "source": [
    "y_pred_ensemble = np.mean([y_pred_dgs,y_pred],axis=0)\n",
    "\n",
    "thresholds = [0.01,0.04,0.06,0.08,0.1,0.12,0.14,0.16,0.2,0.25,0.3,0.35,0.4,0.5,0.6,0.7,0.8]\n",
    "for val in thresholds:\n",
    "    print(\"For threshold: \", val)\n",
    "    pred=y_pred_ensemble.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "  \n",
    "    precision = precision_score(y_test, pred, average='samples')\n",
    "    recall = recall_score(y_test, pred, average='samples')\n",
    "    f1 = f1_score(y_test, pred, average='samples')\n",
    "   \n",
    "    print(\"Samples-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGS-env",
   "language": "python",
   "name": "dgs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
