{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Inférence de l'effet - Stratégie Multilabels\n",
    "Dans ce Notebook, nous cosntruisons un modèle qui permet d'inférer l'EFFET à partir de la classification de l'incident et des données textuelles\n",
    "\n",
    "Nous considérons ce problème comme un problème de classification multiclasses et multilabels. En effet, il y a plusieurs effets possibles et un incidents peut entrainer plusieurs effets.\n",
    "\n",
    "Ainsi, notre métrique d'évaluation sera le f1_samples\n",
    "\n",
    "Dans le Notebook précedent, nous n'avions pas pris en compte l'aspect multilabel et notre score était de  f1_weighted = 0,28.\n",
    "\n",
    "Volontairement dans un premier temps, nous ne modifions pas les paramères de notre modèle afin d'avaluer l'apport de la stratégie multilabelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "lang ='french'\n",
    "\n",
    "import clean_text\n",
    "import skmultilearn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score,f1_score,classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import TruncatedSVD,IncrementalPCA,SparsePCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import spacy\n",
    "nlp =spacy.load('fr')\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "df_declaration_mrv = pd.read_csv(\"data/data_mrv/declaration_mrv_complet.csv\")#delimiter=';',encoding='ISO-8859-1')\n",
    "id_to_dco = pd.read_csv(\"data/ref_MRV/referentiel_dispositif.csv\",delimiter=';',encoding='ISO-8859-1')\n",
    "df_effets = pd.read_csv(\"data/ref_MRV/referentiel_dispositif_effets_connus.csv\",delimiter=';',encoding='ISO-8859-1')\n",
    "df_dys = pd.read_csv(\"data/ref_MRV/referentiel_dispositif_dysfonctionnement.csv\",delimiter=';',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Netoyage des données :\n",
    "- Elimination de l'effet : PAS D'EFFET NEFASTE DECLARE\n",
    "- Suppression des classes sous représentées (<15 occurences)\n",
    "- Netoyyage des donénes textuelles\n",
    "- Encodage de la classification et des effets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76954\n",
      "76402\n",
      "CPU times: user 31.4 s, sys: 0 ns, total: 31.4 s\n",
      "Wall time: 31.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#On complète les effets vide comme étant sans effets\n",
    "df_declaration_mrv['TYPE_EFFET']  = df_declaration_mrv['TYPE_EFFET'].fillna(\"PAS D'EFFET NEFASTE DECLARE\")\n",
    "df_declaration_mrv['TEF_ID']= df_declaration_mrv['TEF_ID'].fillna('E1213')\n",
    "\n",
    "#on selectionne les colonnes avec des effets\n",
    "df = df_declaration_mrv[['DESCRIPTION_INCIDENT','TYPE_VIGILANCE','LIBELLE_COMMERCIAL',\n",
    "                         'REFERENCE_COMMERCIALE','ETAT_PATIENT','FABRICANT','DCO_ID',\n",
    "                         'ACTION_PATIENT','CLASSIFICATION','TEF_ID']]#[df_declaration_mrv['TEF_ID']!='E1213']\n",
    "# On complète les NaN avec du vide\n",
    "df['ETAT_PATIENT'] = df['ETAT_PATIENT'].fillna(\"\")\n",
    "df['DESCRIPTION_INCIDENT'] = df['DESCRIPTION_INCIDENT'].fillna(\"\")\n",
    "df['LIBELLE_COMMERCIAL'] = df['LIBELLE_COMMERCIAL'].fillna(\"\")\n",
    "df['FABRICANT'] = df['FABRICANT'].fillna(\"\")\n",
    "df[\"REFERENCE_COMMERCIALE\"] = df['REFERENCE_COMMERCIALE'].fillna(\"\")\n",
    "df['TYPE_VIGILANCE'] = df['TYPE_VIGILANCE'].fillna(\"\")\n",
    "df['CLASSIFICATION'] = df['CLASSIFICATION'].fillna('')\n",
    "df['DCO_ID'] = df['DCO_ID'].fillna(-1)\n",
    "#On nettoieles variables textueelles : \n",
    "\n",
    "for col in  ['DESCRIPTION_INCIDENT','LIBELLE_COMMERCIAL','ETAT_PATIENT','FABRICANT','ACTION_PATIENT'] :\n",
    "    df[col] = df[col].map(lambda x: clean_text.preprocess_text(x))\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "n = 15\n",
    "# On filtre pour a voir plus de n observations par classse\n",
    "df = df.groupby(\"TEF_ID\").filter(lambda x: len(x) > n)\n",
    "print(len(df))\n",
    "le_v = LabelEncoder()\n",
    "df.TYPE_VIGILANCE = le_v.fit_transform(df.TYPE_VIGILANCE.values)\n",
    "le = LabelEncoder()\n",
    "df.TEF_ID = le.fit_transform(df.TEF_ID.values)\n",
    "\n",
    "df_m = df.groupby('DESCRIPTION_INCIDENT')['TEF_ID'].apply(list).reset_index(name='multilabels')\n",
    "\n",
    "\n",
    "df_ = pd.merge(df,df_m, on = 'DESCRIPTION_INCIDENT')\n",
    "df_['multilabels'] = df_['multilabels'].apply(np.array)\n",
    "df_['multilabels'] = df_['multilabels'].map(np.unique)\n",
    "\n",
    "#df_.to_csv('Multilabel_dataset.csv')\n",
    "\n",
    "#df_ = df_.drop_duplicates('DESCRIPTION_INCIDENT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Construction du jeu de données d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection des train et test set\n",
    "train_index,test_index = next(GroupShuffleSplit(random_state=1029).split(df_, groups=df_['DESCRIPTION_INCIDENT']))\n",
    "df_train, df_test = df_.iloc[train_index], df_.iloc[test_index]\n",
    "y = df_train.multilabels\n",
    "y_test =df_test.multilabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Encodage multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = MultiLabelBinarizer()\n",
    "y_lb =lb.fit_transform(y) \n",
    "y_test_lb = lb.transform(y_test)\n",
    "X = df_train[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "X_test = df_test[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Construction du pipeline avec une stratégie ONE-VS-REST\n",
    "\n",
    "This strategy, also known as one-vs-all, is implemented in OneVsRestClassifier. The strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only n_classes classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy and is a fair default choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 2.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preprocess = ColumnTransformer(\n",
    "    [('description_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 10000,norm = 'l2'), 'DESCRIPTION_INCIDENT'),\n",
    "     \n",
    "     ('etat_pat_tfidf', TfidfVectorizer(sublinear_tf=True, min_df=3,ngram_range=(1, 1),\n",
    "                                       stop_words=STOP_WORDS,\n",
    "                                       max_features = 10000,norm = 'l2'), 'ETAT_PATIENT'),\n",
    "     \n",
    "     ('fabricant_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 5000,norm = 'l2'), 'FABRICANT'),\n",
    "    \n",
    "    ('classification_enc', TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 100,norm = 'l2'),'CLASSIFICATION')\n",
    "     ],\n",
    "    \n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', OneVsRestClassifier(CalibratedClassifierCV(LinearSVC(class_weight='balanced'),cv=3, method='isotonic'))),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Evaluation du pipeline en cross validation : l'importance de la séparation train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min, sys: 0 ns, total: 26min\n",
      "Wall time: 26min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4733920669007727"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cv = KFold(n_splits=5, random_state=0)\n",
    "result= cross_validate(pipeline, X, y_lb, scoring='f1_samples', cv=cv)\n",
    "result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 25s, sys: 0 ns, total: 30min 25s\n",
      "Wall time: 30min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.903673111438492"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cv = ShuffleSplit(n_splits=5, random_state=0)\n",
    "result= cross_validate(pipeline, X, y_lb, scoring='f1_samples', cv=cv)\n",
    "result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.8488677419996127\n"
     ]
    }
   ],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold, MultilabelStratifiedShuffleSplit\n",
    "mrv =  pd.read_csv('./data_clean/clean_data.csv')\n",
    "mrv = mrv[mrv['TEF_ID']!='E1213']\n",
    "\n",
    "msss = MultilabelStratifiedKFold(n_splits=2, random_state=1029)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "for train_index, test_index in msss.split(mrv['text'], mlb.fit_transform(mrv['TEF_ID'])):\n",
    "    train, test = mrv.loc[train_index],  mrv.loc[test_index]\n",
    "\n",
    "X_train = train[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "y_train = mlb.transform(train['TEF_ID'])\n",
    "\n",
    "X_test = test[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "y_test = mlb.transform(test['TEF_ID'])\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test , y_pred,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2994"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mrv['TEF_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32731, 14)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(mrv['TEF_ID'].values)\n",
    "a = mlb.transform(mrv['TEF_ID'])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.62      0.58      2615\n",
      "           1       0.54      0.62      0.58      2615\n",
      "           2       0.85      0.83      0.84     11388\n",
      "           3       0.94      0.92      0.93     14604\n",
      "           4       0.47      0.56      0.51      2711\n",
      "           5       0.66      0.68      0.67      3758\n",
      "           6       0.49      0.54      0.51      1681\n",
      "           7       0.69      0.74      0.72      2286\n",
      "           8       0.81      0.79      0.80     11223\n",
      "           9       0.61      0.66      0.63      2282\n",
      "          10       0.53      0.57      0.55      1327\n",
      "          11       0.53      0.62      0.57      2306\n",
      "          12       1.00      1.00      1.00     16389\n",
      "          13       1.00      1.00      1.00     16389\n",
      "\n",
      "   micro avg       0.84      0.85      0.85     91574\n",
      "   macro avg       0.69      0.73      0.71     91574\n",
      "weighted avg       0.85      0.85      0.85     91574\n",
      " samples avg       0.86      0.87      0.85     91574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.3 Si on supprimer les doublons ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.5008347403295654\n"
     ]
    }
   ],
   "source": [
    "## Supression des doublons\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "\n",
    "df_s = df_.drop_duplicates('DESCRIPTION_INCIDENT')\n",
    "\n",
    "lb_s = MultiLabelBinarizer()\n",
    "y_s = df_s.multilabels\n",
    "y_s  = lb_s.fit_transform(y_s)\n",
    "\n",
    "df_s = df_s[['FABRICANT','CLASSIFICATION','TYPE_VIGILANCE','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=2, random_state=0)\n",
    "\n",
    "train_index_s,test_index_s = next(mskf.split(df_s,y_s))\n",
    "df_train_s, df_test_s = df_s.iloc[train_index_s], df_s.iloc[test_index_s]\n",
    "y_train_s = y_s[train_index_s]\n",
    "y_test_s =y_s[test_index_s]\n",
    "\n",
    "#lb_s = MultiLabelBinarizer()\n",
    "#y_train_lb_s =lb_s.fit_transform(y_train_s) \n",
    "#y_test_lb_s = lb.transform(y_test_s)\n",
    "X_train_s = df_train_s[['FABRICANT','CLASSIFICATION','TYPE_VIGILANCE','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "X_test_s = df_test_s[['FABRICANT','CLASSIFICATION','TYPE_VIGILANCE','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_s,y_train_s)\n",
    "#y_test_lb = lb.transform(y_test)\n",
    "Y_pred_ovr_s = pipeline.predict(X_test_s)\n",
    "f1 = f1_score(y_test_s , Y_pred_ovr_s,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.22      0.36        18\n",
      "           1       1.00      0.09      0.17        11\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.68      0.36      0.47        36\n",
      "           4       0.40      0.16      0.23        25\n",
      "           5       0.64      0.55      0.59       110\n",
      "           6       0.30      0.18      0.22       119\n",
      "           7       1.00      0.20      0.33         5\n",
      "           8       0.50      0.10      0.16        21\n",
      "           9       0.32      0.12      0.17        50\n",
      "          10       1.00      0.15      0.27        13\n",
      "          11       0.40      0.09      0.14        23\n",
      "          12       0.60      0.14      0.22        22\n",
      "          13       0.40      0.11      0.17        18\n",
      "          14       1.00      0.20      0.33        20\n",
      "          15       1.00      0.08      0.14        13\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       1.00      0.08      0.14        13\n",
      "          18       0.77      0.66      0.71       241\n",
      "          19       0.60      0.19      0.29        31\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.61      0.57      0.59        30\n",
      "          22       0.67      0.63      0.65        95\n",
      "          23       0.33      0.11      0.17         9\n",
      "          24       0.67      0.50      0.57        20\n",
      "          25       0.50      0.10      0.17        10\n",
      "          26       0.46      0.44      0.45        75\n",
      "          27       0.59      0.70      0.64        86\n",
      "          28       0.76      0.80      0.78       142\n",
      "          29       0.81      0.73      0.77        89\n",
      "          30       0.90      0.75      0.82       177\n",
      "          31       0.80      0.62      0.70        26\n",
      "          32       0.57      0.27      0.36        30\n",
      "          33       0.33      0.11      0.17         9\n",
      "          34       0.05      0.04      0.04        28\n",
      "          35       0.61      0.56      0.58       445\n",
      "          36       0.44      0.09      0.15        44\n",
      "          37       0.00      0.00      0.00        24\n",
      "          38       0.33      0.11      0.16        65\n",
      "          39       0.50      0.10      0.17        10\n",
      "          40       0.88      0.56      0.68        27\n",
      "          41       0.00      0.00      0.00         6\n",
      "          42       0.48      0.62      0.54        85\n",
      "          43       0.20      0.19      0.19        27\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       1.00      0.33      0.50         9\n",
      "          46       0.32      0.50      0.39       161\n",
      "          47       0.67      0.25      0.36         8\n",
      "          48       0.00      0.00      0.00         5\n",
      "          49       0.75      0.25      0.38        12\n",
      "          50       0.61      0.50      0.55        22\n",
      "          51       0.94      0.75      0.84        44\n",
      "          52       1.00      0.14      0.25         7\n",
      "          53       0.77      0.78      0.78       171\n",
      "          54       0.79      0.41      0.54        37\n",
      "          55       0.72      0.54      0.62        24\n",
      "          56       0.62      0.36      0.45        14\n",
      "          57       1.00      0.22      0.36         9\n",
      "          58       0.00      0.00      0.00         7\n",
      "          59       0.61      0.42      0.50       151\n",
      "          60       0.58      0.46      0.51       220\n",
      "          61       0.29      0.14      0.19        42\n",
      "          62       0.47      0.19      0.27        42\n",
      "          63       0.73      0.44      0.55        25\n",
      "          64       0.63      0.63      0.63        27\n",
      "          65       0.50      0.09      0.15        11\n",
      "          66       0.00      0.00      0.00        13\n",
      "          67       0.00      0.00      0.00        15\n",
      "          68       0.67      0.19      0.30        21\n",
      "          69       0.00      0.00      0.00         9\n",
      "          70       0.00      0.00      0.00         7\n",
      "          71       0.26      0.16      0.20       149\n",
      "          72       0.71      0.29      0.42        51\n",
      "          73       0.59      0.26      0.36        39\n",
      "          74       0.00      0.00      0.00         5\n",
      "          75       0.75      0.38      0.50         8\n",
      "          76       0.67      0.29      0.40         7\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.80      0.75      0.78       225\n",
      "          79       0.00      0.00      0.00         8\n",
      "          80       0.58      0.37      0.45        19\n",
      "          81       0.78      0.82      0.80       347\n",
      "          82       0.86      0.33      0.48        18\n",
      "          83       0.67      0.25      0.36         8\n",
      "          84       1.00      0.22      0.36         9\n",
      "          85       0.51      0.38      0.43       101\n",
      "          86       0.57      0.58      0.58       668\n",
      "          87       0.15      0.09      0.11        68\n",
      "          88       0.63      0.64      0.64       509\n",
      "          89       0.00      0.00      0.00         4\n",
      "          90       0.68      0.50      0.58        38\n",
      "          91       0.88      0.52      0.65        29\n",
      "          92       1.00      0.12      0.21        17\n",
      "          93       0.80      0.29      0.42        14\n",
      "          94       0.00      0.00      0.00         6\n",
      "          95       0.94      0.85      0.89        20\n",
      "          96       0.50      0.23      0.31       142\n",
      "          97       0.00      0.00      0.00         7\n",
      "          98       0.60      0.38      0.46         8\n",
      "          99       0.00      0.00      0.00         7\n",
      "         100       0.00      0.00      0.00         6\n",
      "         101       0.00      0.00      0.00         6\n",
      "         102       1.00      0.18      0.30        28\n",
      "         103       0.89      0.98      0.93      1085\n",
      "         104       0.67      0.09      0.15        23\n",
      "         105       0.40      0.66      0.50        94\n",
      "         106       0.82      0.58      0.68        79\n",
      "         107       0.33      0.20      0.25        10\n",
      "         108       1.00      0.20      0.33         5\n",
      "         109       0.40      0.57      0.47       569\n",
      "         110       0.70      0.55      0.62        96\n",
      "         111       1.00      0.14      0.25         7\n",
      "         112       0.45      0.34      0.38       125\n",
      "         113       0.60      0.78      0.68       556\n",
      "         114       0.64      0.87      0.74       702\n",
      "         115       0.61      0.67      0.64       241\n",
      "         116       0.58      0.67      0.62       286\n",
      "         117       0.58      0.67      0.62       319\n",
      "         118       0.55      0.35      0.42       138\n",
      "         119       0.51      0.55      0.53       249\n",
      "         120       0.65      0.83      0.73       620\n",
      "         121       0.55      0.26      0.35        66\n",
      "         122       0.33      0.04      0.07        24\n",
      "         123       0.51      0.71      0.60       517\n",
      "         124       0.67      0.24      0.36        33\n",
      "         125       0.67      0.29      0.40        49\n",
      "         126       1.00      0.15      0.27        13\n",
      "         127       0.57      0.36      0.44        66\n",
      "         128       0.33      0.05      0.09        20\n",
      "         129       0.61      0.53      0.57       192\n",
      "         130       0.45      0.45      0.45       184\n",
      "         131       0.57      0.35      0.44       111\n",
      "         132       0.56      0.16      0.25        55\n",
      "         133       0.00      0.00      0.00        12\n",
      "         134       0.54      0.15      0.24        46\n",
      "         135       0.40      0.12      0.18        17\n",
      "         136       0.83      0.48      0.61        31\n",
      "         137       0.00      0.00      0.00         6\n",
      "         138       0.29      0.19      0.23        53\n",
      "         139       0.46      0.36      0.41        83\n",
      "         140       0.62      0.68      0.65       781\n",
      "         141       0.65      0.39      0.48       140\n",
      "         142       1.00      0.50      0.67         8\n",
      "         143       0.49      0.40      0.44       221\n",
      "         144       0.50      0.17      0.26        23\n",
      "         145       0.50      0.11      0.18         9\n",
      "         146       0.77      0.41      0.54        58\n",
      "         147       0.74      0.29      0.42        48\n",
      "         148       1.00      0.23      0.37        35\n",
      "         149       0.64      0.26      0.37        35\n",
      "         150       0.17      0.08      0.11        13\n",
      "         151       0.00      0.00      0.00         4\n",
      "         152       0.00      0.00      0.00         6\n",
      "         153       1.00      0.38      0.55         8\n",
      "         154       0.00      0.00      0.00         7\n",
      "         155       0.00      0.00      0.00         8\n",
      "         156       0.00      0.00      0.00         7\n",
      "         157       0.75      0.23      0.35        13\n",
      "         158       1.00      0.45      0.62        11\n",
      "         159       1.00      0.20      0.33         5\n",
      "         160       0.00      0.00      0.00         7\n",
      "         161       0.00      0.00      0.00         2\n",
      "         162       0.67      0.67      0.67         3\n",
      "         163       0.00      0.00      0.00        11\n",
      "         164       0.57      0.33      0.42        12\n",
      "         165       0.00      0.00      0.00         8\n",
      "         166       1.00      0.50      0.67         6\n",
      "         167       1.00      0.14      0.24        29\n",
      "         168       1.00      0.20      0.33         5\n",
      "         169       0.00      0.00      0.00        11\n",
      "         170       0.25      0.20      0.22        10\n",
      "         171       1.00      0.29      0.44         7\n",
      "\n",
      "   micro avg       0.61      0.59      0.60     14390\n",
      "   macro avg       0.53      0.29      0.34     14390\n",
      "weighted avg       0.61      0.59      0.58     14390\n",
      " samples avg       0.51      0.56      0.50     14390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_s , Y_pred_ovr_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Evaluation du pipeline sur les données de test\n",
    "### Avec le SVM probabilisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.fit(X,y_lb)\n",
    "#y_test_lb = lb.transform(y_test)\n",
    "Y_pred_ovr = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test_lb , Y_pred_ovr,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.5944730016530945\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test_lb , Y_pred_ovr,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.08      0.13        12\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00        38\n",
      "           3       0.94      0.32      0.48        50\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.60      0.09      0.16        64\n",
      "           6       0.91      0.09      0.17       322\n",
      "           7       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00        37\n",
      "           9       0.00      0.00      0.00        36\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       1.00      0.11      0.20        18\n",
      "          12       1.00      0.17      0.29        12\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         7\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.00      0.00      0.00        13\n",
      "          18       0.69      0.46      0.55       229\n",
      "          19       0.86      0.08      0.14        79\n",
      "          20       0.00      0.00      0.00        14\n",
      "          21       0.92      0.79      0.85        57\n",
      "          22       0.74      0.54      0.63       107\n",
      "          23       0.00      0.00      0.00        44\n",
      "          24       0.60      0.19      0.29        16\n",
      "          25       0.00      0.00      0.00        15\n",
      "          26       1.00      0.11      0.19        93\n",
      "          27       0.71      0.19      0.31       103\n",
      "          28       0.91      0.85      0.88       136\n",
      "          29       0.91      0.82      0.87       102\n",
      "          30       0.93      0.38      0.54       215\n",
      "          31       0.52      0.62      0.57        40\n",
      "          32       0.00      0.00      0.00        21\n",
      "          33       0.00      0.00      0.00        17\n",
      "          34       0.00      0.00      0.00        15\n",
      "          35       0.70      0.35      0.46       654\n",
      "          36       0.00      0.00      0.00        61\n",
      "          37       0.00      0.00      0.00        29\n",
      "          38       1.00      0.02      0.03        66\n",
      "          39       0.00      0.00      0.00        23\n",
      "          40       0.87      0.73      0.80        56\n",
      "          41       0.00      0.00      0.00         4\n",
      "          42       0.66      0.13      0.21       164\n",
      "          43       0.00      0.00      0.00        38\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       1.00      1.00      1.00         8\n",
      "          46       1.00      0.02      0.04       153\n",
      "          47       0.00      0.00      0.00         4\n",
      "          48       0.00      0.00      0.00         9\n",
      "          49       0.00      0.00      0.00         8\n",
      "          50       0.81      0.54      0.65        24\n",
      "          51       0.97      0.71      0.82        55\n",
      "          52       0.00      0.00      0.00         8\n",
      "          53       0.80      0.56      0.66       126\n",
      "          54       0.35      0.41      0.38        22\n",
      "          55       1.00      0.28      0.44        39\n",
      "          56       1.00      0.38      0.55        24\n",
      "          57       0.00      0.00      0.00        13\n",
      "          58       0.00      0.00      0.00        10\n",
      "          59       0.84      0.18      0.29       382\n",
      "          60       0.92      0.13      0.23       733\n",
      "          61       0.00      0.00      0.00        51\n",
      "          62       0.00      0.00      0.00        32\n",
      "          63       1.00      0.14      0.25        42\n",
      "          64       0.92      0.40      0.56        55\n",
      "          65       0.00      0.00      0.00        35\n",
      "          66       1.00      0.11      0.19        19\n",
      "          67       1.00      0.31      0.47        39\n",
      "          68       1.00      0.08      0.15        24\n",
      "          69       1.00      0.33      0.50         6\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       1.00      0.02      0.03       127\n",
      "          72       0.67      0.02      0.04        92\n",
      "          73       0.78      0.84      0.81      5956\n",
      "          74       1.00      0.21      0.35        33\n",
      "          75       0.00      0.00      0.00        22\n",
      "          76       0.89      0.89      0.89         9\n",
      "          77       0.00      0.00      0.00         4\n",
      "          78       0.00      0.00      0.00        48\n",
      "          79       0.76      0.28      0.41       190\n",
      "          80       0.00      0.00      0.00         4\n",
      "          81       0.00      0.00      0.00        34\n",
      "          82       0.87      0.75      0.80       267\n",
      "          83       0.00      0.00      0.00        22\n",
      "          84       0.00      0.00      0.00         7\n",
      "          85       0.00      0.00      0.00         4\n",
      "          86       0.90      0.10      0.18        88\n",
      "          87       0.77      0.04      0.08       540\n",
      "          88       0.00      0.00      0.00        78\n",
      "          89       0.75      0.66      0.71      1772\n",
      "          90       0.00      0.00      0.00        48\n",
      "          91       0.53      0.22      0.31        83\n",
      "          92       1.00      0.50      0.67        22\n",
      "          93       0.00      0.00      0.00         5\n",
      "          94       0.80      0.50      0.62         8\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.73      0.67      0.70        12\n",
      "          97       0.00      0.00      0.00        98\n",
      "          98       0.00      0.00      0.00         8\n",
      "          99       1.00      0.60      0.75         5\n",
      "         100       0.00      0.00      0.00        12\n",
      "         101       0.00      0.00      0.00         5\n",
      "         102       0.80      0.25      0.38        16\n",
      "         103       0.00      0.00      0.00        35\n",
      "         104       0.94      0.95      0.95      3444\n",
      "         105       0.00      0.00      0.00        78\n",
      "         106       0.86      0.11      0.19        55\n",
      "         107       0.81      0.66      0.73        53\n",
      "         108       1.00      0.58      0.74        24\n",
      "         109       0.00      0.00      0.00         4\n",
      "         110       0.29      0.00      0.01       559\n",
      "         111       0.89      0.12      0.21        68\n",
      "         112       0.00      0.00      0.00        64\n",
      "         113       0.86      0.14      0.24       475\n",
      "         114       0.72      0.74      0.73      2251\n",
      "         115       0.81      0.95      0.87      2898\n",
      "         116       0.80      0.61      0.70      1284\n",
      "         117       0.81      0.61      0.69      1377\n",
      "         118       0.72      0.65      0.68      1511\n",
      "         119       0.71      0.46      0.55       687\n",
      "         120       0.73      0.57      0.64      1192\n",
      "         121       0.82      0.92      0.87      2712\n",
      "         122       0.97      0.24      0.38       360\n",
      "         123       1.00      0.23      0.37       106\n",
      "         124       0.74      0.78      0.76      2272\n",
      "         125       1.00      0.15      0.26       102\n",
      "         126       0.52      0.39      0.45       113\n",
      "         127       1.00      0.06      0.11        71\n",
      "         128       0.73      0.28      0.41       288\n",
      "         129       0.00      0.00      0.00       173\n",
      "         130       0.77      0.51      0.62       874\n",
      "         131       0.71      0.33      0.45       877\n",
      "         132       0.98      0.17      0.29       726\n",
      "         133       0.80      0.37      0.50       260\n",
      "         134       0.00      0.00      0.00        50\n",
      "         135       1.00      0.04      0.08       302\n",
      "         136       0.62      0.07      0.13        70\n",
      "         137       0.92      0.73      0.81        30\n",
      "         138       0.00      0.00      0.00        10\n",
      "         139       1.00      0.13      0.23        70\n",
      "         140       0.64      0.38      0.48        90\n",
      "         141       0.80      0.24      0.37       913\n",
      "         142       0.40      0.04      0.07       159\n",
      "         143       1.00      1.00      1.00        30\n",
      "         144       0.91      0.04      0.08       239\n",
      "         145       0.00      0.00      0.00        22\n",
      "         146       0.00      0.00      0.00         5\n",
      "         147       0.45      0.24      0.32       120\n",
      "         148       0.73      0.34      0.46        71\n",
      "         149       0.70      0.12      0.21        57\n",
      "         150       0.00      0.00      0.00        40\n",
      "         151       0.00      0.00      0.00        25\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.00      0.00      0.00        23\n",
      "         154       1.00      0.60      0.75        15\n",
      "         155       0.50      1.00      0.67         4\n",
      "         156       0.00      0.00      0.00        10\n",
      "         157       0.00      0.00      0.00        11\n",
      "         158       0.00      0.00      0.00        20\n",
      "         159       1.00      1.00      1.00         6\n",
      "         160       1.00      0.50      0.67         8\n",
      "         161       0.00      0.00      0.00        12\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         8\n",
      "         164       0.00      0.00      0.00        14\n",
      "         165       0.00      0.00      0.00        13\n",
      "         166       0.00      0.00      0.00         4\n",
      "         167       0.00      0.00      0.00        17\n",
      "         168       0.00      0.00      0.00        20\n",
      "         169       1.00      1.00      1.00         3\n",
      "         170       0.00      0.00      0.00        10\n",
      "         171       0.00      0.00      0.00        20\n",
      "         172       1.00      0.73      0.84        22\n",
      "\n",
      "   micro avg       0.79      0.60      0.68     42151\n",
      "   macro avg       0.46      0.23      0.27     42151\n",
      "weighted avg       0.76      0.60      0.62     42151\n",
      " samples avg       0.63      0.59      0.59     42151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_lb , Y_pred_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Encoder_effets.sav']"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'Encoder_effets.sav'\n",
    "joblib.dump(le, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_e = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = X_test[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']].fillna('').loc[1:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_e.predict_proba(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(x:int,dico,col)-> str :\n",
    "    \"\"\"\n",
    "    Renvoie le nom du dispositif à partir du numéro précisé dans le reférentiel\n",
    "    si le numéro n'existe pas, alors il ne renvoi rien\n",
    "    \"\"\"\n",
    "    try :\n",
    "        return (df_effets[df_effets['TEF_ID']==int(x[1:])]['TYPE_EFFET'].iloc[0])\n",
    "    except :\n",
    "        return(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_e.predict_proba(X_test.loc[1:1])\n",
    "df_r = pd.DataFrame(pred[0])\n",
    "df_r[\"class\"] = le.inverse_transform(df_r.index.values)\n",
    "df_r['class_name'] = df_r['class'].apply(lambda x :  get_name(x))\n",
    "df_r['proba'] = df_r[0]\n",
    "df_r = df_r.drop(0,axis=1)\n",
    "df_r = df_r.sort_values('proba',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_name</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>E1232</td>\n",
       "      <td>REACTION ALLERGIQUE</td>\n",
       "      <td>0.559276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>E1213</td>\n",
       "      <td>PAS D'EFFET NEFASTE DECLARE</td>\n",
       "      <td>0.444602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E1111</td>\n",
       "      <td>ALLERGIE</td>\n",
       "      <td>0.106148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>E1467</td>\n",
       "      <td>SF DERMATO</td>\n",
       "      <td>0.099553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>E1476</td>\n",
       "      <td>PRURIT</td>\n",
       "      <td>0.097375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>E1449</td>\n",
       "      <td>SF CARDIO</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>E1146</td>\n",
       "      <td>DISSECTION</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>E1470</td>\n",
       "      <td>SC DIGESTIF</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>E1218</td>\n",
       "      <td>PERTE DE CHANCE PROCREATION</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>E1219</td>\n",
       "      <td>PERTE DE CHEVEUX</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                   class_name     proba\n",
       "82   E1232          REACTION ALLERGIQUE  0.559276\n",
       "73   E1213  PAS D'EFFET NEFASTE DECLARE  0.444602\n",
       "6    E1111                     ALLERGIE  0.106148\n",
       "131  E1467                   SF DERMATO  0.099553\n",
       "140  E1476                       PRURIT  0.097375\n",
       "..     ...                          ...       ...\n",
       "119  E1449                    SF CARDIO  0.000000\n",
       "33   E1146                   DISSECTION  0.000000\n",
       "134  E1470                  SC DIGESTIF  0.000000\n",
       "77   E1218  PERTE DE CHANCE PROCREATION  0.000000\n",
       "78   E1219             PERTE DE CHEVEUX  0.000000\n",
       "\n",
       "[173 rows x 3 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans le SVM probabilisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.631352294551771\n",
      "CPU times: user 2min 55s, sys: 0 ns, total: 2min 55s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline.fit(X,y_lb)\n",
    "Y_pred_ovr = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test_lb , Y_pred_ovr,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.572080991241877\n"
     ]
    }
   ],
   "source": [
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.08      0.14        12\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00        38\n",
      "           3       0.96      0.50      0.66        50\n",
      "           4       1.00      0.07      0.12        15\n",
      "           5       0.43      0.50      0.46        64\n",
      "           6       0.60      0.30      0.40       322\n",
      "           7       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00        37\n",
      "           9       0.38      0.22      0.28        36\n",
      "          10       1.00      0.67      0.80         6\n",
      "          11       1.00      0.11      0.20        18\n",
      "          12       0.57      0.33      0.42        12\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.50      0.29      0.36         7\n",
      "          16       0.00      0.00      0.00         5\n",
      "          17       0.00      0.00      0.00        13\n",
      "          18       0.70      0.46      0.55       229\n",
      "          19       0.46      0.08      0.13        79\n",
      "          20       0.00      0.00      0.00        14\n",
      "          21       0.89      0.72      0.80        57\n",
      "          22       0.62      0.54      0.58       107\n",
      "          23       0.91      0.73      0.81        44\n",
      "          24       0.50      0.31      0.38        16\n",
      "          25       0.67      0.13      0.22        15\n",
      "          26       0.39      0.49      0.43        93\n",
      "          27       0.47      0.33      0.39       103\n",
      "          28       0.64      0.87      0.74       136\n",
      "          29       0.86      0.86      0.86       102\n",
      "          30       0.83      0.46      0.59       215\n",
      "          31       0.50      0.57      0.53        40\n",
      "          32       0.78      0.33      0.47        21\n",
      "          33       0.00      0.00      0.00        17\n",
      "          34       0.00      0.00      0.00        15\n",
      "          35       0.64      0.45      0.53       654\n",
      "          36       0.46      0.10      0.16        61\n",
      "          37       0.00      0.00      0.00        29\n",
      "          38       0.47      0.11      0.17        66\n",
      "          39       0.25      0.09      0.13        23\n",
      "          40       0.95      0.71      0.82        56\n",
      "          41       1.00      0.50      0.67         4\n",
      "          42       0.57      0.65      0.60       164\n",
      "          43       0.28      0.13      0.18        38\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       1.00      0.88      0.93         8\n",
      "          46       0.26      0.50      0.34       153\n",
      "          47       0.00      0.00      0.00         4\n",
      "          48       0.00      0.00      0.00         9\n",
      "          49       0.00      0.00      0.00         8\n",
      "          50       0.76      0.54      0.63        24\n",
      "          51       0.97      0.53      0.68        55\n",
      "          52       0.00      0.00      0.00         8\n",
      "          53       0.75      0.61      0.68       126\n",
      "          54       0.42      0.59      0.49        22\n",
      "          55       1.00      0.33      0.50        39\n",
      "          56       1.00      0.46      0.63        24\n",
      "          57       0.00      0.00      0.00        13\n",
      "          58       0.00      0.00      0.00        10\n",
      "          59       0.77      0.30      0.44       382\n",
      "          60       0.76      0.47      0.58       733\n",
      "          61       0.22      0.08      0.12        51\n",
      "          62       0.25      0.12      0.17        32\n",
      "          63       0.86      0.14      0.24        42\n",
      "          64       0.90      0.51      0.65        55\n",
      "          65       0.00      0.00      0.00        35\n",
      "          66       0.00      0.00      0.00        19\n",
      "          67       1.00      0.31      0.47        39\n",
      "          68       0.23      0.42      0.29        24\n",
      "          69       1.00      0.33      0.50         6\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.16      0.10      0.12       127\n",
      "          72       0.92      0.51      0.66        92\n",
      "          73       0.75      0.85      0.80      5956\n",
      "          74       1.00      0.27      0.43        33\n",
      "          75       0.00      0.00      0.00        22\n",
      "          76       0.89      0.89      0.89         9\n",
      "          77       0.00      0.00      0.00         4\n",
      "          78       0.00      0.00      0.00        48\n",
      "          79       0.62      0.43      0.50       190\n",
      "          80       0.00      0.00      0.00         4\n",
      "          81       0.00      0.00      0.00        34\n",
      "          82       0.85      0.77      0.81       267\n",
      "          83       0.50      0.09      0.15        22\n",
      "          84       1.00      0.43      0.60         7\n",
      "          85       0.00      0.00      0.00         4\n",
      "          86       0.63      0.38      0.47        88\n",
      "          87       0.32      0.32      0.32       540\n",
      "          88       0.38      0.08      0.13        78\n",
      "          89       0.79      0.60      0.68      1772\n",
      "          90       0.00      0.00      0.00        48\n",
      "          91       0.58      0.27      0.36        83\n",
      "          92       1.00      0.50      0.67        22\n",
      "          93       0.00      0.00      0.00         5\n",
      "          94       1.00      0.38      0.55         8\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.67      0.50      0.57        12\n",
      "          97       0.39      0.19      0.26        98\n",
      "          98       0.00      0.00      0.00         8\n",
      "          99       1.00      0.60      0.75         5\n",
      "         100       0.00      0.00      0.00        12\n",
      "         101       0.00      0.00      0.00         5\n",
      "         102       0.80      0.25      0.38        16\n",
      "         103       0.06      0.09      0.07        35\n",
      "         104       0.96      0.94      0.95      3444\n",
      "         105       0.67      0.03      0.05        78\n",
      "         106       0.30      0.62      0.40        55\n",
      "         107       0.85      0.66      0.74        53\n",
      "         108       1.00      0.67      0.80        24\n",
      "         109       0.00      0.00      0.00         4\n",
      "         110       0.35      0.54      0.43       559\n",
      "         111       0.30      0.41      0.35        68\n",
      "         112       1.00      0.94      0.97        64\n",
      "         113       0.79      0.34      0.47       475\n",
      "         114       0.77      0.69      0.73      2251\n",
      "         115       0.84      0.80      0.82      2898\n",
      "         116       0.81      0.52      0.64      1284\n",
      "         117       0.85      0.58      0.69      1377\n",
      "         118       0.78      0.62      0.69      1511\n",
      "         119       0.76      0.45      0.56       687\n",
      "         120       0.73      0.50      0.59      1192\n",
      "         121       0.88      0.77      0.82      2712\n",
      "         122       0.76      0.40      0.52       360\n",
      "         123       1.00      0.23      0.37       106\n",
      "         124       0.80      0.66      0.72      2272\n",
      "         125       0.00      0.00      0.00       102\n",
      "         126       0.70      0.31      0.43       113\n",
      "         127       1.00      0.06      0.11        71\n",
      "         128       0.61      0.18      0.28       288\n",
      "         129       0.79      0.13      0.22       173\n",
      "         130       0.76      0.47      0.58       874\n",
      "         131       0.67      0.45      0.54       877\n",
      "         132       0.79      0.30      0.43       726\n",
      "         133       0.79      0.37      0.50       260\n",
      "         134       1.00      0.18      0.31        50\n",
      "         135       0.77      0.19      0.31       302\n",
      "         136       0.73      0.11      0.20        70\n",
      "         137       0.49      0.87      0.63        30\n",
      "         138       0.00      0.00      0.00        10\n",
      "         139       0.61      0.24      0.35        70\n",
      "         140       0.65      0.40      0.50        90\n",
      "         141       0.59      0.63      0.61       913\n",
      "         142       0.55      0.30      0.39       159\n",
      "         143       1.00      0.57      0.72        30\n",
      "         144       0.34      0.25      0.29       239\n",
      "         145       0.86      0.27      0.41        22\n",
      "         146       0.00      0.00      0.00         5\n",
      "         147       0.35      0.16      0.22       120\n",
      "         148       0.75      0.34      0.47        71\n",
      "         149       0.73      0.14      0.24        57\n",
      "         150       0.80      0.20      0.32        40\n",
      "         151       0.00      0.00      0.00        25\n",
      "         152       0.00      0.00      0.00         1\n",
      "         153       0.00      0.00      0.00        23\n",
      "         154       0.00      0.00      0.00        15\n",
      "         155       0.50      1.00      0.67         4\n",
      "         156       0.33      0.20      0.25        10\n",
      "         157       0.00      0.00      0.00        11\n",
      "         158       0.00      0.00      0.00        20\n",
      "         159       1.00      1.00      1.00         6\n",
      "         160       1.00      0.50      0.67         8\n",
      "         161       0.00      0.00      0.00        12\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       0.00      0.00      0.00         8\n",
      "         164       0.00      0.00      0.00        14\n",
      "         165       0.00      0.00      0.00        13\n",
      "         166       0.00      0.00      0.00         4\n",
      "         167       0.06      0.06      0.06        17\n",
      "         168       0.00      0.00      0.00        20\n",
      "         169       1.00      1.00      1.00         3\n",
      "         170       0.00      0.00      0.00        10\n",
      "         171       0.00      0.00      0.00        20\n",
      "         172       1.00      0.73      0.84        22\n",
      "\n",
      "   micro avg       0.75      0.61      0.68     42151\n",
      "   macro avg       0.48      0.30      0.34     42151\n",
      "weighted avg       0.75      0.61      0.66     42151\n",
      " samples avg       0.67      0.65      0.63     42151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_lb , Y_pred_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "               precision    recall  f1-score   support   \n",
    "samples avg       0.62      0.66      0.62     23357\n",
    "(sans doublon)\n",
    "Samples avg      0.67      0.65      0.63     42151\n",
    "(avec doublon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commentaire : \n",
    "#### **Les principaux enseignements sont les suivants :**\n",
    "1)  L'approche multilabels est pertinente : Nous obtenons enfin un score \"correct\" 0.55 qui se rapproche de la précision à 4 du model simple Label. Ce qui est assez cohérent car il y a en moyenne 4 classes par evénement. Cela signifie que nous avons simplement tirer partie de la métrique mais que notre modèle n'apprend pas mieux... Dommage ! C'est en fait assez logique car le SVM en multiclasse applique déja une stratégie One vs REST\n",
    "\n",
    "2)  Elle est pertinente.. Mais moins qu'on pourrait le penser avec la shuffle validation : comme le montre la différence entre le Kfold et le ShuffleSplit, les doublons joue un rôle important. Cette différence s'explique apr le fait que les doublons joue un rôle important dans notre base de données car ils ne sont pas exactement des \"doublons\". De plus ils nous permettent, de tenir compte de la proportion des classes dans notre evaluation.\n",
    "\n",
    "3) Cette approche multilabels combinée avec la probalisation du SVM est couteuse en temps de construction de modèle et nous devrons le prendre en compte dans notre approche de finetuning.\n",
    "\n",
    "#### **Les pistes d'améliorations sont :**\n",
    "\n",
    "1) Finetuner le modèle pour vérifier que notre jeu de paramètre n'est pas un cas particulier de performances \n",
    "\n",
    "\n",
    "2) Essayer une approche\n",
    "- MultiOutputClassifier\n",
    "- ClassifierChain https://scikit-learn.org/stable/auto_examples/multioutput/plot_classifier_chain_yeast.html\n",
    "\n",
    "3) Essayer le one-sht learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Optune et la marge de progression du modèle\n",
    "Pour le finetunning, nous enlevons la probabilisation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "\n",
    "def objective(trial):    \n",
    "    \n",
    "    train_index,test_index = next(GroupShuffleSplit(random_state=1029).split(X, groups=X['DESCRIPTION_INCIDENT']))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    y_train_lb = lb.transform(y_train)\n",
    "    y_test_lb = lb.transform(y_test)\n",
    "    \n",
    "    #Etat Patient\n",
    "    #vect__etat_pat_tfidf__analyzer = trial.suggest_categorical('vect__etat_pat_tfidf__analyzer', ['word', 'char', 'char_wb']) \n",
    "    vect__etat_pat_tfidf__max_features = trial.suggest_int('vect__etat_pat_tfidf__max_features', 500, 20_000)\n",
    "    vect__etat_pat_tfidf__min_df =  trial.suggest_int('vect__etat_pat_tfidf__min_df', 1,5)\n",
    "    vect__etat_pat_tfidf__norm = trial.suggest_categorical('vect__etat_pat_tfidf__norm', ('l1', 'l2'))\n",
    "    #Description\n",
    "    #vect__description_tfidf__analyzer = trial.suggest_categorical('vect__description_tfidf__analyzer', ['word', 'char', 'char_wb']) \n",
    "    vect__description_tfidf__max_features = trial.suggest_int('vect__description_tfidf__max_features', 1500, 60_000)\n",
    "    vect__description_tfidf__min_df =  trial.suggest_int('vect__description_tfidf__min_df', 1,5)\n",
    "    vect__description_tfidf__norm = trial.suggest_categorical('vect__description_tfidf__norm', ('l1', 'l2'))\n",
    "    #Fabricant\n",
    "    vect__fabricant_tfidf__analyzer = trial.suggest_categorical('vect__fabricant_tfidf__analyzer', ['word', 'char', 'char_wb']) \n",
    "    vect__fabricant_tfidf__max_features = trial.suggest_int('vect__fabricant_tfidf__max_features', 500, 10_000)\n",
    "    vect__fabricant_tfidf__min_df =  trial.suggest_int('vect__fabricant_tfidf__min_df', 1,5)\n",
    "    vect__fabricant_tfidf__norm = trial.suggest_categorical('vect__fabricant_tfidf__norm', ('l1', 'l2'))\n",
    "    #action patient\n",
    "    \n",
    "    #Classification\n",
    "    vect__classification_enc__analyzer = trial.suggest_categorical('vect__classification_enc__analyzer', ['word', 'char', 'char_wb']) \n",
    "    vect__classification_enc__max_features = trial.suggest_int('vect__classification_enc__max_features', 500, 5000)\n",
    "    vect__classification_enc__min_df =  trial.suggest_int('vect__classification_enc__min_df', 1,5)\n",
    "    vect__classification_enc__norm = trial.suggest_categorical('vect__classification_enc__norm', ('l1', 'l2'))\n",
    "    \n",
    "    #clf__C =trial.suggest_loguniform('svr_c', 1e-5, 1e5)\n",
    "    \n",
    "\n",
    "    \n",
    "    params = {\n",
    "        #'vect__etat_pat_tfidf__analyzer':vect__etat_pat_tfidf__analyzer,\n",
    "        'vect__etat_pat_tfidf__max_features': vect__etat_pat_tfidf__max_features,\n",
    "        'vect__etat_pat_tfidf__min_df':vect__etat_pat_tfidf__min_df,\n",
    "        'vect__etat_pat_tfidf__norm':vect__etat_pat_tfidf__norm,\n",
    "        \n",
    "        #'vect__description_tfidf__analyzer':vect__description_tfidf__analyzer,\n",
    "        'vect__description_tfidf__max_features': vect__description_tfidf__max_features,\n",
    "        'vect__description_tfidf__min_df':vect__description_tfidf__min_df,\n",
    "        'vect__description_tfidf__norm':vect__description_tfidf__norm,\n",
    "        \n",
    "        'vect__fabricant_tfidf__analyzer':vect__fabricant_tfidf__analyzer,\n",
    "        'vect__fabricant_tfidf__max_features': vect__fabricant_tfidf__max_features,\n",
    "        'vect__fabricant_tfidf__min_df':vect__fabricant_tfidf__min_df,\n",
    "        'vect__fabricant_tfidf__norm':vect__fabricant_tfidf__norm,\n",
    "        \n",
    "        \n",
    "        'vect__classification_enc__analyzer':vect__classification_enc__analyzer,\n",
    "        'vect__classification_enc__max_features': vect__classification_enc__max_features,\n",
    "        'vect__classification_enc__min_df':vect__classification_enc__min_df,\n",
    "        'vect__classification_enc__norm':vect__classification_enc__norm,\n",
    "        \n",
    "        #'clf__C':clf__C\n",
    "    }\n",
    "    \n",
    "    pipeline.set_params(**params)\n",
    "    pipeline.fit(X_train,y_train_lb)\n",
    "    Y_pred_ovr = pipeline.predict(X_test)\n",
    "    score = f1_score(y_test_lb , Y_pred_ovr,average='samples')\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-06-10 18:43:30,547]\u001b[0m Finished trial#0 with value: 0.5268400357946823 with parameters: {'vect__etat_pat_tfidf__max_features': 9211, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 34910, 'vect__description_tfidf__min_df': 4, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'char_wb', 'vect__fabricant_tfidf__max_features': 7623, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'char', 'vect__classification_enc__max_features': 3078, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#0 with value: 0.5268400357946823.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 18:45:45,297]\u001b[0m Finished trial#1 with value: 0.5314562900155817 with parameters: {'vect__etat_pat_tfidf__max_features': 2892, 'vect__etat_pat_tfidf__min_df': 1, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 36279, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 4229, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'char_wb', 'vect__classification_enc__max_features': 665, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l2'}. Best is trial#1 with value: 0.5314562900155817.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 18:47:22,640]\u001b[0m Finished trial#2 with value: 0.5603574460513823 with parameters: {'vect__etat_pat_tfidf__max_features': 16840, 'vect__etat_pat_tfidf__min_df': 2, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 9083, 'vect__description_tfidf__min_df': 5, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 7423, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'char_wb', 'vect__classification_enc__max_features': 4127, 'vect__classification_enc__min_df': 2, 'vect__classification_enc__norm': 'l1'}. Best is trial#2 with value: 0.5603574460513823.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 18:50:27,843]\u001b[0m Finished trial#3 with value: 0.5267247097317531 with parameters: {'vect__etat_pat_tfidf__max_features': 11601, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 32520, 'vect__description_tfidf__min_df': 4, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'char_wb', 'vect__fabricant_tfidf__max_features': 8702, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'char', 'vect__classification_enc__max_features': 845, 'vect__classification_enc__min_df': 1, 'vect__classification_enc__norm': 'l2'}. Best is trial#2 with value: 0.5603574460513823.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 18:53:24,559]\u001b[0m Finished trial#4 with value: 0.5299157604790384 with parameters: {'vect__etat_pat_tfidf__max_features': 6628, 'vect__etat_pat_tfidf__min_df': 1, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 8463, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'char', 'vect__fabricant_tfidf__max_features': 6522, 'vect__fabricant_tfidf__min_df': 5, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'char', 'vect__classification_enc__max_features': 3901, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l2'}. Best is trial#2 with value: 0.5603574460513823.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 18:55:31,384]\u001b[0m Finished trial#5 with value: 0.5569012836602969 with parameters: {'vect__etat_pat_tfidf__max_features': 13070, 'vect__etat_pat_tfidf__min_df': 2, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 52351, 'vect__description_tfidf__min_df': 5, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'char_wb', 'vect__fabricant_tfidf__max_features': 8426, 'vect__fabricant_tfidf__min_df': 1, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'char_wb', 'vect__classification_enc__max_features': 4600, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l2'}. Best is trial#2 with value: 0.5603574460513823.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 18:57:37,051]\u001b[0m Finished trial#6 with value: 0.5564728834793602 with parameters: {'vect__etat_pat_tfidf__max_features': 10984, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l1', 'vect__description_tfidf__max_features': 41634, 'vect__description_tfidf__min_df': 4, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'char_wb', 'vect__fabricant_tfidf__max_features': 4727, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'char_wb', 'vect__classification_enc__max_features': 4443, 'vect__classification_enc__min_df': 2, 'vect__classification_enc__norm': 'l2'}. Best is trial#2 with value: 0.5603574460513823.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 18:59:19,849]\u001b[0m Finished trial#7 with value: 0.5585375018330276 with parameters: {'vect__etat_pat_tfidf__max_features': 3333, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l1', 'vect__description_tfidf__max_features': 40931, 'vect__description_tfidf__min_df': 5, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 5326, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'char_wb', 'vect__classification_enc__max_features': 4529, 'vect__classification_enc__min_df': 1, 'vect__classification_enc__norm': 'l2'}. Best is trial#2 with value: 0.5603574460513823.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:02:25,653]\u001b[0m Finished trial#8 with value: 0.5539287245771842 with parameters: {'vect__etat_pat_tfidf__max_features': 6169, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l1', 'vect__description_tfidf__max_features': 38722, 'vect__description_tfidf__min_df': 5, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1261, 'vect__fabricant_tfidf__min_df': 1, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'char_wb', 'vect__classification_enc__max_features': 1984, 'vect__classification_enc__min_df': 1, 'vect__classification_enc__norm': 'l2'}. Best is trial#2 with value: 0.5603574460513823.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:04:39,162]\u001b[0m Finished trial#9 with value: 0.5284500436934877 with parameters: {'vect__etat_pat_tfidf__max_features': 1694, 'vect__etat_pat_tfidf__min_df': 2, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 35899, 'vect__description_tfidf__min_df': 4, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'char', 'vect__fabricant_tfidf__max_features': 7398, 'vect__fabricant_tfidf__min_df': 1, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 977, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#2 with value: 0.5603574460513823.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:05:42,375]\u001b[0m Finished trial#10 with value: 0.5616248167403621 with parameters: {'vect__etat_pat_tfidf__max_features': 19534, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 3707, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 9998, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 3319, 'vect__classification_enc__min_df': 2, 'vect__classification_enc__norm': 'l1'}. Best is trial#10 with value: 0.5616248167403621.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:06:36,461]\u001b[0m Finished trial#11 with value: 0.5547480035633864 with parameters: {'vect__etat_pat_tfidf__max_features': 19934, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 1661, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 9382, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 3281, 'vect__classification_enc__min_df': 2, 'vect__classification_enc__norm': 'l1'}. Best is trial#10 with value: 0.5616248167403621.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:07:53,902]\u001b[0m Finished trial#12 with value: 0.5625030459023882 with parameters: {'vect__etat_pat_tfidf__max_features': 18538, 'vect__etat_pat_tfidf__min_df': 2, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 17103, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 9738, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2228, 'vect__classification_enc__min_df': 2, 'vect__classification_enc__norm': 'l1'}. Best is trial#12 with value: 0.5625030459023882.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:09:11,039]\u001b[0m Finished trial#13 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 19700, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 20401, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 9992, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2062, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:10:29,956]\u001b[0m Finished trial#14 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 15961, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 19810, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 9981, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1805, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:11:48,780]\u001b[0m Finished trial#15 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 15443, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 22363, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 2674, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1599, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:13:32,877]\u001b[0m Finished trial#16 with value: 0.5507648051161407 with parameters: {'vect__etat_pat_tfidf__max_features': 14546, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l1', 'vect__description_tfidf__max_features': 22697, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'char', 'vect__fabricant_tfidf__max_features': 9855, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1412, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:14:48,957]\u001b[0m Finished trial#17 with value: 0.5621574514895398 with parameters: {'vect__etat_pat_tfidf__max_features': 17367, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 17853, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 6362, 'vect__fabricant_tfidf__min_df': 5, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2277, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:16:02,969]\u001b[0m Finished trial#18 with value: 0.5600194593911404 with parameters: {'vect__etat_pat_tfidf__max_features': 15240, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 12668, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 2071, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1473, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:17:18,077]\u001b[0m Finished trial#19 with value: 0.5631711814525451 with parameters: {'vect__etat_pat_tfidf__max_features': 17264, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 24413, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 8661, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2771, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:19:02,654]\u001b[0m Finished trial#20 with value: 0.5507648051161407 with parameters: {'vect__etat_pat_tfidf__max_features': 13231, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l1', 'vect__description_tfidf__max_features': 26600, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'char', 'vect__fabricant_tfidf__max_features': 9156, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2531, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:20:25,457]\u001b[0m Finished trial#21 with value: 0.5637037728658226 with parameters: {'vect__etat_pat_tfidf__max_features': 15662, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 18953, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3302, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1601, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:21:45,874]\u001b[0m Finished trial#22 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 18689, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 26995, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 2800, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1731, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:23:06,074]\u001b[0m Finished trial#23 with value: 0.560468554687617 with parameters: {'vect__etat_pat_tfidf__max_features': 13627, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 29893, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 2671, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1221, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:24:24,495]\u001b[0m Finished trial#24 with value: 0.5625815278742254 with parameters: {'vect__etat_pat_tfidf__max_features': 19965, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 29197, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 954, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1914, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:25:44,314]\u001b[0m Finished trial#25 with value: 0.5614203425051959 with parameters: {'vect__etat_pat_tfidf__max_features': 16134, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 13384, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3600, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1725, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:27:05,526]\u001b[0m Finished trial#26 with value: 0.5602848049244039 with parameters: {'vect__etat_pat_tfidf__max_features': 18467, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 47806, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1844, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 540, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:28:44,792]\u001b[0m Finished trial#27 with value: 0.5629820218499538 with parameters: {'vect__etat_pat_tfidf__max_features': 18280, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 23995, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 2821, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'char', 'vect__classification_enc__max_features': 1165, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:30:02,846]\u001b[0m Finished trial#28 with value: 0.5618030107457465 with parameters: {'vect__etat_pat_tfidf__max_features': 19735, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 13785, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 5515, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2276, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:31:59,975]\u001b[0m Finished trial#29 with value: 0.5527151973877178 with parameters: {'vect__etat_pat_tfidf__max_features': 8598, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 27557, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'char_wb', 'vect__fabricant_tfidf__max_features': 3999, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'char', 'vect__classification_enc__max_features': 2777, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:33:20,611]\u001b[0m Finished trial#30 with value: 0.5630829423908487 with parameters: {'vect__etat_pat_tfidf__max_features': 9568, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 21254, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 6152, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1983, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:34:39,456]\u001b[0m Finished trial#31 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 14525, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 20589, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1759, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1697, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:35:57,352]\u001b[0m Finished trial#32 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 16687, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 33658, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 2596, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2550, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:37:13,015]\u001b[0m Finished trial#33 with value: 0.5622109268207929 with parameters: {'vect__etat_pat_tfidf__max_features': 14367, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 32696, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1706, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2524, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:38:31,073]\u001b[0m Finished trial#34 with value: 0.5627165840681763 with parameters: {'vect__etat_pat_tfidf__max_features': 17956, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 33125, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 823, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2543, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:40:17,140]\u001b[0m Finished trial#35 with value: 0.5244441456731861 with parameters: {'vect__etat_pat_tfidf__max_features': 11933, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 44922, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 2632, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 3026, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:42:14,014]\u001b[0m Finished trial#36 with value: 0.5526418824224153 with parameters: {'vect__etat_pat_tfidf__max_features': 16759, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 27947, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'char_wb', 'vect__fabricant_tfidf__max_features': 2255, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'char', 'vect__classification_enc__max_features': 1265, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:43:38,815]\u001b[0m Finished trial#37 with value: 0.5625165858425152 with parameters: {'vect__etat_pat_tfidf__max_features': 18939, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 36708, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 4441, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2107, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:46:27,882]\u001b[0m Finished trial#38 with value: 0.5295970164147575 with parameters: {'vect__etat_pat_tfidf__max_features': 12370, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 59802, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'char', 'vect__fabricant_tfidf__max_features': 591, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 851, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:48:24,432]\u001b[0m Finished trial#39 with value: 0.5557511208125576 with parameters: {'vect__etat_pat_tfidf__max_features': 14935, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l1', 'vect__description_tfidf__max_features': 24849, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3193, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'char_wb', 'vect__classification_enc__max_features': 3606, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l2'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:50:25,137]\u001b[0m Finished trial#40 with value: 0.5526290901845319 with parameters: {'vect__etat_pat_tfidf__max_features': 16429, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 16019, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'char_wb', 'vect__fabricant_tfidf__max_features': 3622, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'char', 'vect__classification_enc__max_features': 1651, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:51:47,426]\u001b[0m Finished trial#41 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 17269, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 21425, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 8127, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1847, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:53:11,867]\u001b[0m Finished trial#42 with value: 0.5626433174632419 with parameters: {'vect__etat_pat_tfidf__max_features': 15755, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 10601, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 7849, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1774, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:54:31,973]\u001b[0m Finished trial#43 with value: 0.5625815278742254 with parameters: {'vect__etat_pat_tfidf__max_features': 13946, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 31557, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1490, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1485, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:55:47,489]\u001b[0m Finished trial#44 with value: 0.5633276548010223 with parameters: {'vect__etat_pat_tfidf__max_features': 12547, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 7038, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 2380, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 908, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l2'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:58:10,247]\u001b[0m Finished trial#45 with value: 0.5242877873687336 with parameters: {'vect__etat_pat_tfidf__max_features': 10881, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 25937, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 4893, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'char_wb', 'vect__classification_enc__max_features': 1053, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 19:59:29,563]\u001b[0m Finished trial#46 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 16386, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 35344, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1163, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1341, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:00:52,028]\u001b[0m Finished trial#47 with value: 0.5629627857564123 with parameters: {'vect__etat_pat_tfidf__max_features': 17416, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 22149, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 9210, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1349, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:02:23,812]\u001b[0m Finished trial#48 with value: 0.5617932964252331 with parameters: {'vect__etat_pat_tfidf__max_features': 18946, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 39633, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1079, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 624, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l2'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:04:10,436]\u001b[0m Finished trial#49 with value: 0.5501404679272891 with parameters: {'vect__etat_pat_tfidf__max_features': 17728, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l1', 'vect__description_tfidf__max_features': 16061, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'char', 'vect__fabricant_tfidf__max_features': 8073, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1834, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:05:54,731]\u001b[0m Finished trial#50 with value: 0.561836055066643 with parameters: {'vect__etat_pat_tfidf__max_features': 15249, 'vect__etat_pat_tfidf__min_df': 2, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 35380, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 6977, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'char_wb', 'vect__classification_enc__max_features': 2412, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:07:16,186]\u001b[0m Finished trial#51 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 16782, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 42672, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1391, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1545, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:08:38,416]\u001b[0m Finished trial#52 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 14303, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 43568, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3047, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1580, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:10:01,755]\u001b[0m Finished trial#53 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 14360, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 43486, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3148, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2143, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:11:27,122]\u001b[0m Finished trial#54 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 19569, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 52122, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3719, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2126, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:12:50,123]\u001b[0m Finished trial#55 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 17071, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 51056, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 4089, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 3029, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:14:15,341]\u001b[0m Finished trial#56 with value: 0.5607871182171347 with parameters: {'vect__etat_pat_tfidf__max_features': 19529, 'vect__etat_pat_tfidf__min_df': 1, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 55867, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3946, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2887, 'vect__classification_enc__min_df': 2, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:15:34,970]\u001b[0m Finished trial#57 with value: 0.5625165858425152 with parameters: {'vect__etat_pat_tfidf__max_features': 17139, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 19137, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 4263, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 3472, 'vect__classification_enc__min_df': 2, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:17:14,311]\u001b[0m Finished trial#58 with value: 0.5264739521507742 with parameters: {'vect__etat_pat_tfidf__max_features': 13029, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 50216, 'vect__description_tfidf__min_df': 4, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3240, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 4868, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:18:57,578]\u001b[0m Finished trial#59 with value: 0.5531176294690449 with parameters: {'vect__etat_pat_tfidf__max_features': 14178, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 44904, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'char_wb', 'vect__fabricant_tfidf__max_features': 2988, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1941, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:20:17,347]\u001b[0m Finished trial#60 with value: 0.5590729520371518 with parameters: {'vect__etat_pat_tfidf__max_features': 16303, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l1', 'vect__description_tfidf__max_features': 29946, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1903, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 3173, 'vect__classification_enc__min_df': 3, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:21:34,605]\u001b[0m Finished trial#61 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 18693, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 54213, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3622, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2214, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:22:52,067]\u001b[0m Finished trial#62 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 19036, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 19864, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 2404, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2373, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:24:09,640]\u001b[0m Finished trial#63 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 14658, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 42643, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1432, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1515, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:25:28,208]\u001b[0m Finished trial#64 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 13587, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 56497, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3575, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2076, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:26:46,253]\u001b[0m Finished trial#65 with value: 0.5625165858425152 with parameters: {'vect__etat_pat_tfidf__max_features': 19204, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 52369, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 3864, 'vect__fabricant_tfidf__min_df': 2, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2631, 'vect__classification_enc__min_df': 2, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:28:29,629]\u001b[0m Finished trial#66 with value: 0.5530312166523292 with parameters: {'vect__etat_pat_tfidf__max_features': 17951, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 21376, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'char', 'vect__fabricant_tfidf__max_features': 2196, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2051, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:29:50,935]\u001b[0m Finished trial#67 with value: 0.5623234483972629 with parameters: {'vect__etat_pat_tfidf__max_features': 15512, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 47573, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 4912, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1128, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:31:32,792]\u001b[0m Finished trial#68 with value: 0.5616881855360616 with parameters: {'vect__etat_pat_tfidf__max_features': 18111, 'vect__etat_pat_tfidf__min_df': 3, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 23322, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 9628, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'char', 'vect__classification_enc__max_features': 1389, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:32:54,968]\u001b[0m Finished trial#69 with value: 0.5613200595693172 with parameters: {'vect__etat_pat_tfidf__max_features': 16065, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 37332, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 8791, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l2', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1843, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l2'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:34:11,983]\u001b[0m Finished trial#70 with value: 0.5622109268207929 with parameters: {'vect__etat_pat_tfidf__max_features': 11375, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 17592, 'vect__description_tfidf__min_df': 3, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 9936, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1679, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:35:29,823]\u001b[0m Finished trial#71 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 13668, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 25752, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 2747, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1968, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:36:46,431]\u001b[0m Finished trial#72 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 15617, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 25183, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 5594, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1279, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:38:06,171]\u001b[0m Finished trial#73 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 16808, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 43381, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 5665, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2283, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:39:23,271]\u001b[0m Finished trial#74 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 14940, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 47584, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 5653, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2380, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:40:39,379]\u001b[0m Finished trial#75 with value: 0.5629891834027633 with parameters: {'vect__etat_pat_tfidf__max_features': 4575, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 28435, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 5985, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1725, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:41:58,282]\u001b[0m Finished trial#76 with value: 0.5638014529635027 with parameters: {'vect__etat_pat_tfidf__max_features': 16541, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 39705, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 1399, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1628, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:43:17,432]\u001b[0m Finished trial#77 with value: 0.5606396122903499 with parameters: {'vect__etat_pat_tfidf__max_features': 16414, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 33579, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 584, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 1417, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:45:03,612]\u001b[0m Finished trial#78 with value: 0.5603840228262646 with parameters: {'vect__etat_pat_tfidf__max_features': 16738, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 38277, 'vect__description_tfidf__min_df': 1, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 6950, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'char_wb', 'vect__classification_enc__max_features': 1256, 'vect__classification_enc__min_df': 5, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n",
      "\u001b[32m[I 2020-06-10 20:48:59,319]\u001b[0m Finished trial#79 with value: 0.5560222611348575 with parameters: {'vect__etat_pat_tfidf__max_features': 13248, 'vect__etat_pat_tfidf__min_df': 5, 'vect__etat_pat_tfidf__norm': 'l1', 'vect__description_tfidf__max_features': 59942, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l1', 'vect__fabricant_tfidf__analyzer': 'char_wb', 'vect__fabricant_tfidf__max_features': 2501, 'vect__fabricant_tfidf__min_df': 4, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2354, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}. Best is trial#13 with value: 0.5638014529635027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=13, value=0.5638014529635027, datetime_start=datetime.datetime(2020, 6, 10, 19, 7, 53, 904403), datetime_complete=datetime.datetime(2020, 6, 10, 19, 9, 11, 38205), params={'vect__etat_pat_tfidf__max_features': 19700, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', 'vect__description_tfidf__max_features': 20401, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', 'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 9992, 'vect__fabricant_tfidf__min_df': 3, 'vect__fabricant_tfidf__norm': 'l1', 'vect__action_pat_tfidf__analyzer': 'word', 'vect__classification_enc__max_features': 2062, 'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}, distributions={'vect__etat_pat_tfidf__max_features': IntUniformDistribution(high=20000, low=500, step=1), 'vect__etat_pat_tfidf__min_df': IntUniformDistribution(high=5, low=1, step=1), 'vect__etat_pat_tfidf__norm': CategoricalDistribution(choices=('l1', 'l2')), 'vect__description_tfidf__max_features': IntUniformDistribution(high=60000, low=1500, step=1), 'vect__description_tfidf__min_df': IntUniformDistribution(high=5, low=1, step=1), 'vect__description_tfidf__norm': CategoricalDistribution(choices=('l1', 'l2')), 'vect__fabricant_tfidf__analyzer': CategoricalDistribution(choices=('word', 'char', 'char_wb')), 'vect__fabricant_tfidf__max_features': IntUniformDistribution(high=10000, low=500, step=1), 'vect__fabricant_tfidf__min_df': IntUniformDistribution(high=5, low=1, step=1), 'vect__fabricant_tfidf__norm': CategoricalDistribution(choices=('l1', 'l2')), 'vect__action_pat_tfidf__analyzer': CategoricalDistribution(choices=('word', 'char', 'char_wb')), 'vect__classification_enc__max_features': IntUniformDistribution(high=5000, low=500, step=1), 'vect__classification_enc__min_df': IntUniformDistribution(high=5, low=1, step=1), 'vect__classification_enc__norm': CategoricalDistribution(choices=('l1', 'l2'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=13, state=TrialState.COMPLETE)\n"
     ]
    }
   ],
   "source": [
    "time_out = 75*100\n",
    "studyName = 'EFFET_ml_optimisation_svm'\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, timeout=time_out)\n",
    "\n",
    "#Suvegarde du resultat\n",
    "df = study.trials_dataframe()\n",
    "df.to_json(studyName+'.json')\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.5491033504163741\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Param = {'vect__etat_pat_tfidf__max_features': 19700, 'vect__etat_pat_tfidf__min_df': 4, 'vect__etat_pat_tfidf__norm': 'l2', \n",
    "         'vect__description_tfidf__max_features': 20401, 'vect__description_tfidf__min_df': 2, 'vect__description_tfidf__norm': 'l2', \n",
    "         'vect__fabricant_tfidf__analyzer': 'word', 'vect__fabricant_tfidf__max_features': 9992, 'vect__fabricant_tfidf__min_df': 3, \n",
    "         'vect__fabricant_tfidf__norm': 'l1', 'vect__classification_enc_analyzer': 'word', 'vect__classification_enc__max_features': 2062,\n",
    "         'vect__classification_enc__min_df': 4, 'vect__classification_enc__norm': 'l1'}\n",
    "\n",
    "preprocess2 = ColumnTransformer(\n",
    "    [('description_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=2,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 20401,norm = 'l2'), 'DESCRIPTION_INCIDENT'),\n",
    "     \n",
    "     ('etat_pat_tfidf', TfidfVectorizer(sublinear_tf=True, min_df=4,\n",
    "                                        ngram_range=(1, 1),\n",
    "                                        stop_words=STOP_WORDS,\n",
    "                                        max_features = 19700,\n",
    "                                        norm = 'l2'), 'ETAT_PATIENT'),\n",
    "     \n",
    "     ('fabricant_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 9992,norm = 'l1'), 'FABRICANT'),\n",
    "    \n",
    "    ('classification_enc', TfidfVectorizer(sublinear_tf=True, min_df=4,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 2062,norm = 'l2'),'CLASSIFICATION')\n",
    "     ],\n",
    "    \n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess2),\n",
    "    ('clf', OneVsRestClassifier(CalibratedClassifierCV(LinearSVC(class_weight='balanced'),cv=3, method='isotonic'))),\n",
    "])\n",
    "\n",
    "\n",
    "pipeline.fit(X,y_lb)\n",
    "Y_pred_ovr = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test_lb , Y_pred_ovr,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.20      0.26        49\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.78      0.31      0.44        68\n",
      "           4       0.00      0.00      0.00        34\n",
      "           5       0.45      0.37      0.41        68\n",
      "           6       0.00      0.00      0.00       353\n",
      "           7       1.00      0.76      0.86        21\n",
      "           8       1.00      0.26      0.41        23\n",
      "           9       0.00      0.00      0.00        34\n",
      "          10       0.00      0.00      0.00        25\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.67      0.12      0.21        16\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.00      0.00      0.00        39\n",
      "          15       0.00      0.00      0.00        18\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00        14\n",
      "          18       0.76      0.65      0.70       179\n",
      "          19       0.88      0.14      0.24        50\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.56      0.69      0.62        13\n",
      "          22       0.72      0.54      0.62        61\n",
      "          23       1.00      0.62      0.76        26\n",
      "          24       0.88      0.24      0.38        29\n",
      "          25       1.00      0.13      0.24        15\n",
      "          26       0.84      0.22      0.35        95\n",
      "          27       0.53      0.29      0.37        80\n",
      "          28       0.73      0.62      0.67       106\n",
      "          29       0.90      0.93      0.92       116\n",
      "          30       0.83      0.56      0.66       209\n",
      "          31       0.92      0.40      0.56        57\n",
      "          32       0.00      0.00      0.00         8\n",
      "          33       0.00      0.00      0.00         8\n",
      "          34       0.00      0.00      0.00        35\n",
      "          35       0.71      0.48      0.57       650\n",
      "          36       0.00      0.00      0.00        62\n",
      "          37       0.00      0.00      0.00        34\n",
      "          38       0.00      0.00      0.00        82\n",
      "          39       0.00      0.00      0.00        10\n",
      "          40       0.82      0.68      0.74        34\n",
      "          41       0.00      0.00      0.00         2\n",
      "          42       0.75      0.25      0.37       189\n",
      "          43       0.44      0.29      0.35        14\n",
      "          44       0.00      0.00      0.00        13\n",
      "          45       1.00      0.75      0.86        12\n",
      "          46       0.56      0.06      0.12       155\n",
      "          47       0.00      0.00      0.00        15\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.69      0.53      0.60        17\n",
      "          50       1.00      0.75      0.86        40\n",
      "          51       1.00      1.00      1.00        62\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.66      0.67      0.66        81\n",
      "          54       0.21      0.33      0.26        18\n",
      "          55       0.87      0.59      0.70        56\n",
      "          56       1.00      0.50      0.67         2\n",
      "          57       1.00      0.92      0.96        26\n",
      "          58       0.00      0.00      0.00        24\n",
      "          59       0.78      0.17      0.28       289\n",
      "          60       0.73      0.24      0.36       770\n",
      "          61       1.00      0.02      0.03        61\n",
      "          62       0.00      0.00      0.00        33\n",
      "          63       1.00      0.56      0.71        18\n",
      "          64       1.00      0.37      0.54        46\n",
      "          65       1.00      0.09      0.17        64\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       1.00      0.41      0.58        27\n",
      "          68       0.67      0.10      0.17        42\n",
      "          69       0.00      0.00      0.00        24\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.00      0.00      0.00       106\n",
      "          72       0.91      0.42      0.58        92\n",
      "          73       0.67      0.06      0.11        33\n",
      "          74       1.00      0.67      0.80         6\n",
      "          75       1.00      0.75      0.86         4\n",
      "          76       0.00      0.00      0.00         3\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.82      0.64      0.72       166\n",
      "          79       0.00      0.00      0.00        20\n",
      "          80       0.54      0.29      0.38        24\n",
      "          81       0.84      0.79      0.81       239\n",
      "          82       0.00      0.00      0.00        17\n",
      "          83       0.00      0.00      0.00         5\n",
      "          84       0.00      0.00      0.00        63\n",
      "          85       0.78      0.35      0.49        82\n",
      "          86       0.74      0.38      0.50       546\n",
      "          87       0.18      0.07      0.10        45\n",
      "          88       0.86      0.79      0.82      2852\n",
      "          89       0.00      0.00      0.00         4\n",
      "          90       0.62      0.71      0.66        55\n",
      "          91       0.67      0.57      0.62        14\n",
      "          92       0.57      0.08      0.15        48\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       1.00      0.57      0.73        28\n",
      "          95       1.00      0.89      0.94        18\n",
      "          96       0.75      0.06      0.11        99\n",
      "          97       0.00      0.00      0.00         5\n",
      "          98       0.50      0.50      0.50         2\n",
      "          99       0.00      0.00      0.00         3\n",
      "         100       0.00      0.00      0.00        18\n",
      "         101       1.00      0.40      0.57        15\n",
      "         102       0.17      0.05      0.07        86\n",
      "         103       0.97      0.99      0.98      4380\n",
      "         104       0.00      0.00      0.00        18\n",
      "         105       0.65      0.35      0.46        74\n",
      "         106       0.90      0.41      0.57        46\n",
      "         107       0.84      0.50      0.63        32\n",
      "         108       0.00      0.00      0.00         4\n",
      "         109       0.71      0.03      0.05       560\n",
      "         110       0.85      0.34      0.48        98\n",
      "         111       0.00      0.00      0.00         5\n",
      "         112       0.94      0.69      0.80      1359\n",
      "         113       0.76      0.81      0.78      2635\n",
      "         114       0.88      0.97      0.92      3918\n",
      "         115       0.90      0.77      0.83      2084\n",
      "         116       0.86      0.76      0.81      2302\n",
      "         117       0.74      0.48      0.58      2488\n",
      "         118       0.98      0.24      0.38      1008\n",
      "         119       0.76      0.31      0.44      2250\n",
      "         120       0.83      0.95      0.89      3494\n",
      "         121       0.78      0.04      0.07      1199\n",
      "         122       0.00      0.00      0.00       177\n",
      "         123       0.73      0.78      0.76      2437\n",
      "         124       0.76      0.18      0.28       177\n",
      "         125       0.80      0.45      0.58       238\n",
      "         126       1.00      0.02      0.05       168\n",
      "         127       1.00      0.11      0.19       294\n",
      "         128       0.00      0.00      0.00        93\n",
      "         129       0.71      0.41      0.52       920\n",
      "         130       0.83      0.35      0.49      1064\n",
      "         131       0.54      0.11      0.18       628\n",
      "         132       0.36      0.04      0.07       358\n",
      "         133       1.00      0.16      0.27        57\n",
      "         134       0.95      0.87      0.91       916\n",
      "         135       0.00      0.00      0.00        39\n",
      "         136       0.96      0.81      0.88        57\n",
      "         137       0.00      0.00      0.00         6\n",
      "         138       0.00      0.00      0.00        61\n",
      "         139       0.59      0.12      0.20        82\n",
      "         140       0.80      0.51      0.62       818\n",
      "         141       0.88      0.44      0.59       212\n",
      "         142       1.00      0.43      0.60         7\n",
      "         143       0.76      0.12      0.21       233\n",
      "         144       0.64      0.26      0.37        27\n",
      "         145       1.00      0.25      0.40         4\n",
      "         146       0.78      0.42      0.55        93\n",
      "         147       0.93      0.30      0.45        44\n",
      "         148       0.59      0.36      0.45        47\n",
      "         149       0.85      0.46      0.60        37\n",
      "         150       1.00      0.08      0.14        13\n",
      "         151       0.00      0.00      0.00         3\n",
      "         152       0.00      0.00      0.00         6\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         3\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.59      0.18      0.27        57\n",
      "         158       0.43      0.38      0.40         8\n",
      "         159       0.00      0.00      0.00         9\n",
      "         160       0.00      0.00      0.00        10\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         4\n",
      "         163       0.00      0.00      0.00         9\n",
      "         164       1.00      0.50      0.67         4\n",
      "         165       0.00      0.00      0.00        13\n",
      "         166       1.00      0.25      0.40         8\n",
      "         167       1.00      0.14      0.25        21\n",
      "         168       0.00      0.00      0.00         4\n",
      "         169       0.00      0.00      0.00        19\n",
      "         170       0.00      0.00      0.00        23\n",
      "         171       0.00      0.00      0.00        32\n",
      "\n",
      "   micro avg       0.84      0.62      0.71     47095\n",
      "   macro avg       0.49      0.26      0.31     47095\n",
      "weighted avg       0.79      0.62      0.66     47095\n",
      " samples avg       0.63      0.53      0.55     47095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_lb , Y_pred_ovr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commantaire\n",
    " Notre première approximation des performances était la bonne. En effet, le finetunning des paramètres des TFIDF n'a pas permis d'augmenter significativmement les résultats\n",
    " \n",
    "## 3.0 L'approche Multioutput\n",
    "\n",
    "> Multioutput classification support can be added to any classifier with MultiOutputClassifier. This strategy consists of fitting one classifier per target. This allows multiple target variable classifications. The purpose of this class is to extend estimators to be able to estimate a series of target functions (f1,f2,f3…,fn) that are trained on a single X predictor matrix to predict a series of responses (y1,y2,y3…,yn).\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.572080991241877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', MultiOutputClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])\n",
    "#### prédiction \n",
    "pipeline.fit(X,y_lb)\n",
    "Y_pred_ovr = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test_lb , Y_pred_ovr,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.34        49\n",
      "           1       1.00      0.50      0.67         4\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.66      0.31      0.42        68\n",
      "           4       0.57      0.12      0.20        34\n",
      "           5       0.42      0.50      0.46        68\n",
      "           6       0.29      0.11      0.16       353\n",
      "           7       1.00      0.76      0.86        21\n",
      "           8       0.88      0.30      0.45        23\n",
      "           9       0.10      0.03      0.05        34\n",
      "          10       0.00      0.00      0.00        25\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.67      0.12      0.21        16\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.00      0.00      0.00        39\n",
      "          15       0.00      0.00      0.00        18\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00        14\n",
      "          18       0.74      0.68      0.71       179\n",
      "          19       1.00      0.04      0.08        50\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.64      0.69      0.67        13\n",
      "          22       0.62      0.57      0.60        61\n",
      "          23       1.00      0.62      0.76        26\n",
      "          24       0.83      0.17      0.29        29\n",
      "          25       1.00      0.13      0.24        15\n",
      "          26       0.48      0.33      0.39        95\n",
      "          27       0.50      0.69      0.58        80\n",
      "          28       0.60      0.75      0.67       106\n",
      "          29       0.85      0.91      0.88       116\n",
      "          30       0.86      0.54      0.66       209\n",
      "          31       1.00      0.39      0.56        57\n",
      "          32       0.20      0.25      0.22         8\n",
      "          33       0.00      0.00      0.00         8\n",
      "          34       1.00      0.06      0.11        35\n",
      "          35       0.66      0.52      0.58       650\n",
      "          36       0.67      0.16      0.26        62\n",
      "          37       0.00      0.00      0.00        34\n",
      "          38       0.79      0.13      0.23        82\n",
      "          39       0.40      0.20      0.27        10\n",
      "          40       0.91      0.59      0.71        34\n",
      "          41       0.00      0.00      0.00         2\n",
      "          42       0.70      0.49      0.57       189\n",
      "          43       0.35      0.57      0.43        14\n",
      "          44       0.00      0.00      0.00        13\n",
      "          45       1.00      0.75      0.86        12\n",
      "          46       0.28      0.46      0.35       155\n",
      "          47       0.00      0.00      0.00        15\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.91      0.59      0.71        17\n",
      "          50       0.87      0.97      0.92        40\n",
      "          51       1.00      0.87      0.93        62\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.62      0.72      0.66        81\n",
      "          54       0.15      0.28      0.20        18\n",
      "          55       0.94      0.59      0.73        56\n",
      "          56       1.00      0.50      0.67         2\n",
      "          57       1.00      0.92      0.96        26\n",
      "          58       0.00      0.00      0.00        24\n",
      "          59       0.86      0.37      0.52       289\n",
      "          60       0.70      0.38      0.49       770\n",
      "          61       0.56      0.56      0.56        61\n",
      "          62       0.25      0.06      0.10        33\n",
      "          63       0.86      0.67      0.75        18\n",
      "          64       0.94      0.37      0.53        46\n",
      "          65       1.00      0.09      0.17        64\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       1.00      0.30      0.46        27\n",
      "          68       0.67      0.10      0.17        42\n",
      "          69       0.00      0.00      0.00        24\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.33      0.17      0.22       106\n",
      "          72       0.93      0.42      0.58        92\n",
      "          73       0.50      0.15      0.23        33\n",
      "          74       1.00      0.67      0.80         6\n",
      "          75       1.00      0.75      0.86         4\n",
      "          76       0.00      0.00      0.00         3\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.72      0.68      0.70       166\n",
      "          79       0.00      0.00      0.00        20\n",
      "          80       0.33      0.08      0.13        24\n",
      "          81       0.83      0.82      0.83       239\n",
      "          82       0.86      0.35      0.50        17\n",
      "          83       1.00      0.60      0.75         5\n",
      "          84       1.00      0.03      0.06        63\n",
      "          85       0.66      0.46      0.54        82\n",
      "          86       0.57      0.61      0.59       546\n",
      "          87       0.41      0.24      0.31        45\n",
      "          88       0.84      0.45      0.58      2852\n",
      "          89       0.00      0.00      0.00         4\n",
      "          90       0.55      0.58      0.57        55\n",
      "          91       1.00      0.36      0.53        14\n",
      "          92       1.00      0.12      0.22        48\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       0.94      0.57      0.71        28\n",
      "          95       1.00      0.78      0.88        18\n",
      "          96       0.51      0.43      0.47        99\n",
      "          97       0.00      0.00      0.00         5\n",
      "          98       0.50      0.50      0.50         2\n",
      "          99       0.00      0.00      0.00         3\n",
      "         100       0.00      0.00      0.00        18\n",
      "         101       1.00      0.27      0.42        15\n",
      "         102       0.17      0.05      0.07        86\n",
      "         103       0.99      0.98      0.99      4380\n",
      "         104       0.00      0.00      0.00        18\n",
      "         105       0.38      0.59      0.47        74\n",
      "         106       0.85      0.48      0.61        46\n",
      "         107       1.00      0.50      0.67        32\n",
      "         108       0.00      0.00      0.00         4\n",
      "         109       0.46      0.54      0.50       560\n",
      "         110       0.70      0.40      0.51        98\n",
      "         111       0.00      0.00      0.00         5\n",
      "         112       0.93      0.70      0.80      1359\n",
      "         113       0.83      0.65      0.73      2635\n",
      "         114       0.91      0.84      0.87      3918\n",
      "         115       0.91      0.39      0.55      2084\n",
      "         116       0.85      0.36      0.50      2302\n",
      "         117       0.76      0.41      0.53      2488\n",
      "         118       0.98      0.31      0.47      1008\n",
      "         119       0.80      0.36      0.50      2250\n",
      "         120       0.92      0.87      0.89      3494\n",
      "         121       0.89      0.08      0.14      1199\n",
      "         122       0.00      0.00      0.00       177\n",
      "         123       0.77      0.62      0.69      2437\n",
      "         124       0.91      0.18      0.29       177\n",
      "         125       0.74      0.31      0.44       238\n",
      "         126       1.00      0.02      0.05       168\n",
      "         127       0.73      0.13      0.21       294\n",
      "         128       0.00      0.00      0.00        93\n",
      "         129       0.67      0.36      0.47       920\n",
      "         130       0.76      0.37      0.49      1064\n",
      "         131       0.69      0.26      0.38       628\n",
      "         132       0.97      0.08      0.15       358\n",
      "         133       1.00      0.16      0.27        57\n",
      "         134       1.00      0.82      0.90       916\n",
      "         135       0.00      0.00      0.00        39\n",
      "         136       0.98      0.79      0.87        57\n",
      "         137       0.00      0.00      0.00         6\n",
      "         138       0.30      0.05      0.08        61\n",
      "         139       0.71      0.37      0.48        82\n",
      "         140       0.69      0.60      0.64       818\n",
      "         141       0.78      0.60      0.68       212\n",
      "         142       1.00      0.14      0.25         7\n",
      "         143       0.43      0.30      0.35       233\n",
      "         144       0.33      0.07      0.12        27\n",
      "         145       1.00      0.50      0.67         4\n",
      "         146       0.78      0.46      0.58        93\n",
      "         147       1.00      0.34      0.51        44\n",
      "         148       0.65      0.36      0.47        47\n",
      "         149       0.68      0.46      0.55        37\n",
      "         150       1.00      0.08      0.14        13\n",
      "         151       0.00      0.00      0.00         3\n",
      "         152       1.00      0.33      0.50         6\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         3\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.50      0.07      0.12        57\n",
      "         158       0.00      0.00      0.00         8\n",
      "         159       0.00      0.00      0.00         9\n",
      "         160       0.00      0.00      0.00        10\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         4\n",
      "         163       0.00      0.00      0.00         9\n",
      "         164       1.00      0.50      0.67         4\n",
      "         165       1.00      0.08      0.14        13\n",
      "         166       1.00      0.62      0.77         8\n",
      "         167       1.00      0.14      0.25        21\n",
      "         168       0.00      0.00      0.00         4\n",
      "         169       1.00      0.11      0.19        19\n",
      "         170       0.67      0.09      0.15        23\n",
      "         171       0.00      0.00      0.00        32\n",
      "\n",
      "   micro avg       0.83      0.55      0.66     47095\n",
      "   macro avg       0.55      0.30      0.35     47095\n",
      "weighted avg       0.81      0.55      0.63     47095\n",
      " samples avg       0.68      0.55      0.57     47095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_lb , Y_pred_ovr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "Comme attendu, nous n'observons pas de grande différence car les deux approches sont très similaires\n",
    "\n",
    "## 3.1 Approche One vs One\n",
    "\n",
    ">This strategy consists in fitting one classifier per class pair. At prediction time, the class which received the most votes is selected. Since it requires to fit n_classes * (n_classes - 1) / 2 classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don’t scale well with n_samples. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used n_classes times.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.572080991241877\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', MultiOutputClassifier(OneVsOneClassifier(LinearSVC(class_weight='balanced')))),\n",
    "])\n",
    "#### prédiction \n",
    "pipeline.fit(X,y_lb)\n",
    "Y_pred_ovr = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test_lb , Y_pred_ovr,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "Nous n'oservons pas de changement de performances, seulement une hausse du temps de calcul\n",
    "## 3.2 l'approche ClassifierChain\n",
    ">A multi-label model that arranges binary classifiers into a chain.\n",
    "Each model makes a prediction in the order specified by the chain using all of the available features provided to the model plus the predictions of models that are earlier in the chain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index_,test_index_ = next(GroupShuffleSplit(random_state=1029).split(X, groups=X['DESCRIPTION_INCIDENT']))\n",
    "X_train_, X_test_ = X.iloc[train_index_], X.iloc[test_index_]\n",
    "y_train_, y_test_ = y.iloc[train_index_], y.iloc[test_index_]\n",
    "\n",
    "X_train_, X_test_ =preprocess.fit_transform(X_train_),preprocess.transform(X_test_)\n",
    "y_train_lb_ = lb.transform(y_train_)\n",
    "y_test_lb_ = lb.transform(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5956181738659063\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test_ =preprocess.fit_transform(X),preprocess.transform(X_test)\n",
    "clf = LinearSVC(class_weight='balanced')\n",
    "\n",
    "\n",
    "chains = [ClassifierChain(clf, order='random', random_state=i) for i in range(10)]\n",
    "\n",
    "for chain in chains:\n",
    "    chain.fit(X_train, y_lb)\n",
    "    \n",
    "y_pred_chains = np.array([chain.predict(X_test_) for chain in chains])\n",
    "\n",
    "chain_f1_scores = [f1_score(y_test_lb, y_pred_chain, average='samples') for y_pred_chain in y_pred_chains]\n",
    "\n",
    "y_pred_ensemble = y_pred_chains.mean(axis=0)\n",
    "\n",
    "y_e = y_pred_ensemble>=0.4\n",
    "\n",
    "ensemble_f1_score = f1_score(y_test_lb,y_e, average='samples')\n",
    "\n",
    "print(ensemble_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.34        49\n",
      "           1       1.00      0.50      0.67         4\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.66      0.31      0.42        68\n",
      "           4       0.57      0.12      0.20        34\n",
      "           5       0.46      0.63      0.53        68\n",
      "           6       0.29      0.11      0.16       353\n",
      "           7       1.00      0.76      0.86        21\n",
      "           8       1.00      0.30      0.47        23\n",
      "           9       0.11      0.03      0.05        34\n",
      "          10       0.00      0.00      0.00        25\n",
      "          11       0.67      0.18      0.29        22\n",
      "          12       0.50      0.19      0.27        16\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.00      0.00      0.00        39\n",
      "          15       0.00      0.00      0.00        18\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00        14\n",
      "          18       0.74      0.72      0.73       179\n",
      "          19       1.00      0.04      0.08        50\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.60      0.69      0.64        13\n",
      "          22       0.57      0.66      0.61        61\n",
      "          23       1.00      0.62      0.76        26\n",
      "          24       0.78      0.24      0.37        29\n",
      "          25       1.00      0.13      0.24        15\n",
      "          26       0.64      0.41      0.50        95\n",
      "          27       0.58      0.76      0.66        80\n",
      "          28       0.64      0.74      0.68       106\n",
      "          29       0.85      0.91      0.88       116\n",
      "          30       0.86      0.54      0.66       209\n",
      "          31       0.93      0.44      0.60        57\n",
      "          32       0.20      0.25      0.22         8\n",
      "          33       0.00      0.00      0.00         8\n",
      "          34       1.00      0.06      0.11        35\n",
      "          35       0.63      0.54      0.58       650\n",
      "          36       0.33      0.06      0.11        62\n",
      "          37       0.00      0.00      0.00        34\n",
      "          38       0.61      0.13      0.22        82\n",
      "          39       0.40      0.20      0.27        10\n",
      "          40       0.92      0.68      0.78        34\n",
      "          41       0.00      0.00      0.00         2\n",
      "          42       0.69      0.51      0.59       189\n",
      "          43       0.24      0.29      0.26        14\n",
      "          44       0.00      0.00      0.00        13\n",
      "          45       1.00      0.75      0.86        12\n",
      "          46       0.28      0.48      0.36       155\n",
      "          47       0.00      0.00      0.00        15\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.91      0.59      0.71        17\n",
      "          50       0.93      0.97      0.95        40\n",
      "          51       1.00      0.87      0.93        62\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.60      0.75      0.67        81\n",
      "          54       0.15      0.28      0.20        18\n",
      "          55       0.97      0.59      0.73        56\n",
      "          56       1.00      0.50      0.67         2\n",
      "          57       1.00      0.92      0.96        26\n",
      "          58       0.00      0.00      0.00        24\n",
      "          59       0.80      0.34      0.48       289\n",
      "          60       0.66      0.35      0.46       770\n",
      "          61       0.59      0.56      0.57        61\n",
      "          62       0.20      0.06      0.09        33\n",
      "          63       0.88      0.78      0.82        18\n",
      "          64       0.94      0.37      0.53        46\n",
      "          65       1.00      0.09      0.17        64\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       1.00      0.30      0.46        27\n",
      "          68       0.67      0.10      0.17        42\n",
      "          69       0.00      0.00      0.00        24\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.29      0.17      0.21       106\n",
      "          72       0.93      0.42      0.58        92\n",
      "          73       0.50      0.15      0.23        33\n",
      "          74       1.00      0.67      0.80         6\n",
      "          75       1.00      0.75      0.86         4\n",
      "          76       0.00      0.00      0.00         3\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.75      0.69      0.72       166\n",
      "          79       0.00      0.00      0.00        20\n",
      "          80       0.33      0.08      0.13        24\n",
      "          81       0.82      0.86      0.84       239\n",
      "          82       0.86      0.35      0.50        17\n",
      "          83       1.00      0.60      0.75         5\n",
      "          84       1.00      0.03      0.06        63\n",
      "          85       0.68      0.55      0.61        82\n",
      "          86       0.53      0.73      0.62       546\n",
      "          87       0.52      0.29      0.37        45\n",
      "          88       0.85      0.49      0.62      2852\n",
      "          89       0.00      0.00      0.00         4\n",
      "          90       0.55      0.58      0.57        55\n",
      "          91       0.75      0.43      0.55        14\n",
      "          92       1.00      0.12      0.22        48\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       0.94      0.57      0.71        28\n",
      "          95       1.00      0.89      0.94        18\n",
      "          96       0.47      0.47      0.47        99\n",
      "          97       0.00      0.00      0.00         5\n",
      "          98       0.33      0.50      0.40         2\n",
      "          99       0.00      0.00      0.00         3\n",
      "         100       0.00      0.00      0.00        18\n",
      "         101       1.00      0.27      0.42        15\n",
      "         102       0.17      0.05      0.07        86\n",
      "         103       0.98      0.98      0.98      4380\n",
      "         104       0.00      0.00      0.00        18\n",
      "         105       0.38      0.49      0.43        74\n",
      "         106       0.83      0.52      0.64        46\n",
      "         107       1.00      0.50      0.67        32\n",
      "         108       0.00      0.00      0.00         4\n",
      "         109       0.45      0.58      0.51       560\n",
      "         110       0.64      0.37      0.47        98\n",
      "         111       0.00      0.00      0.00         5\n",
      "         112       0.93      0.74      0.82      1359\n",
      "         113       0.83      0.69      0.75      2635\n",
      "         114       0.92      0.84      0.88      3918\n",
      "         115       0.86      0.42      0.57      2084\n",
      "         116       0.83      0.42      0.56      2302\n",
      "         117       0.76      0.46      0.57      2488\n",
      "         118       0.98      0.31      0.47      1008\n",
      "         119       0.79      0.34      0.48      2250\n",
      "         120       0.89      0.85      0.87      3494\n",
      "         121       0.84      0.04      0.08      1199\n",
      "         122       0.00      0.00      0.00       177\n",
      "         123       0.79      0.65      0.71      2437\n",
      "         124       0.94      0.18      0.30       177\n",
      "         125       0.69      0.31      0.43       238\n",
      "         126       1.00      0.02      0.05       168\n",
      "         127       1.00      0.22      0.36       294\n",
      "         128       0.00      0.00      0.00        93\n",
      "         129       0.70      0.47      0.56       920\n",
      "         130       0.78      0.41      0.53      1064\n",
      "         131       0.76      0.29      0.42       628\n",
      "         132       0.00      0.00      0.00       358\n",
      "         133       1.00      0.16      0.27        57\n",
      "         134       1.00      0.82      0.90       916\n",
      "         135       0.00      0.00      0.00        39\n",
      "         136       0.96      0.77      0.85        57\n",
      "         137       0.00      0.00      0.00         6\n",
      "         138       0.30      0.05      0.08        61\n",
      "         139       0.64      0.33      0.44        82\n",
      "         140       0.68      0.71      0.69       818\n",
      "         141       0.77      0.66      0.71       212\n",
      "         142       1.00      0.14      0.25         7\n",
      "         143       0.42      0.32      0.36       233\n",
      "         144       0.64      0.26      0.37        27\n",
      "         145       1.00      0.25      0.40         4\n",
      "         146       0.64      0.46      0.54        93\n",
      "         147       1.00      0.34      0.51        44\n",
      "         148       0.63      0.36      0.46        47\n",
      "         149       0.65      0.46      0.54        37\n",
      "         150       1.00      0.08      0.14        13\n",
      "         151       0.00      0.00      0.00         3\n",
      "         152       1.00      0.33      0.50         6\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       0.00      0.00      0.00         3\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.36      0.07      0.12        57\n",
      "         158       0.00      0.00      0.00         8\n",
      "         159       0.00      0.00      0.00         9\n",
      "         160       0.00      0.00      0.00        10\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.00      0.00      0.00         4\n",
      "         163       0.00      0.00      0.00         9\n",
      "         164       0.40      0.50      0.44         4\n",
      "         165       1.00      0.08      0.14        13\n",
      "         166       1.00      0.62      0.77         8\n",
      "         167       1.00      0.14      0.25        21\n",
      "         168       0.00      0.00      0.00         4\n",
      "         169       1.00      0.11      0.19        19\n",
      "         170       0.00      0.00      0.00        23\n",
      "         171       0.00      0.00      0.00        32\n",
      "\n",
      "   micro avg       0.82      0.57      0.67     47095\n",
      "   macro avg       0.53      0.30      0.35     47095\n",
      "weighted avg       0.80      0.57      0.64     47095\n",
      " samples avg       0.71      0.57      0.60     47095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_lb,y_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04225001471861698"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random test\n",
    "test = np.random.rand(y_e.shape[0],y_e.shape[1])>=0.5\n",
    "f1_score(y_test_lb_,test, average='samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire : \n",
    "L'approche chain combiner à une méthode ensemblise améliore les performaces de quelques pourcent mais l'ordre de grandeur reste le même.\n",
    "\n",
    "L'approche multilabel est une piste à suivre mais elle n'améliore pas ou peu la qualité de notre apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si on appliue un mapping inteligent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 10.3 µs\n",
      "172\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json \n",
    "\n",
    "df_declaration_mrv = pd.read_csv(\"data/data_mrv/declaration_mrv_complet.csv\")#delimiter=';',encoding='ISO-8859-1')\n",
    "id_to_dco = pd.read_csv(\"data/ref_MRV/referentiel_dispositif.csv\",delimiter=';',encoding='ISO-8859-1')\n",
    "df_effets = pd.read_csv(\"data/ref_MRV/referentiel_dispositif_effets_connus.csv\",delimiter=';',encoding='ISO-8859-1')\n",
    "df_dys = pd.read_csv(\"data/ref_MRV/referentiel_dispositif_dysfonctionnement.csv\",delimiter=';',encoding='ISO-8859-1')\n",
    "\n",
    "with open ('mapping_effet.json', 'r') as file :\n",
    "    mapping_effet = json.load(file)\n",
    "    \n",
    "#On complète les effets vide comme étant sans effets\n",
    "df_declaration_mrv['TYPE_EFFET']  = df_declaration_mrv['TYPE_EFFET'].fillna(\"PAS D'EFFET NEFASTE DECLARE\")\n",
    "df_declaration_mrv['TEF_ID']= df_declaration_mrv['TEF_ID'].fillna('E1213')\n",
    "\n",
    "\n",
    "#on selectionne les colonnes avec des effets\n",
    "df = df_declaration_mrv[['DESCRIPTION_INCIDENT','TYPE_VIGILANCE','LIBELLE_COMMERCIAL',\n",
    "                         'REFERENCE_COMMERCIALE','ETAT_PATIENT','FABRICANT','DCO_ID',\n",
    "                         'ACTION_PATIENT','CLASSIFICATION','TYPE_EFFET','TEF_ID']][df_declaration_mrv['TEF_ID']!='E1213']\n",
    "# On complète les NaN avec du vide\n",
    "df['ETAT_PATIENT'] = df['ETAT_PATIENT'].fillna(\"\")\n",
    "df['DESCRIPTION_INCIDENT'] = df['DESCRIPTION_INCIDENT'].fillna(\"\")\n",
    "df['LIBELLE_COMMERCIAL'] = df['LIBELLE_COMMERCIAL'].fillna(\"\")\n",
    "df['FABRICANT'] = df['FABRICANT'].fillna(\"\")\n",
    "df[\"REFERENCE_COMMERCIALE\"] = df['REFERENCE_COMMERCIALE'].fillna(\"\")\n",
    "df['TYPE_VIGILANCE'] = df['TYPE_VIGILANCE'].fillna(\"\")\n",
    "df['CLASSIFICATION'] = df['CLASSIFICATION'].fillna('')\n",
    "df['DCO_ID'] = df['DCO_ID'].fillna(-1)\n",
    "#On nettoieles variables textueelles : \n",
    "\n",
    "for col in  ['DESCRIPTION_INCIDENT','LIBELLE_COMMERCIAL','ETAT_PATIENT','FABRICANT','ACTION_PATIENT'] :\n",
    "    df[col] = df[col].map(lambda x: clean_text.preprocess_text(x))\n",
    "\n",
    "def apply_mapping(x,mapping):\n",
    "    cle = list(mapping.keys())\n",
    "    if x in cle:\n",
    "        return(x)\n",
    "    else:\n",
    "        for elt in cle:\n",
    "            if x in mapping[elt] :\n",
    "                return elt\n",
    "\n",
    "n = 15\n",
    "# On filtre pour a voir plus de n observations par classse\n",
    "df = df.groupby(\"TEF_ID\").filter(lambda x: len(x) > n)\n",
    "\n",
    "print(len(df.groupby(\"TYPE_EFFET\")))\n",
    "df.TYPE_EFFET = df.TYPE_EFFET.map(lambda x: apply_mapping(x,mapping_effet))\n",
    "print(len(df.groupby(\"TYPE_EFFET\")))\n",
    "\n",
    "le = LabelEncoder()\n",
    "df.TYPE_VIGILANCE = le.fit_transform(df.TYPE_VIGILANCE.values)\n",
    "le = LabelEncoder()\n",
    "df.TYPE_EFFET = le.fit_transform(df.TYPE_EFFET.values)\n",
    "\n",
    "\n",
    "# Encodage des varaible  multilabelle\n",
    "df_m = df.groupby('DESCRIPTION_INCIDENT')['TYPE_EFFET'].apply(list).reset_index(name='multilabels')\n",
    "\n",
    "\n",
    "df_ = pd.merge(df,df_m, on = 'DESCRIPTION_INCIDENT')\n",
    "df_['multilabels'] = df_['multilabels'].apply(np.array)\n",
    "df_['multilabels'] = df_['multilabels'].map(np.unique)\n",
    "\n",
    "\n",
    "# selection des train et test set\n",
    "train_index,test_index = next(GroupShuffleSplit(random_state=1029).split(df_, groups=df_['DESCRIPTION_INCIDENT']))\n",
    "df_train, df_test = df_.iloc[train_index], df_.iloc[test_index]\n",
    "y = df_train.multilabels\n",
    "y_test =df_test.multilabels\n",
    "\n",
    "lb = MultiLabelBinarizer()\n",
    "y_lb =lb.fit_transform(y) \n",
    "y_test_lb = lb.transform(y_test)\n",
    "X = df_train[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']]\n",
    "X_test = df_test[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.5916493372568136\n",
      "CPU times: user 1min 38s, sys: 0 ns, total: 1min 38s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', MultiOutputClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])\n",
    "#### prédiction \n",
    "pipeline.fit(X,y_lb)\n",
    "Y_pred_ovr = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test_lb , Y_pred_ovr,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping_effet.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = sk.metrics.multilabel_confusion_matrix(y_test_lb,y_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re = pd.DataFrame(classification_report(y_test_lb , Y_pred_ovr,output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'micro avg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-273-9b06eafa88de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_re\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   4562\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4564\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4566\u001b[0m         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_attributes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DGS-env/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'micro avg'"
     ]
    }
   ],
   "source": [
    "df_re['Class'] = le.inverse_transform(df_re.index.map(int).values[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "L =df_re.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-3a35fc6d70ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "L.map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGS-env",
   "language": "python",
   "name": "dgs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
