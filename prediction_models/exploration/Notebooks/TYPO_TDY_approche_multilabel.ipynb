{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Inférence du type  de dysfonctionnement - Stratégie Multilabels - tableau des scores\n",
    "Dans ce Notebook, nous cosntruisons un modèle qui permet d'inférer le type de de dysfocntionnement à partir de la classification de l'incident et des données textuelles\n",
    "\n",
    "Nous considérons ce problème comme un problème de classification multiclasses et multilabels. En effet, il y a plusieurs effets possibles et un incidents peut entrainer plusieurs effets.\n",
    "\n",
    "Ainsi, notre métrique d'évaluation sera le f1_samples\n",
    "\n",
    "Dans le Notebook précedent, nous n'avions pas pris en compte l'aspect multilabel et notre score était de  f1_weighted = 0,??.\n",
    "\n",
    "Dans ce notebook, nous testons différents modèles :\n",
    "- SVM\n",
    "- XGboost\n",
    "- LSTM\n",
    "- NBSVM\n",
    "\n",
    "Et différents encodages : \n",
    "- TFIDF\n",
    "- countvectorizer\n",
    "\n",
    "Les scores sont résumé dans le tableau suivant : https://starclay-my.sharepoint.com/:x:/g/personal/rquillivic_starclay_fr/EZPS3DrBBQ9MrZskrcwKVAEBGsLY61W089kd8RFvIEirjg?e=ve9g9K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score,f1_score,classification_report,recall_score,precision_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp =spacy.load('fr')\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 17.6 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "train = pd.read_pickle('./data_split/train.pkl')\n",
    "# Pour faire un modèle sans le \n",
    "#train = train[~train['TEF_ID'].map(lambda x : 106 in x)]\n",
    "X_train = train[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT', 'ACTION_PATIENT']]\n",
    "y_train = mlb.fit_transform(train['TDY_ID'])\n",
    "test =  pd.read_pickle('./data_split/test.pkl')\n",
    "#test = test[~test['TEF_ID'].map(lambda x : k in x)]\n",
    "X_test = test[['FABRICANT','CLASSIFICATION','DESCRIPTION_INCIDENT','ETAT_PATIENT','ACTION_PATIENT']]\n",
    "y_test = mlb.transform(test['TDY_ID'])\n",
    "\n",
    "\n",
    "X_train_dgs = np.load('results/dgs_camenbert_train_vec.npy')\n",
    "X_test_dgs =np.load('results/dgs_camenbert_test_vec.npy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_effets = pd.read_csv(\"data/ref_MRV/referentiel_dispositif_effets_connus.csv\",delimiter=';',encoding='ISO-8859-1')\n",
    "df_dys = pd.read_csv(\"data/ref_MRV/referentiel_dispositif_dysfonctionnement.csv\",delimiter=';',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Construction du pipeline avec une stratégie ONE-VS-REST\n",
    "\n",
    "> \"This strategy, also known as one-vs-all, is implemented in OneVsRestClassifier. The strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only n_classes classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy and is a fair default choice.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 1.27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preprocess = ColumnTransformer(\n",
    "    [('description_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 10000,norm = 'l2'), 'DESCRIPTION_INCIDENT'),\n",
    "     \n",
    "     ('etat_pat_tfidf', TfidfVectorizer(sublinear_tf=True, min_df=3,ngram_range=(1, 1),\n",
    "                                       stop_words=STOP_WORDS,\n",
    "                                       max_features = 10000,norm = 'l2'), 'ETAT_PATIENT'),\n",
    "     ('action_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 5000,norm = 'l2'), 'ACTION_PATIENT'),\n",
    "     \n",
    "     ('fabricant_tfidf',TfidfVectorizer(sublinear_tf=True, min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 5000,norm = 'l2'), 'FABRICANT')\n",
    "     ],\n",
    "    \n",
    "    remainder='passthrough')\n",
    "\n",
    "preprocess_2 = ColumnTransformer(\n",
    "    [('description_tfidf',CountVectorizer( min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 10000), 'DESCRIPTION_INCIDENT'),\n",
    "     \n",
    "     ('etat_pat_tfidf', CountVectorizer( min_df=3,ngram_range=(1, 1),\n",
    "                                       stop_words=STOP_WORDS,\n",
    "                                       max_features = 10000), 'ETAT_PATIENT'),\n",
    "     ('action_tfidf',CountVectorizer(min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 5000), 'ACTION_PATIENT'),\n",
    "     \n",
    "     ('fabricant_tfidf',CountVectorizer(min_df=3,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 5000), 'FABRICANT')\n",
    "     ],\n",
    "    \n",
    "    remainder='passthrough')\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])\n",
    "\n",
    "pipeline_2 = Pipeline([\n",
    "    ('vect', preprocess_2),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.4664546244029526\n",
      "CPU times: user 1min 5s, sys: 1.46 s, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test , y_pred,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72      1258\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      0.25      0.40         4\n",
      "           5       1.00      0.50      0.67         4\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.38      0.60      0.46         5\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         4\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.40      0.14      0.21        14\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       1.00      0.25      0.40         4\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.17      0.08      0.11        13\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         2\n",
      "          22       0.67      0.30      0.41        27\n",
      "          23       0.64      0.64      0.64        25\n",
      "          24       1.00      0.33      0.50         3\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         8\n",
      "          28       0.20      0.08      0.12        12\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       1.00      0.17      0.29         6\n",
      "          31       0.00      0.00      0.00         6\n",
      "          32       1.00      0.12      0.22         8\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.75      0.53      0.62        95\n",
      "          35       0.00      0.00      0.00         2\n",
      "          36       0.00      0.00      0.00         8\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         3\n",
      "          40       0.80      0.50      0.62        24\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.20      0.25      0.22         4\n",
      "          47       0.40      0.25      0.31         8\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         5\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.50      1.00      0.67         1\n",
      "          55       1.00      0.20      0.33         5\n",
      "          56       1.00      1.00      1.00         3\n",
      "          57       1.00      0.33      0.50         3\n",
      "          58       0.00      0.00      0.00         4\n",
      "          59       0.78      0.54      0.64        13\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       1.00      0.17      0.29         6\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.43      0.20      0.27        15\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       1.00      0.40      0.57         5\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.60      0.47      0.53        19\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         3\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.50      0.29      0.37        17\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.69      0.31      0.43        29\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.73      0.42      0.54        26\n",
      "          79       0.89      0.67      0.76        24\n",
      "          80       0.47      0.40      0.43        20\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.86      0.67      0.75         9\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       0.75      0.56      0.64        32\n",
      "          86       0.25      0.17      0.20         6\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         5\n",
      "          90       0.00      0.00      0.00         3\n",
      "          91       0.50      0.12      0.20        16\n",
      "          92       1.00      0.29      0.44         7\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       1.00      0.20      0.33         5\n",
      "          98       0.50      0.33      0.40         3\n",
      "          99       0.00      0.00      0.00         3\n",
      "         100       0.50      0.33      0.40         3\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.50      0.44      0.47        16\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.80      0.67      0.73         6\n",
      "         105       0.23      0.11      0.15        27\n",
      "         106       0.67      0.25      0.36         8\n",
      "         107       0.84      0.50      0.63        32\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.49      0.52      0.50        33\n",
      "         110       1.00      0.17      0.29         6\n",
      "         111       1.00      0.25      0.40         8\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         2\n",
      "         116       0.50      0.17      0.25         6\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         4\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       1.00      0.50      0.67         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.58      0.39      0.47        28\n",
      "         124       0.50      0.25      0.33         4\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.50      0.40      0.44         5\n",
      "         129       0.00      0.00      0.00         2\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         3\n",
      "         135       0.00      0.00      0.00         5\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         2\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       0.50      0.23      0.32        13\n",
      "         142       1.00      0.14      0.25        14\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       1.00      0.75      0.86         4\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         0\n",
      "         150       0.41      0.30      0.34       104\n",
      "         151       0.67      0.17      0.27        12\n",
      "         152       0.67      0.33      0.44        12\n",
      "         153       1.00      0.29      0.44         7\n",
      "         154       1.00      0.10      0.18        10\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.83      0.92      0.87       373\n",
      "         160       1.00      1.00      1.00         1\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.50      0.14      0.22         7\n",
      "         163       0.88      0.78      0.82        18\n",
      "         164       0.67      0.17      0.27        12\n",
      "         165       0.00      0.00      0.00        10\n",
      "         166       0.50      0.20      0.29         5\n",
      "         167       0.00      0.00      0.00        16\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       1.00      0.50      0.67         2\n",
      "         170       0.00      0.00      0.00         1\n",
      "         171       0.82      0.75      0.78        12\n",
      "         172       0.00      0.00      0.00         6\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.54      0.46      0.50       136\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       0.36      0.26      0.30        19\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.39      0.43      0.41        21\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         2\n",
      "         181       0.67      1.00      0.80         4\n",
      "         182       0.00      0.00      0.00         2\n",
      "         183       0.00      0.00      0.00         3\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         4\n",
      "         186       0.00      0.00      0.00         2\n",
      "         187       0.00      0.00      0.00         3\n",
      "         188       0.00      0.00      0.00         3\n",
      "         189       0.00      0.00      0.00         2\n",
      "         190       0.50      0.25      0.33         4\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.50      0.14      0.22         7\n",
      "         194       1.00      0.11      0.20         9\n",
      "         195       1.00      0.25      0.40         4\n",
      "         196       0.00      0.00      0.00         2\n",
      "         197       1.00      0.14      0.25         7\n",
      "         198       1.00      0.33      0.50         6\n",
      "         199       1.00      0.57      0.73         7\n",
      "         200       0.18      0.18      0.18       165\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         3\n",
      "         204       0.33      0.32      0.33        75\n",
      "         205       0.37      0.18      0.24        61\n",
      "         206       0.75      0.30      0.43        10\n",
      "         207       0.00      0.00      0.00         1\n",
      "         208       0.40      0.35      0.37       115\n",
      "         209       1.00      0.25      0.40         4\n",
      "         210       0.72      0.81      0.76        16\n",
      "         211       0.00      0.00      0.00         2\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         8\n",
      "         216       1.00      0.11      0.20         9\n",
      "         217       0.00      0.00      0.00         2\n",
      "         218       1.00      0.43      0.60         7\n",
      "         219       0.00      0.00      0.00         2\n",
      "         220       0.00      0.00      0.00         7\n",
      "         221       1.00      0.29      0.44         7\n",
      "         222       0.67      0.33      0.44         6\n",
      "         223       0.80      0.80      0.80         5\n",
      "         224       0.00      0.00      0.00         8\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       1.00      0.33      0.50         3\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         2\n",
      "         230       0.33      0.17      0.22         6\n",
      "         231       0.00      0.00      0.00         2\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.86      0.75      0.80         8\n",
      "         234       0.00      0.00      0.00         3\n",
      "         235       0.50      1.00      0.67         1\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       1.00      0.60      0.75         5\n",
      "         238       0.00      0.00      0.00         2\n",
      "         239       1.00      1.00      1.00         1\n",
      "         240       0.00      0.00      0.00         2\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       0.00      0.00      0.00         0\n",
      "         243       0.94      0.65      0.77        23\n",
      "         244       0.00      0.00      0.00         1\n",
      "         245       0.00      0.00      0.00         0\n",
      "         246       0.00      0.00      0.00         1\n",
      "         247       0.00      0.00      0.00         2\n",
      "         248       0.00      0.00      0.00         0\n",
      "         249       0.79      0.46      0.58        67\n",
      "         250       0.00      0.00      0.00         1\n",
      "         251       0.60      0.38      0.46        16\n",
      "         252       0.00      0.00      0.00         0\n",
      "         253       0.00      0.00      0.00         0\n",
      "         254       0.63      0.67      0.65       299\n",
      "         255       0.00      0.00      0.00         4\n",
      "         256       0.00      0.00      0.00         4\n",
      "         257       0.00      0.00      0.00         0\n",
      "         258       1.00      0.50      0.67         4\n",
      "         259       1.00      0.29      0.44         7\n",
      "         260       0.50      0.09      0.15        11\n",
      "         261       0.00      0.00      0.00         0\n",
      "         262       0.00      0.00      0.00         0\n",
      "         263       0.00      0.00      0.00         2\n",
      "         264       0.00      0.00      0.00         3\n",
      "         265       1.00      1.00      1.00         1\n",
      "         266       0.00      0.00      0.00         3\n",
      "         267       0.00      0.00      0.00         2\n",
      "         268       0.00      0.00      0.00         1\n",
      "         269       0.00      0.00      0.00         0\n",
      "         270       0.00      0.00      0.00         1\n",
      "         271       0.00      0.00      0.00         0\n",
      "         272       0.50      0.08      0.14        12\n",
      "         273       1.00      0.17      0.29         6\n",
      "         274       1.00      0.50      0.67         2\n",
      "         275       0.00      0.00      0.00         0\n",
      "         276       0.00      0.00      0.00         1\n",
      "         277       0.00      0.00      0.00         0\n",
      "         278       0.00      0.00      0.00         0\n",
      "         279       0.50      0.56      0.53       232\n",
      "         280       0.57      0.43      0.49        86\n",
      "         281       0.00      0.00      0.00         1\n",
      "         282       0.00      0.00      0.00        11\n",
      "         283       0.33      0.14      0.20        14\n",
      "         284       0.00      0.00      0.00         8\n",
      "         285       0.00      0.00      0.00         0\n",
      "         286       1.00      1.00      1.00         1\n",
      "         287       0.00      0.00      0.00         1\n",
      "         288       0.00      0.00      0.00         5\n",
      "         289       0.00      0.00      0.00         0\n",
      "         290       0.00      0.00      0.00         0\n",
      "         291       0.00      0.00      0.00         0\n",
      "         292       0.00      0.00      0.00         2\n",
      "         293       0.00      0.00      0.00         2\n",
      "         294       1.00      0.11      0.20         9\n",
      "         295       0.67      0.24      0.35        17\n",
      "         296       0.00      0.00      0.00         2\n",
      "         297       0.00      0.00      0.00         0\n",
      "         298       0.00      0.00      0.00         0\n",
      "         299       0.00      0.00      0.00         2\n",
      "         300       0.00      0.00      0.00         6\n",
      "         301       0.75      0.25      0.38        24\n",
      "         302       0.61      0.39      0.48        51\n",
      "         303       0.56      0.49      0.52        51\n",
      "         304       0.00      0.00      0.00         0\n",
      "         305       0.50      0.17      0.25         6\n",
      "         306       1.00      0.75      0.86         4\n",
      "         307       0.00      0.00      0.00         4\n",
      "         308       0.75      0.30      0.43        10\n",
      "         309       0.00      0.00      0.00         0\n",
      "         310       0.00      0.00      0.00         0\n",
      "         311       0.24      0.19      0.21        26\n",
      "         312       0.67      0.67      0.67         3\n",
      "         313       0.00      0.00      0.00         0\n",
      "         314       0.00      0.00      0.00         2\n",
      "         315       0.00      0.00      0.00         1\n",
      "         316       0.00      0.00      0.00         0\n",
      "         317       0.00      0.00      0.00         1\n",
      "         318       1.00      1.00      1.00         9\n",
      "         319       0.00      0.00      0.00         0\n",
      "         320       0.43      0.50      0.46         6\n",
      "         321       0.50      0.08      0.13        13\n",
      "         322       1.00      0.31      0.47        13\n",
      "         323       1.00      0.42      0.59        12\n",
      "         324       0.40      0.33      0.36        30\n",
      "         325       0.53      0.55      0.54        44\n",
      "         326       0.20      0.14      0.17         7\n",
      "         327       0.34      0.48      0.40       313\n",
      "         328       0.67      0.57      0.62        14\n",
      "         329       0.67      0.33      0.44         6\n",
      "         330       0.45      0.39      0.42       141\n",
      "         331       1.00      1.00      1.00         1\n",
      "         332       0.00      0.00      0.00         0\n",
      "         333       0.50      0.25      0.33        40\n",
      "         334       0.50      0.25      0.33         4\n",
      "         335       0.00      0.00      0.00         0\n",
      "         336       1.00      0.20      0.33         5\n",
      "         337       0.00      0.00      0.00         0\n",
      "         338       0.00      0.00      0.00         0\n",
      "         339       0.00      0.00      0.00         0\n",
      "         340       0.00      0.00      0.00         0\n",
      "         341       0.77      0.63      0.70        38\n",
      "         342       0.75      0.75      0.75         4\n",
      "         343       0.00      0.00      0.00         0\n",
      "         344       0.57      0.67      0.62        24\n",
      "         345       0.60      0.60      0.60         5\n",
      "         346       0.00      0.00      0.00         0\n",
      "         347       0.60      0.60      0.60        10\n",
      "         348       0.67      0.50      0.57         4\n",
      "         349       0.74      0.50      0.60        40\n",
      "         350       0.70      0.65      0.67        43\n",
      "         351       1.00      0.33      0.50         3\n",
      "         352       0.00      0.00      0.00         1\n",
      "         353       0.00      0.00      0.00         1\n",
      "         354       0.00      0.00      0.00         4\n",
      "         355       0.00      0.00      0.00         0\n",
      "         356       0.00      0.00      0.00         0\n",
      "         357       0.00      0.00      0.00         2\n",
      "         358       0.00      0.00      0.00         1\n",
      "         359       0.00      0.00      0.00         9\n",
      "         360       0.00      0.00      0.00         0\n",
      "         361       1.00      0.50      0.67         2\n",
      "         362       1.00      0.33      0.50         3\n",
      "         363       0.00      0.00      0.00         2\n",
      "         364       0.00      0.00      0.00         4\n",
      "         365       1.00      0.12      0.22         8\n",
      "         366       0.00      0.00      0.00         6\n",
      "         367       0.83      0.71      0.77        14\n",
      "         368       0.00      0.00      0.00         1\n",
      "         369       0.50      0.36      0.42        11\n",
      "         370       0.00      0.00      0.00         3\n",
      "         371       0.86      0.43      0.57        14\n",
      "         372       0.00      0.00      0.00         0\n",
      "         373       0.25      0.12      0.17         8\n",
      "         374       0.00      0.00      0.00         1\n",
      "         375       0.57      0.22      0.32        18\n",
      "         376       0.00      0.00      0.00         1\n",
      "         377       1.00      0.40      0.57         5\n",
      "         378       0.00      0.00      0.00         0\n",
      "         379       0.00      0.00      0.00         8\n",
      "         380       0.00      0.00      0.00         0\n",
      "         381       0.33      0.25      0.29         4\n",
      "         382       0.00      0.00      0.00         3\n",
      "         383       0.00      0.00      0.00         5\n",
      "         384       1.00      1.00      1.00         1\n",
      "         385       0.00      0.00      0.00         0\n",
      "         386       0.00      0.00      0.00         1\n",
      "         387       0.33      0.11      0.17         9\n",
      "         388       0.00      0.00      0.00         1\n",
      "         389       1.00      0.50      0.67         2\n",
      "         390       0.50      0.08      0.13        13\n",
      "         391       1.00      0.50      0.67         2\n",
      "         392       1.00      0.17      0.29         6\n",
      "         393       0.00      0.00      0.00         0\n",
      "         394       0.00      0.00      0.00         2\n",
      "         395       0.00      0.00      0.00         1\n",
      "         396       0.00      0.00      0.00        11\n",
      "         397       0.00      0.00      0.00         0\n",
      "         398       0.00      0.00      0.00         2\n",
      "         399       0.00      0.00      0.00         0\n",
      "         400       0.00      0.00      0.00         0\n",
      "         401       0.00      0.00      0.00         1\n",
      "         402       0.00      0.00      0.00         1\n",
      "         403       0.45      0.36      0.40        28\n",
      "         404       0.00      0.00      0.00         3\n",
      "         405       0.83      0.45      0.59        11\n",
      "         406       1.00      0.40      0.57         5\n",
      "         407       0.00      0.00      0.00         2\n",
      "         408       0.14      0.25      0.18         4\n",
      "         409       0.00      0.00      0.00         1\n",
      "         410       0.47      0.59      0.52        27\n",
      "         411       1.00      0.31      0.47        13\n",
      "         412       0.00      0.00      0.00         2\n",
      "         413       0.00      0.00      0.00         0\n",
      "         414       0.33      0.12      0.18         8\n",
      "         415       0.00      0.00      0.00         2\n",
      "         416       1.00      0.17      0.29         6\n",
      "         417       0.00      0.00      0.00         4\n",
      "         418       0.80      0.57      0.67        14\n",
      "         419       0.00      0.00      0.00         1\n",
      "         420       0.00      0.00      0.00         2\n",
      "         421       0.00      0.00      0.00         0\n",
      "         422       0.00      0.00      0.00         0\n",
      "         423       0.00      0.00      0.00         1\n",
      "         424       0.00      0.00      0.00         2\n",
      "         425       0.00      0.00      0.00         1\n",
      "         426       0.00      0.00      0.00         0\n",
      "         427       0.00      0.00      0.00         0\n",
      "         428       0.00      0.00      0.00         3\n",
      "         429       0.00      0.00      0.00         0\n",
      "         430       1.00      1.00      1.00         1\n",
      "         431       0.00      0.00      0.00         4\n",
      "         432       0.00      0.00      0.00         0\n",
      "         433       0.00      0.00      0.00         5\n",
      "         434       0.80      0.27      0.40        15\n",
      "         435       0.00      0.00      0.00         1\n",
      "         436       0.00      0.00      0.00         0\n",
      "         437       0.55      0.57      0.56       440\n",
      "         438       0.00      0.00      0.00         0\n",
      "         439       0.25      0.12      0.17         8\n",
      "         440       0.00      0.00      0.00         1\n",
      "         441       0.00      0.00      0.00         0\n",
      "         442       0.56      0.50      0.53        20\n",
      "         443       0.75      0.33      0.46        18\n",
      "         444       0.57      0.57      0.57        14\n",
      "         445       0.75      0.75      0.75        16\n",
      "         446       0.00      0.00      0.00         1\n",
      "         447       0.00      0.00      0.00         0\n",
      "         448       0.20      0.08      0.11        13\n",
      "         449       0.50      1.00      0.67         2\n",
      "         450       0.00      0.00      0.00         1\n",
      "         451       0.40      0.33      0.36         6\n",
      "         452       0.00      0.00      0.00         1\n",
      "         453       1.00      0.50      0.67         2\n",
      "         454       0.58      0.58      0.58        43\n",
      "         455       0.71      0.69      0.70        32\n",
      "         456       0.00      0.00      0.00         3\n",
      "         457       0.00      0.00      0.00         2\n",
      "         458       0.00      0.00      0.00         2\n",
      "         459       1.00      0.67      0.80         3\n",
      "         460       0.50      0.19      0.27        16\n",
      "         461       0.00      0.00      0.00         0\n",
      "         462       0.00      0.00      0.00         4\n",
      "         463       0.50      0.25      0.33        12\n",
      "         464       1.00      0.40      0.57         5\n",
      "         465       0.00      0.00      0.00         0\n",
      "         466       0.00      0.00      0.00         5\n",
      "         467       0.00      0.00      0.00         0\n",
      "         468       0.60      0.52      0.56       125\n",
      "         469       0.50      0.35      0.41        48\n",
      "         470       0.00      0.00      0.00         1\n",
      "         471       0.50      0.40      0.44         5\n",
      "         472       0.00      0.00      0.00         0\n",
      "         473       0.00      0.00      0.00         0\n",
      "         474       0.50      0.50      0.50         2\n",
      "         475       0.00      0.00      0.00         2\n",
      "         476       0.00      0.00      0.00         3\n",
      "         477       0.00      0.00      0.00         1\n",
      "         478       0.00      0.00      0.00         2\n",
      "         479       1.00      0.29      0.44         7\n",
      "         480       0.00      0.00      0.00        13\n",
      "         481       0.00      0.00      0.00         0\n",
      "         482       0.00      0.00      0.00         1\n",
      "         483       0.67      0.20      0.31        10\n",
      "         484       0.00      0.00      0.00         0\n",
      "         485       1.00      0.20      0.33        10\n",
      "         486       0.00      0.00      0.00         2\n",
      "         487       0.00      0.00      0.00         1\n",
      "         488       1.00      0.33      0.50         3\n",
      "         489       0.50      0.31      0.38        13\n",
      "         490       0.60      0.18      0.27        17\n",
      "         491       0.50      0.17      0.25        12\n",
      "         492       0.00      0.00      0.00         0\n",
      "         493       0.00      0.00      0.00         0\n",
      "         494       1.00      0.12      0.22         8\n",
      "         495       0.00      0.00      0.00        10\n",
      "         496       0.00      0.00      0.00         1\n",
      "         497       1.00      0.50      0.67         2\n",
      "         498       0.00      0.00      0.00         0\n",
      "         499       0.00      0.00      0.00         2\n",
      "         500       0.50      1.00      0.67         1\n",
      "         501       0.00      0.00      0.00         0\n",
      "         502       0.67      0.23      0.34        26\n",
      "         503       0.00      0.00      0.00         1\n",
      "         504       0.00      0.00      0.00         2\n",
      "         505       1.00      0.20      0.33         5\n",
      "         506       0.76      0.69      0.72        32\n",
      "         507       0.50      0.17      0.25         6\n",
      "         508       0.00      0.00      0.00         1\n",
      "         509       0.00      0.00      0.00         0\n",
      "         510       0.33      0.18      0.24        11\n",
      "         511       0.00      0.00      0.00         0\n",
      "         512       0.25      1.00      0.40         1\n",
      "         513       0.69      0.38      0.49        24\n",
      "         514       0.00      0.00      0.00         0\n",
      "         515       0.47      0.64      0.54        11\n",
      "         516       0.00      0.00      0.00         0\n",
      "         517       0.00      0.00      0.00         0\n",
      "         518       0.00      0.00      0.00         0\n",
      "         519       0.76      0.76      0.76        17\n",
      "         520       0.00      0.00      0.00         2\n",
      "         521       0.00      0.00      0.00         0\n",
      "         522       0.00      0.00      0.00         9\n",
      "         523       0.00      0.00      0.00         5\n",
      "         524       0.88      0.78      0.82         9\n",
      "         525       0.00      0.00      0.00         0\n",
      "         526       0.00      0.00      0.00         3\n",
      "         527       0.67      0.25      0.36         8\n",
      "         528       0.00      0.00      0.00         0\n",
      "         529       0.00      0.00      0.00         0\n",
      "         530       1.00      0.45      0.62        11\n",
      "         531       1.00      0.67      0.80         3\n",
      "         532       1.00      0.20      0.33         5\n",
      "         533       0.26      0.29      0.27       303\n",
      "         534       0.00      0.00      0.00         1\n",
      "         535       0.00      0.00      0.00         0\n",
      "         536       0.00      0.00      0.00         0\n",
      "         537       0.80      0.57      0.67         7\n",
      "         538       0.00      0.00      0.00         0\n",
      "         539       0.00      0.00      0.00         3\n",
      "         540       0.00      0.00      0.00         0\n",
      "         541       1.00      1.00      1.00         1\n",
      "         542       0.00      0.00      0.00         0\n",
      "         543       0.00      0.00      0.00         1\n",
      "         544       0.67      0.33      0.44         6\n",
      "         545       0.00      0.00      0.00         3\n",
      "         546       0.83      0.76      0.79        25\n",
      "         547       0.00      0.00      0.00         0\n",
      "         548       0.70      0.88      0.78         8\n",
      "         549       1.00      0.67      0.80         3\n",
      "         550       1.00      1.00      1.00         2\n",
      "         551       0.00      0.00      0.00         0\n",
      "         552       0.00      0.00      0.00         1\n",
      "         553       0.00      0.00      0.00         5\n",
      "         554       0.00      0.00      0.00         3\n",
      "         555       0.38      0.17      0.23        18\n",
      "         556       1.00      0.33      0.50         3\n",
      "         557       0.50      0.22      0.31         9\n",
      "         558       0.00      0.00      0.00         4\n",
      "         559       0.75      0.84      0.79        25\n",
      "         560       1.00      0.60      0.75         5\n",
      "         561       0.00      0.00      0.00         2\n",
      "         562       0.00      0.00      0.00         7\n",
      "         563       1.00      0.93      0.96        29\n",
      "         564       0.83      0.83      0.83         6\n",
      "         565       0.00      0.00      0.00         4\n",
      "         566       0.00      0.00      0.00         0\n",
      "         567       0.00      0.00      0.00         4\n",
      "         568       0.00      0.00      0.00         1\n",
      "         569       0.67      1.00      0.80         2\n",
      "         570       1.00      1.00      1.00         2\n",
      "         571       0.00      0.00      0.00         0\n",
      "         572       0.82      0.47      0.60        19\n",
      "         573       0.00      0.00      0.00         1\n",
      "         574       0.00      0.00      0.00         0\n",
      "         575       0.00      0.00      0.00         1\n",
      "         576       0.00      0.00      0.00         0\n",
      "         577       0.00      0.00      0.00         0\n",
      "         578       0.00      0.00      0.00         0\n",
      "         579       0.00      0.00      0.00         0\n",
      "         580       0.00      0.00      0.00         1\n",
      "         581       0.00      0.00      0.00         0\n",
      "         582       0.00      0.00      0.00         1\n",
      "         583       0.00      0.00      0.00         2\n",
      "         584       0.00      0.00      0.00         1\n",
      "         585       0.00      0.00      0.00         1\n",
      "         586       0.00      0.00      0.00         0\n",
      "         587       0.00      0.00      0.00         0\n",
      "         588       0.00      0.00      0.00         1\n",
      "         589       0.00      0.00      0.00         4\n",
      "         590       0.00      0.00      0.00         0\n",
      "         591       0.00      0.00      0.00         0\n",
      "         592       0.00      0.00      0.00         0\n",
      "         593       0.00      0.00      0.00         3\n",
      "         594       0.00      0.00      0.00         0\n",
      "         595       0.50      0.25      0.33         4\n",
      "         596       0.00      0.00      0.00         0\n",
      "         597       0.00      0.00      0.00         0\n",
      "         598       0.00      0.00      0.00         1\n",
      "         599       0.00      0.00      0.00         0\n",
      "         600       0.00      0.00      0.00         1\n",
      "         601       1.00      1.00      1.00         1\n",
      "         602       0.00      0.00      0.00         0\n",
      "         603       0.00      0.00      0.00         0\n",
      "         604       0.00      0.00      0.00         0\n",
      "         605       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.58      0.48      0.52      7488\n",
      "   macro avg       0.28      0.17      0.20      7488\n",
      "weighted avg       0.56      0.48      0.50      7488\n",
      " samples avg       0.46      0.50      0.47      7488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.4404537559704733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      1258\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      0.25      0.40         4\n",
      "           5       1.00      0.50      0.67         4\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.40      0.40      0.40         5\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         4\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.50      0.14      0.22        14\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       1.00      0.25      0.40         4\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.50      0.50      0.50         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.20      0.08      0.11        13\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         2\n",
      "          22       0.56      0.37      0.44        27\n",
      "          23       0.60      0.60      0.60        25\n",
      "          24       1.00      0.33      0.50         3\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         8\n",
      "          28       0.00      0.00      0.00        12\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00         6\n",
      "          31       0.00      0.00      0.00         6\n",
      "          32       1.00      0.12      0.22         8\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.56      0.56      0.56        95\n",
      "          35       0.00      0.00      0.00         2\n",
      "          36       0.50      0.12      0.20         8\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         3\n",
      "          40       0.73      0.46      0.56        24\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.20      0.25      0.22         4\n",
      "          47       0.67      0.25      0.36         8\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       1.00      0.20      0.33         5\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       1.00      0.20      0.33         5\n",
      "          56       1.00      1.00      1.00         3\n",
      "          57       1.00      0.33      0.50         3\n",
      "          58       0.00      0.00      0.00         4\n",
      "          59       0.55      0.46      0.50        13\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.33      0.17      0.22         6\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.33      0.20      0.25        15\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.50      0.20      0.29         5\n",
      "          67       0.50      1.00      0.67         1\n",
      "          68       0.54      0.37      0.44        19\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         3\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.58      0.41      0.48        17\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.56      0.48      0.52        29\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.58      0.42      0.49        26\n",
      "          79       0.75      0.62      0.68        24\n",
      "          80       0.50      0.40      0.44        20\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.50      0.44      0.47         9\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       0.62      0.47      0.54        32\n",
      "          86       0.14      0.17      0.15         6\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         5\n",
      "          90       0.00      0.00      0.00         3\n",
      "          91       0.60      0.19      0.29        16\n",
      "          92       0.40      0.29      0.33         7\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         5\n",
      "          98       1.00      0.33      0.50         3\n",
      "          99       0.00      0.00      0.00         3\n",
      "         100       1.00      0.33      0.50         3\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.42      0.31      0.36        16\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.80      0.67      0.73         6\n",
      "         105       0.17      0.11      0.13        27\n",
      "         106       1.00      0.38      0.55         8\n",
      "         107       0.67      0.44      0.53        32\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.50      0.55      0.52        33\n",
      "         110       0.50      0.17      0.25         6\n",
      "         111       0.67      0.25      0.36         8\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         2\n",
      "         116       0.40      0.33      0.36         6\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         4\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       1.00      0.50      0.67         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.50      0.36      0.42        28\n",
      "         124       0.25      0.25      0.25         4\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.25      0.20      0.22         5\n",
      "         129       0.00      0.00      0.00         2\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         3\n",
      "         135       0.00      0.00      0.00         5\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         2\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       0.38      0.23      0.29        13\n",
      "         142       0.33      0.07      0.12        14\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       0.75      0.75      0.75         4\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         0\n",
      "         150       0.23      0.22      0.22       104\n",
      "         151       0.67      0.17      0.27        12\n",
      "         152       0.50      0.33      0.40        12\n",
      "         153       1.00      0.29      0.44         7\n",
      "         154       0.50      0.30      0.37        10\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.85      0.87      0.86       373\n",
      "         160       1.00      1.00      1.00         1\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.67      0.29      0.40         7\n",
      "         163       1.00      0.67      0.80        18\n",
      "         164       0.50      0.17      0.25        12\n",
      "         165       0.00      0.00      0.00        10\n",
      "         166       0.50      0.20      0.29         5\n",
      "         167       0.00      0.00      0.00        16\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       1.00      0.50      0.67         2\n",
      "         170       0.00      0.00      0.00         1\n",
      "         171       0.73      0.67      0.70        12\n",
      "         172       0.00      0.00      0.00         6\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.41      0.41      0.41       136\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       0.28      0.26      0.27        19\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.31      0.24      0.27        21\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       0.00      0.00      0.00         2\n",
      "         181       1.00      0.75      0.86         4\n",
      "         182       0.00      0.00      0.00         2\n",
      "         183       0.00      0.00      0.00         3\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.20      0.25      0.22         4\n",
      "         186       0.00      0.00      0.00         2\n",
      "         187       0.00      0.00      0.00         3\n",
      "         188       0.00      0.00      0.00         3\n",
      "         189       0.00      0.00      0.00         2\n",
      "         190       1.00      0.25      0.40         4\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.50      0.14      0.22         7\n",
      "         194       0.50      0.22      0.31         9\n",
      "         195       1.00      0.25      0.40         4\n",
      "         196       0.00      0.00      0.00         2\n",
      "         197       1.00      0.14      0.25         7\n",
      "         198       1.00      0.50      0.67         6\n",
      "         199       1.00      0.57      0.73         7\n",
      "         200       0.18      0.19      0.18       165\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         3\n",
      "         204       0.23      0.28      0.25        75\n",
      "         205       0.21      0.15      0.17        61\n",
      "         206       0.33      0.30      0.32        10\n",
      "         207       1.00      1.00      1.00         1\n",
      "         208       0.31      0.32      0.32       115\n",
      "         209       1.00      0.25      0.40         4\n",
      "         210       0.75      0.75      0.75        16\n",
      "         211       0.00      0.00      0.00         2\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.50      0.12      0.20         8\n",
      "         216       0.50      0.11      0.18         9\n",
      "         217       0.00      0.00      0.00         2\n",
      "         218       0.83      0.71      0.77         7\n",
      "         219       0.00      0.00      0.00         2\n",
      "         220       0.00      0.00      0.00         7\n",
      "         221       0.33      0.29      0.31         7\n",
      "         222       0.00      0.00      0.00         6\n",
      "         223       0.67      0.40      0.50         5\n",
      "         224       1.00      0.12      0.22         8\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       1.00      0.33      0.50         3\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         2\n",
      "         230       0.00      0.00      0.00         6\n",
      "         231       0.00      0.00      0.00         2\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.75      0.75      0.75         8\n",
      "         234       1.00      0.33      0.50         3\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       1.00      0.80      0.89         5\n",
      "         238       0.00      0.00      0.00         2\n",
      "         239       1.00      1.00      1.00         1\n",
      "         240       0.00      0.00      0.00         2\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       0.00      0.00      0.00         0\n",
      "         243       0.68      0.57      0.62        23\n",
      "         244       0.00      0.00      0.00         1\n",
      "         245       0.00      0.00      0.00         0\n",
      "         246       0.00      0.00      0.00         1\n",
      "         247       0.00      0.00      0.00         2\n",
      "         248       0.00      0.00      0.00         0\n",
      "         249       0.58      0.52      0.55        67\n",
      "         250       0.00      0.00      0.00         1\n",
      "         251       0.50      0.44      0.47        16\n",
      "         252       0.00      0.00      0.00         0\n",
      "         253       0.00      0.00      0.00         0\n",
      "         254       0.59      0.62      0.60       299\n",
      "         255       0.00      0.00      0.00         4\n",
      "         256       0.00      0.00      0.00         4\n",
      "         257       0.00      0.00      0.00         0\n",
      "         258       1.00      0.50      0.67         4\n",
      "         259       0.75      0.43      0.55         7\n",
      "         260       1.00      0.09      0.17        11\n",
      "         261       0.00      0.00      0.00         0\n",
      "         262       0.00      0.00      0.00         0\n",
      "         263       0.00      0.00      0.00         2\n",
      "         264       0.00      0.00      0.00         3\n",
      "         265       1.00      1.00      1.00         1\n",
      "         266       0.00      0.00      0.00         3\n",
      "         267       0.00      0.00      0.00         2\n",
      "         268       0.00      0.00      0.00         1\n",
      "         269       0.00      0.00      0.00         0\n",
      "         270       0.00      0.00      0.00         1\n",
      "         271       0.00      0.00      0.00         0\n",
      "         272       0.33      0.08      0.13        12\n",
      "         273       1.00      0.17      0.29         6\n",
      "         274       1.00      0.50      0.67         2\n",
      "         275       0.00      0.00      0.00         0\n",
      "         276       0.00      0.00      0.00         1\n",
      "         277       0.00      0.00      0.00         0\n",
      "         278       0.00      0.00      0.00         0\n",
      "         279       0.46      0.51      0.49       232\n",
      "         280       0.57      0.49      0.53        86\n",
      "         281       0.00      0.00      0.00         1\n",
      "         282       0.00      0.00      0.00        11\n",
      "         283       0.17      0.07      0.10        14\n",
      "         284       0.05      0.12      0.07         8\n",
      "         285       0.00      0.00      0.00         0\n",
      "         286       0.00      0.00      0.00         1\n",
      "         287       0.00      0.00      0.00         1\n",
      "         288       0.00      0.00      0.00         5\n",
      "         289       0.00      0.00      0.00         0\n",
      "         290       0.00      0.00      0.00         0\n",
      "         291       0.00      0.00      0.00         0\n",
      "         292       0.00      0.00      0.00         2\n",
      "         293       0.00      0.00      0.00         2\n",
      "         294       0.50      0.11      0.18         9\n",
      "         295       0.83      0.29      0.43        17\n",
      "         296       0.00      0.00      0.00         2\n",
      "         297       0.00      0.00      0.00         0\n",
      "         298       0.00      0.00      0.00         0\n",
      "         299       0.00      0.00      0.00         2\n",
      "         300       0.00      0.00      0.00         6\n",
      "         301       0.60      0.25      0.35        24\n",
      "         302       0.44      0.31      0.37        51\n",
      "         303       0.42      0.51      0.46        51\n",
      "         304       0.00      0.00      0.00         0\n",
      "         305       0.50      0.17      0.25         6\n",
      "         306       1.00      0.50      0.67         4\n",
      "         307       0.00      0.00      0.00         4\n",
      "         308       1.00      0.30      0.46        10\n",
      "         309       0.00      0.00      0.00         0\n",
      "         310       0.00      0.00      0.00         0\n",
      "         311       0.21      0.23      0.22        26\n",
      "         312       0.40      0.67      0.50         3\n",
      "         313       0.00      0.00      0.00         0\n",
      "         314       0.00      0.00      0.00         2\n",
      "         315       0.00      0.00      0.00         1\n",
      "         316       0.00      0.00      0.00         0\n",
      "         317       0.00      0.00      0.00         1\n",
      "         318       0.90      1.00      0.95         9\n",
      "         319       0.00      0.00      0.00         0\n",
      "         320       0.44      0.67      0.53         6\n",
      "         321       0.00      0.00      0.00        13\n",
      "         322       0.80      0.31      0.44        13\n",
      "         323       1.00      0.42      0.59        12\n",
      "         324       0.38      0.27      0.31        30\n",
      "         325       0.46      0.52      0.49        44\n",
      "         326       0.33      0.14      0.20         7\n",
      "         327       0.29      0.42      0.34       313\n",
      "         328       0.45      0.36      0.40        14\n",
      "         329       0.75      0.50      0.60         6\n",
      "         330       0.40      0.38      0.39       141\n",
      "         331       1.00      1.00      1.00         1\n",
      "         332       0.00      0.00      0.00         0\n",
      "         333       0.44      0.20      0.28        40\n",
      "         334       0.50      0.25      0.33         4\n",
      "         335       0.00      0.00      0.00         0\n",
      "         336       1.00      0.20      0.33         5\n",
      "         337       0.00      0.00      0.00         0\n",
      "         338       0.00      0.00      0.00         0\n",
      "         339       0.00      0.00      0.00         0\n",
      "         340       0.00      0.00      0.00         0\n",
      "         341       0.74      0.61      0.67        38\n",
      "         342       0.60      0.75      0.67         4\n",
      "         343       0.00      0.00      0.00         0\n",
      "         344       0.40      0.50      0.44        24\n",
      "         345       0.50      0.40      0.44         5\n",
      "         346       0.00      0.00      0.00         0\n",
      "         347       0.60      0.60      0.60        10\n",
      "         348       0.60      0.75      0.67         4\n",
      "         349       0.69      0.50      0.58        40\n",
      "         350       0.66      0.58      0.62        43\n",
      "         351       0.00      0.00      0.00         3\n",
      "         352       0.00      0.00      0.00         1\n",
      "         353       0.00      0.00      0.00         1\n",
      "         354       0.00      0.00      0.00         4\n",
      "         355       0.00      0.00      0.00         0\n",
      "         356       0.00      0.00      0.00         0\n",
      "         357       0.00      0.00      0.00         2\n",
      "         358       0.00      0.00      0.00         1\n",
      "         359       0.00      0.00      0.00         9\n",
      "         360       0.00      0.00      0.00         0\n",
      "         361       1.00      0.50      0.67         2\n",
      "         362       0.00      0.00      0.00         3\n",
      "         363       0.00      0.00      0.00         2\n",
      "         364       0.00      0.00      0.00         4\n",
      "         365       1.00      0.12      0.22         8\n",
      "         366       1.00      0.17      0.29         6\n",
      "         367       0.60      0.86      0.71        14\n",
      "         368       0.00      0.00      0.00         1\n",
      "         369       0.29      0.18      0.22        11\n",
      "         370       0.00      0.00      0.00         3\n",
      "         371       0.50      0.21      0.30        14\n",
      "         372       0.00      0.00      0.00         0\n",
      "         373       0.10      0.12      0.11         8\n",
      "         374       0.00      0.00      0.00         1\n",
      "         375       0.30      0.17      0.21        18\n",
      "         376       0.00      0.00      0.00         1\n",
      "         377       1.00      0.20      0.33         5\n",
      "         378       0.00      0.00      0.00         0\n",
      "         379       0.00      0.00      0.00         8\n",
      "         380       0.00      0.00      0.00         0\n",
      "         381       0.33      0.25      0.29         4\n",
      "         382       0.00      0.00      0.00         3\n",
      "         383       0.00      0.00      0.00         5\n",
      "         384       1.00      1.00      1.00         1\n",
      "         385       0.00      0.00      0.00         0\n",
      "         386       0.00      0.00      0.00         1\n",
      "         387       0.11      0.11      0.11         9\n",
      "         388       0.00      0.00      0.00         1\n",
      "         389       0.00      0.00      0.00         2\n",
      "         390       1.00      0.08      0.14        13\n",
      "         391       1.00      0.50      0.67         2\n",
      "         392       0.25      0.17      0.20         6\n",
      "         393       0.00      0.00      0.00         0\n",
      "         394       0.00      0.00      0.00         2\n",
      "         395       0.00      0.00      0.00         1\n",
      "         396       0.00      0.00      0.00        11\n",
      "         397       0.00      0.00      0.00         0\n",
      "         398       0.00      0.00      0.00         2\n",
      "         399       0.00      0.00      0.00         0\n",
      "         400       0.00      0.00      0.00         0\n",
      "         401       0.00      0.00      0.00         1\n",
      "         402       0.00      0.00      0.00         1\n",
      "         403       0.33      0.32      0.33        28\n",
      "         404       0.00      0.00      0.00         3\n",
      "         405       0.64      0.64      0.64        11\n",
      "         406       1.00      0.40      0.57         5\n",
      "         407       0.00      0.00      0.00         2\n",
      "         408       0.00      0.00      0.00         4\n",
      "         409       0.00      0.00      0.00         1\n",
      "         410       0.42      0.52      0.47        27\n",
      "         411       1.00      0.31      0.47        13\n",
      "         412       0.00      0.00      0.00         2\n",
      "         413       0.00      0.00      0.00         0\n",
      "         414       0.12      0.12      0.12         8\n",
      "         415       0.00      0.00      0.00         2\n",
      "         416       0.67      0.33      0.44         6\n",
      "         417       0.00      0.00      0.00         4\n",
      "         418       0.47      0.50      0.48        14\n",
      "         419       0.00      0.00      0.00         1\n",
      "         420       0.00      0.00      0.00         2\n",
      "         421       0.00      0.00      0.00         0\n",
      "         422       0.00      0.00      0.00         0\n",
      "         423       0.00      0.00      0.00         1\n",
      "         424       0.00      0.00      0.00         2\n",
      "         425       0.00      0.00      0.00         1\n",
      "         426       0.00      0.00      0.00         0\n",
      "         427       0.00      0.00      0.00         0\n",
      "         428       0.00      0.00      0.00         3\n",
      "         429       0.00      0.00      0.00         0\n",
      "         430       1.00      1.00      1.00         1\n",
      "         431       0.00      0.00      0.00         4\n",
      "         432       0.00      0.00      0.00         0\n",
      "         433       0.00      0.00      0.00         5\n",
      "         434       0.67      0.27      0.38        15\n",
      "         435       0.00      0.00      0.00         1\n",
      "         436       0.00      0.00      0.00         0\n",
      "         437       0.52      0.56      0.54       440\n",
      "         438       0.00      0.00      0.00         0\n",
      "         439       0.00      0.00      0.00         8\n",
      "         440       0.00      0.00      0.00         1\n",
      "         441       0.00      0.00      0.00         0\n",
      "         442       0.40      0.50      0.44        20\n",
      "         443       0.58      0.61      0.59        18\n",
      "         444       0.36      0.36      0.36        14\n",
      "         445       0.58      0.69      0.63        16\n",
      "         446       0.00      0.00      0.00         1\n",
      "         447       0.00      0.00      0.00         0\n",
      "         448       0.40      0.15      0.22        13\n",
      "         449       0.40      1.00      0.57         2\n",
      "         450       0.00      0.00      0.00         1\n",
      "         451       0.50      0.33      0.40         6\n",
      "         452       0.00      0.00      0.00         1\n",
      "         453       1.00      0.50      0.67         2\n",
      "         454       0.56      0.47      0.51        43\n",
      "         455       0.70      0.72      0.71        32\n",
      "         456       0.00      0.00      0.00         3\n",
      "         457       0.00      0.00      0.00         2\n",
      "         458       0.00      0.00      0.00         2\n",
      "         459       1.00      0.33      0.50         3\n",
      "         460       0.50      0.19      0.27        16\n",
      "         461       0.00      0.00      0.00         0\n",
      "         462       0.00      0.00      0.00         4\n",
      "         463       0.50      0.25      0.33        12\n",
      "         464       1.00      0.40      0.57         5\n",
      "         465       0.00      0.00      0.00         0\n",
      "         466       0.00      0.00      0.00         5\n",
      "         467       0.00      0.00      0.00         0\n",
      "         468       0.54      0.51      0.52       125\n",
      "         469       0.38      0.38      0.38        48\n",
      "         470       1.00      1.00      1.00         1\n",
      "         471       0.50      0.60      0.55         5\n",
      "         472       0.00      0.00      0.00         0\n",
      "         473       0.00      0.00      0.00         0\n",
      "         474       0.00      0.00      0.00         2\n",
      "         475       0.00      0.00      0.00         2\n",
      "         476       0.00      0.00      0.00         3\n",
      "         477       0.00      0.00      0.00         1\n",
      "         478       0.00      0.00      0.00         2\n",
      "         479       0.67      0.29      0.40         7\n",
      "         480       0.00      0.00      0.00        13\n",
      "         481       0.00      0.00      0.00         0\n",
      "         482       0.00      0.00      0.00         1\n",
      "         483       0.25      0.20      0.22        10\n",
      "         484       0.00      0.00      0.00         0\n",
      "         485       1.00      0.10      0.18        10\n",
      "         486       0.00      0.00      0.00         2\n",
      "         487       0.00      0.00      0.00         1\n",
      "         488       1.00      0.33      0.50         3\n",
      "         489       0.36      0.31      0.33        13\n",
      "         490       0.57      0.24      0.33        17\n",
      "         491       0.27      0.25      0.26        12\n",
      "         492       0.00      0.00      0.00         0\n",
      "         493       0.00      0.00      0.00         0\n",
      "         494       0.00      0.00      0.00         8\n",
      "         495       0.00      0.00      0.00        10\n",
      "         496       0.00      0.00      0.00         1\n",
      "         497       1.00      0.50      0.67         2\n",
      "         498       0.00      0.00      0.00         0\n",
      "         499       0.00      0.00      0.00         2\n",
      "         500       0.00      0.00      0.00         1\n",
      "         501       0.00      0.00      0.00         0\n",
      "         502       0.47      0.27      0.34        26\n",
      "         503       0.00      0.00      0.00         1\n",
      "         504       0.00      0.00      0.00         2\n",
      "         505       1.00      0.20      0.33         5\n",
      "         506       0.71      0.69      0.70        32\n",
      "         507       0.50      0.17      0.25         6\n",
      "         508       0.00      0.00      0.00         1\n",
      "         509       0.00      0.00      0.00         0\n",
      "         510       0.67      0.18      0.29        11\n",
      "         511       0.00      0.00      0.00         0\n",
      "         512       0.33      1.00      0.50         1\n",
      "         513       0.60      0.38      0.46        24\n",
      "         514       0.00      0.00      0.00         0\n",
      "         515       0.37      0.64      0.47        11\n",
      "         516       0.00      0.00      0.00         0\n",
      "         517       0.00      0.00      0.00         0\n",
      "         518       0.00      0.00      0.00         0\n",
      "         519       0.55      0.65      0.59        17\n",
      "         520       0.00      0.00      0.00         2\n",
      "         521       0.00      0.00      0.00         0\n",
      "         522       0.00      0.00      0.00         9\n",
      "         523       0.00      0.00      0.00         5\n",
      "         524       0.82      1.00      0.90         9\n",
      "         525       0.00      0.00      0.00         0\n",
      "         526       1.00      0.67      0.80         3\n",
      "         527       0.50      0.25      0.33         8\n",
      "         528       0.00      0.00      0.00         0\n",
      "         529       0.00      0.00      0.00         0\n",
      "         530       1.00      0.27      0.43        11\n",
      "         531       0.40      0.67      0.50         3\n",
      "         532       0.67      0.40      0.50         5\n",
      "         533       0.23      0.27      0.25       303\n",
      "         534       0.00      0.00      0.00         1\n",
      "         535       0.00      0.00      0.00         0\n",
      "         536       0.00      0.00      0.00         0\n",
      "         537       1.00      0.43      0.60         7\n",
      "         538       0.00      0.00      0.00         0\n",
      "         539       1.00      0.33      0.50         3\n",
      "         540       0.00      0.00      0.00         0\n",
      "         541       1.00      1.00      1.00         1\n",
      "         542       0.00      0.00      0.00         0\n",
      "         543       0.00      0.00      0.00         1\n",
      "         544       0.60      0.50      0.55         6\n",
      "         545       0.00      0.00      0.00         3\n",
      "         546       0.83      0.76      0.79        25\n",
      "         547       0.00      0.00      0.00         0\n",
      "         548       0.62      1.00      0.76         8\n",
      "         549       1.00      0.33      0.50         3\n",
      "         550       1.00      1.00      1.00         2\n",
      "         551       0.00      0.00      0.00         0\n",
      "         552       0.00      0.00      0.00         1\n",
      "         553       0.00      0.00      0.00         5\n",
      "         554       0.00      0.00      0.00         3\n",
      "         555       0.40      0.22      0.29        18\n",
      "         556       1.00      0.33      0.50         3\n",
      "         557       0.50      0.22      0.31         9\n",
      "         558       0.00      0.00      0.00         4\n",
      "         559       0.74      0.80      0.77        25\n",
      "         560       1.00      0.60      0.75         5\n",
      "         561       0.00      0.00      0.00         2\n",
      "         562       0.00      0.00      0.00         7\n",
      "         563       1.00      0.97      0.98        29\n",
      "         564       0.67      0.67      0.67         6\n",
      "         565       0.00      0.00      0.00         4\n",
      "         566       0.00      0.00      0.00         0\n",
      "         567       0.00      0.00      0.00         4\n",
      "         568       0.00      0.00      0.00         1\n",
      "         569       0.22      1.00      0.36         2\n",
      "         570       1.00      1.00      1.00         2\n",
      "         571       0.00      0.00      0.00         0\n",
      "         572       0.78      0.37      0.50        19\n",
      "         573       0.00      0.00      0.00         1\n",
      "         574       0.00      0.00      0.00         0\n",
      "         575       0.00      0.00      0.00         1\n",
      "         576       0.00      0.00      0.00         0\n",
      "         577       0.00      0.00      0.00         0\n",
      "         578       0.00      0.00      0.00         0\n",
      "         579       0.00      0.00      0.00         0\n",
      "         580       0.00      0.00      0.00         1\n",
      "         581       0.00      0.00      0.00         0\n",
      "         582       0.00      0.00      0.00         1\n",
      "         583       0.00      0.00      0.00         2\n",
      "         584       0.00      0.00      0.00         1\n",
      "         585       0.00      0.00      0.00         1\n",
      "         586       0.00      0.00      0.00         0\n",
      "         587       0.00      0.00      0.00         0\n",
      "         588       0.00      0.00      0.00         1\n",
      "         589       0.00      0.00      0.00         4\n",
      "         590       0.00      0.00      0.00         0\n",
      "         591       0.00      0.00      0.00         0\n",
      "         592       0.00      0.00      0.00         0\n",
      "         593       0.00      0.00      0.00         3\n",
      "         594       0.00      0.00      0.00         0\n",
      "         595       1.00      0.25      0.40         4\n",
      "         596       0.00      0.00      0.00         0\n",
      "         597       0.00      0.00      0.00         0\n",
      "         598       0.00      0.00      0.00         1\n",
      "         599       0.00      0.00      0.00         0\n",
      "         600       0.00      0.00      0.00         1\n",
      "         601       1.00      1.00      1.00         1\n",
      "         602       0.00      0.00      0.00         0\n",
      "         603       0.00      0.00      0.00         0\n",
      "         604       0.00      0.00      0.00         0\n",
      "         605       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.51      0.46      0.48      7488\n",
      "   macro avg       0.25      0.17      0.18      7488\n",
      "weighted avg       0.50      0.46      0.46      7488\n",
      " samples avg       0.43      0.48      0.44      7488\n",
      "\n",
      "CPU times: user 1min 13s, sys: 1.22 s, total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline_2.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipeline_2.predict(X_test)\n",
    "f1 = f1_score(y_test , y_pred,average='samples')\n",
    "print('f1_score samples : ',f1)\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelles sont les colonnes les plus importanes ?\n",
    "Nous cosntruisons un SVM pour chaqune des colonnes et observons les différents scores obtenues : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "FABRICANT\n",
      "f1_score samples :  0.15534010335785517\n",
      "##############################\n",
      "DESCRIPTION_INCIDENT\n",
      "f1_score samples :  0.47272844598832436\n",
      "##############################\n",
      "ETAT_PATIENT\n",
      "f1_score samples :  0.18282027382444876\n",
      "##############################\n",
      "ACTION_PATIENT\n",
      "f1_score samples :  0.14914207939847482\n"
     ]
    }
   ],
   "source": [
    "pipeline_col =Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(sublinear_tf=True, min_df=2,\n",
    "                            ngram_range=(1, 1),\n",
    "                            stop_words=STOP_WORDS,\n",
    "                            max_features = 10000,norm = 'l2')),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])\n",
    "PRED = []\n",
    "for col in ['FABRICANT','DESCRIPTION_INCIDENT','ETAT_PATIENT','ACTION_PATIENT'] :\n",
    "    x_train,x_test = X_train[col],X_test[col]\n",
    "    pipeline_col.fit(x_train,y_train)\n",
    "    pred= pipeline_col.predict(x_test)\n",
    "    PRED.append(pred)\n",
    "    f1 = f1_score(y_test , pred,average='samples')\n",
    "    print('##############################')\n",
    "    print(col)\n",
    "    print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For threshold:  0.4\n",
      "Samples-average quality numbers\n",
      "Precision: 0.2116, Recall: 0.6493, F1-measure: 0.2787\n",
      "For threshold:  0.5\n",
      "Samples-average quality numbers\n",
      "Precision: 0.2116, Recall: 0.6493, F1-measure: 0.2787\n",
      "For threshold:  0.6\n",
      "Samples-average quality numbers\n",
      "Precision: 0.3320, Recall: 0.4322, F1-measure: 0.3535\n",
      "For threshold:  0.65\n",
      "Samples-average quality numbers\n",
      "Precision: 0.3320, Recall: 0.4322, F1-measure: 0.3535\n",
      "For threshold:  0.7\n",
      "Samples-average quality numbers\n",
      "Precision: 0.3320, Recall: 0.4322, F1-measure: 0.3535\n",
      "For threshold:  0.72\n",
      "Samples-average quality numbers\n",
      "Precision: 0.3320, Recall: 0.4322, F1-measure: 0.3535\n",
      "For threshold:  0.75\n",
      "Samples-average quality numbers\n",
      "Precision: 0.3320, Recall: 0.4322, F1-measure: 0.3535\n",
      "For threshold:  0.8\n",
      "Samples-average quality numbers\n",
      "Precision: 0.2126, Recall: 0.2124, F1-measure: 0.2097\n"
     ]
    }
   ],
   "source": [
    "y_e = np.mean(PRED,axis=0)\n",
    "thresholds = [0.4,0.5,0.6,0.65,0.7,0.72,0.75,0.8]\n",
    "for val in thresholds:\n",
    "    print(\"For threshold: \", val)\n",
    "    pred=y_e.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "  \n",
    "    precision = precision_score(y_test, pred, average='samples')\n",
    "    recall = recall_score(y_test, pred, average='samples')\n",
    "    f1 = f1_score(y_test, pred, average='samples')\n",
    "   \n",
    "    print(\"Samples-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commentaire : \n",
    "\n",
    "La colonne DESCRIPTION_INCIDENT sempble de loin la plus importante en ce qui concerne la prédiction de l'effet.\n",
    "\n",
    " \n",
    "## 2.0 L'approche Multioutput\n",
    "\n",
    "> Multioutput classification support can be added to any classifier with MultiOutputClassifier. This strategy consists of fitting one classifier per target. This allows multiple target variable classifications. The purpose of this class is to extend estimators to be able to estimate a series of target functions (f1,f2,f3…,fn) that are trained on a single X predictor matrix to predict a series of responses (y1,y2,y3…,yn).\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.4664546244029526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', MultiOutputClassifier(LinearSVC(class_weight='balanced'))),\n",
    "])\n",
    "#### prédiction \n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test , y_pred,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "Comme attendu, nous n'observons pas de grande différence car les deux approches sont très similaires\n",
    "\n",
    "## 2.1 Approche One vs One\n",
    "\n",
    ">This strategy consists in fitting one classifier per class pair. At prediction time, the class which received the most votes is selected. Since it requires to fit n_classes * (n_classes - 1) / 2 classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don’t scale well with n_samples. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used n_classes times.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score samples :  0.4664546244029526\n",
      "CPU times: user 1min 11s, sys: 1.36 s, total: 1min 13s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', preprocess),\n",
    "    ('clf', MultiOutputClassifier(OneVsOneClassifier(LinearSVC(class_weight='balanced')))),\n",
    "])\n",
    "#### prédiction \n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test , y_pred,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "Nous n'oservons pas de changement de performances, seulement une hausse du temps de calcul\n",
    "## 2.2 l'approche ClassifierChain\n",
    ">A multi-label model that arranges binary classifiers into a chain.\n",
    "Each model makes a prediction in the order specified by the chain using all of the available features provided to the model plus the predictions of models that are earlier in the chain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5066521927920105\n",
      "CPU times: user 29min 40s, sys: 21.1 s, total: 30min 1s\n",
      "Wall time: 30min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_, X_test_ =preprocess.fit_transform(X_train),preprocess.transform(X_test)\n",
    "clf = LinearSVC(class_weight='balanced')\n",
    "\n",
    "\n",
    "chains = [ClassifierChain(clf, order='random', random_state=i) for i in range(10)]\n",
    "\n",
    "for chain in chains:\n",
    "    chain.fit(X_train_, y_train)\n",
    "    \n",
    "y_pred_chains = np.array([chain.predict(X_test_) for chain in chains])\n",
    "\n",
    "chain_f1_scores = [f1_score(y_test, y_pred_chain, average='samples') for y_pred_chain in y_pred_chains]\n",
    "\n",
    "y_pred_ensemble = y_pred_chains.mean(axis=0)\n",
    "\n",
    "y_e = y_pred_ensemble>=0.4\n",
    "\n",
    "ensemble_f1_score = f1_score(y_test,y_e, average='samples')\n",
    "\n",
    "print(ensemble_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.80      0.72      1258\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      0.25      0.40         4\n",
      "           5       1.00      0.50      0.67         4\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.38      0.60      0.46         5\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         4\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.40      0.14      0.21        14\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       1.00      0.25      0.40         4\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.30      0.23      0.26        13\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         2\n",
      "          22       0.50      0.33      0.40        27\n",
      "          23       0.67      0.80      0.73        25\n",
      "          24       1.00      0.33      0.50         3\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         8\n",
      "          28       0.20      0.08      0.12        12\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00         6\n",
      "          31       0.00      0.00      0.00         6\n",
      "          32       1.00      0.12      0.22         8\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.67      0.56      0.61        95\n",
      "          35       0.00      0.00      0.00         2\n",
      "          36       0.00      0.00      0.00         8\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         3\n",
      "          40       0.76      0.54      0.63        24\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.20      0.25      0.22         4\n",
      "          47       0.50      0.25      0.33         8\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         5\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         0\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       1.00      0.20      0.33         5\n",
      "          56       1.00      1.00      1.00         3\n",
      "          57       1.00      0.33      0.50         3\n",
      "          58       0.00      0.00      0.00         4\n",
      "          59       0.78      0.54      0.64        13\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       1.00      0.17      0.29         6\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.40      0.27      0.32        15\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       1.00      0.40      0.57         5\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.53      0.47      0.50        19\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         3\n",
      "          71       0.00      0.00      0.00         0\n",
      "          72       0.50      0.35      0.41        17\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.61      0.38      0.47        29\n",
      "          75       0.00      0.00      0.00         0\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.71      0.46      0.56        26\n",
      "          79       0.79      0.62      0.70        24\n",
      "          80       0.42      0.40      0.41        20\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.75      0.67      0.71         9\n",
      "          84       0.00      0.00      0.00         2\n",
      "          85       0.68      0.59      0.63        32\n",
      "          86       0.25      0.33      0.29         6\n",
      "          87       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.00      0.00      0.00         5\n",
      "          90       0.00      0.00      0.00         3\n",
      "          91       0.50      0.12      0.20        16\n",
      "          92       1.00      0.29      0.44         7\n",
      "          93       0.00      0.00      0.00         2\n",
      "          94       0.00      0.00      0.00         2\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         0\n",
      "          97       1.00      0.20      0.33         5\n",
      "          98       1.00      0.33      0.50         3\n",
      "          99       0.00      0.00      0.00         3\n",
      "         100       0.50      0.33      0.40         3\n",
      "         101       0.00      0.00      0.00         0\n",
      "         102       0.46      0.38      0.41        16\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.80      0.67      0.73         6\n",
      "         105       0.23      0.11      0.15        27\n",
      "         106       0.67      0.25      0.36         8\n",
      "         107       0.84      0.50      0.63        32\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.44      0.52      0.47        33\n",
      "         110       1.00      0.17      0.29         6\n",
      "         111       1.00      0.25      0.40         8\n",
      "         112       0.00      0.00      0.00         3\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         2\n",
      "         116       0.50      0.33      0.40         6\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         4\n",
      "         119       0.00      0.00      0.00         0\n",
      "         120       0.00      0.00      0.00         0\n",
      "         121       1.00      0.50      0.67         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.58      0.39      0.47        28\n",
      "         124       1.00      0.25      0.40         4\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.50      0.40      0.44         5\n",
      "         129       0.00      0.00      0.00         2\n",
      "         130       0.00      0.00      0.00         0\n",
      "         131       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         3\n",
      "         135       0.00      0.00      0.00         5\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         2\n",
      "         138       0.00      0.00      0.00         0\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       0.50      0.23      0.32        13\n",
      "         142       1.00      0.14      0.25        14\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       0.00      0.00      0.00         0\n",
      "         145       1.00      0.75      0.86         4\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.00      0.00      0.00         0\n",
      "         150       0.32      0.31      0.32       104\n",
      "         151       0.67      0.17      0.27        12\n",
      "         152       0.60      0.25      0.35        12\n",
      "         153       1.00      0.29      0.44         7\n",
      "         154       1.00      0.20      0.33        10\n",
      "         155       0.00      0.00      0.00         0\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.00      0.00      0.00         2\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.81      0.93      0.87       373\n",
      "         160       1.00      1.00      1.00         1\n",
      "         161       0.00      0.00      0.00         0\n",
      "         162       0.67      0.29      0.40         7\n",
      "         163       0.87      0.72      0.79        18\n",
      "         164       0.67      0.17      0.27        12\n",
      "         165       0.00      0.00      0.00        10\n",
      "         166       0.67      0.40      0.50         5\n",
      "         167       0.00      0.00      0.00        16\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       1.00      0.50      0.67         2\n",
      "         170       0.00      0.00      0.00         1\n",
      "         171       0.69      0.75      0.72        12\n",
      "         172       0.00      0.00      0.00         6\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.49      0.50      0.50       136\n",
      "         175       0.00      0.00      0.00         1\n",
      "         176       0.33      0.26      0.29        19\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       0.37      0.48      0.42        21\n",
      "         179       0.33      1.00      0.50         1\n",
      "         180       0.00      0.00      0.00         2\n",
      "         181       0.67      1.00      0.80         4\n",
      "         182       0.00      0.00      0.00         2\n",
      "         183       0.00      0.00      0.00         3\n",
      "         184       0.00      0.00      0.00         0\n",
      "         185       0.00      0.00      0.00         4\n",
      "         186       0.00      0.00      0.00         2\n",
      "         187       0.00      0.00      0.00         3\n",
      "         188       0.00      0.00      0.00         3\n",
      "         189       0.00      0.00      0.00         2\n",
      "         190       0.50      0.25      0.33         4\n",
      "         191       0.00      0.00      0.00         0\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.50      0.14      0.22         7\n",
      "         194       1.00      0.11      0.20         9\n",
      "         195       1.00      0.25      0.40         4\n",
      "         196       0.00      0.00      0.00         2\n",
      "         197       1.00      0.14      0.25         7\n",
      "         198       0.50      0.33      0.40         6\n",
      "         199       1.00      0.57      0.73         7\n",
      "         200       0.19      0.21      0.20       165\n",
      "         201       0.00      0.00      0.00         0\n",
      "         202       0.00      0.00      0.00         0\n",
      "         203       0.00      0.00      0.00         3\n",
      "         204       0.31      0.35      0.33        75\n",
      "         205       0.31      0.18      0.23        61\n",
      "         206       0.67      0.40      0.50        10\n",
      "         207       0.00      0.00      0.00         1\n",
      "         208       0.36      0.37      0.36       115\n",
      "         209       1.00      0.25      0.40         4\n",
      "         210       0.62      0.81      0.70        16\n",
      "         211       0.00      0.00      0.00         2\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         8\n",
      "         216       1.00      0.11      0.20         9\n",
      "         217       0.00      0.00      0.00         2\n",
      "         218       1.00      0.43      0.60         7\n",
      "         219       0.00      0.00      0.00         2\n",
      "         220       0.00      0.00      0.00         7\n",
      "         221       1.00      0.29      0.44         7\n",
      "         222       0.67      0.33      0.44         6\n",
      "         223       0.80      0.80      0.80         5\n",
      "         224       0.00      0.00      0.00         8\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       1.00      0.33      0.50         3\n",
      "         228       0.00      0.00      0.00         0\n",
      "         229       0.00      0.00      0.00         2\n",
      "         230       0.33      0.17      0.22         6\n",
      "         231       0.00      0.00      0.00         2\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       0.75      0.75      0.75         8\n",
      "         234       0.00      0.00      0.00         3\n",
      "         235       0.50      1.00      0.67         1\n",
      "         236       0.00      0.00      0.00         0\n",
      "         237       1.00      0.60      0.75         5\n",
      "         238       0.00      0.00      0.00         2\n",
      "         239       1.00      1.00      1.00         1\n",
      "         240       0.00      0.00      0.00         2\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       0.00      0.00      0.00         0\n",
      "         243       0.82      0.61      0.70        23\n",
      "         244       0.00      0.00      0.00         1\n",
      "         245       0.00      0.00      0.00         0\n",
      "         246       0.00      0.00      0.00         1\n",
      "         247       0.00      0.00      0.00         2\n",
      "         248       0.00      0.00      0.00         0\n",
      "         249       0.71      0.54      0.61        67\n",
      "         250       0.00      0.00      0.00         1\n",
      "         251       0.67      0.38      0.48        16\n",
      "         252       0.00      0.00      0.00         0\n",
      "         253       0.00      0.00      0.00         0\n",
      "         254       0.61      0.78      0.68       299\n",
      "         255       0.00      0.00      0.00         4\n",
      "         256       0.00      0.00      0.00         4\n",
      "         257       0.00      0.00      0.00         0\n",
      "         258       1.00      0.50      0.67         4\n",
      "         259       1.00      0.29      0.44         7\n",
      "         260       0.50      0.09      0.15        11\n",
      "         261       0.00      0.00      0.00         0\n",
      "         262       0.00      0.00      0.00         0\n",
      "         263       0.00      0.00      0.00         2\n",
      "         264       0.00      0.00      0.00         3\n",
      "         265       1.00      1.00      1.00         1\n",
      "         266       0.00      0.00      0.00         3\n",
      "         267       0.00      0.00      0.00         2\n",
      "         268       0.00      0.00      0.00         1\n",
      "         269       0.00      0.00      0.00         0\n",
      "         270       0.00      0.00      0.00         1\n",
      "         271       0.00      0.00      0.00         0\n",
      "         272       0.67      0.17      0.27        12\n",
      "         273       1.00      0.17      0.29         6\n",
      "         274       1.00      0.50      0.67         2\n",
      "         275       0.00      0.00      0.00         0\n",
      "         276       0.00      0.00      0.00         1\n",
      "         277       0.00      0.00      0.00         0\n",
      "         278       0.00      0.00      0.00         0\n",
      "         279       0.45      0.58      0.51       232\n",
      "         280       0.57      0.45      0.51        86\n",
      "         281       0.00      0.00      0.00         1\n",
      "         282       0.00      0.00      0.00        11\n",
      "         283       0.33      0.14      0.20        14\n",
      "         284       0.00      0.00      0.00         8\n",
      "         285       0.00      0.00      0.00         0\n",
      "         286       1.00      1.00      1.00         1\n",
      "         287       0.00      0.00      0.00         1\n",
      "         288       0.00      0.00      0.00         5\n",
      "         289       0.00      0.00      0.00         0\n",
      "         290       0.00      0.00      0.00         0\n",
      "         291       0.00      0.00      0.00         0\n",
      "         292       0.00      0.00      0.00         2\n",
      "         293       0.00      0.00      0.00         2\n",
      "         294       1.00      0.11      0.20         9\n",
      "         295       0.71      0.29      0.42        17\n",
      "         296       0.00      0.00      0.00         2\n",
      "         297       0.00      0.00      0.00         0\n",
      "         298       0.00      0.00      0.00         0\n",
      "         299       0.00      0.00      0.00         2\n",
      "         300       0.00      0.00      0.00         6\n",
      "         301       0.75      0.25      0.38        24\n",
      "         302       0.56      0.37      0.45        51\n",
      "         303       0.53      0.57      0.55        51\n",
      "         304       0.00      0.00      0.00         0\n",
      "         305       0.50      0.17      0.25         6\n",
      "         306       1.00      0.75      0.86         4\n",
      "         307       0.00      0.00      0.00         4\n",
      "         308       0.80      0.40      0.53        10\n",
      "         309       0.00      0.00      0.00         0\n",
      "         310       0.00      0.00      0.00         0\n",
      "         311       0.27      0.23      0.25        26\n",
      "         312       0.40      0.67      0.50         3\n",
      "         313       0.00      0.00      0.00         0\n",
      "         314       0.00      0.00      0.00         2\n",
      "         315       0.00      0.00      0.00         1\n",
      "         316       0.00      0.00      0.00         0\n",
      "         317       0.00      0.00      0.00         1\n",
      "         318       0.90      1.00      0.95         9\n",
      "         319       0.00      0.00      0.00         0\n",
      "         320       0.38      0.50      0.43         6\n",
      "         321       0.67      0.15      0.25        13\n",
      "         322       1.00      0.31      0.47        13\n",
      "         323       1.00      0.42      0.59        12\n",
      "         324       0.43      0.43      0.43        30\n",
      "         325       0.55      0.68      0.61        44\n",
      "         326       0.33      0.14      0.20         7\n",
      "         327       0.30      0.50      0.38       313\n",
      "         328       0.62      0.57      0.59        14\n",
      "         329       0.67      0.33      0.44         6\n",
      "         330       0.42      0.35      0.38       141\n",
      "         331       1.00      1.00      1.00         1\n",
      "         332       0.00      0.00      0.00         0\n",
      "         333       0.42      0.28      0.33        40\n",
      "         334       1.00      0.25      0.40         4\n",
      "         335       0.00      0.00      0.00         0\n",
      "         336       1.00      0.20      0.33         5\n",
      "         337       0.00      0.00      0.00         0\n",
      "         338       0.00      0.00      0.00         0\n",
      "         339       0.00      0.00      0.00         0\n",
      "         340       0.00      0.00      0.00         0\n",
      "         341       0.80      0.63      0.71        38\n",
      "         342       0.75      0.75      0.75         4\n",
      "         343       0.00      0.00      0.00         0\n",
      "         344       0.57      0.67      0.62        24\n",
      "         345       0.50      0.40      0.44         5\n",
      "         346       0.00      0.00      0.00         0\n",
      "         347       0.60      0.60      0.60        10\n",
      "         348       0.75      0.75      0.75         4\n",
      "         349       0.74      0.50      0.60        40\n",
      "         350       0.71      0.67      0.69        43\n",
      "         351       1.00      0.33      0.50         3\n",
      "         352       0.00      0.00      0.00         1\n",
      "         353       0.00      0.00      0.00         1\n",
      "         354       0.00      0.00      0.00         4\n",
      "         355       0.00      0.00      0.00         0\n",
      "         356       0.00      0.00      0.00         0\n",
      "         357       0.00      0.00      0.00         2\n",
      "         358       0.00      0.00      0.00         1\n",
      "         359       0.00      0.00      0.00         9\n",
      "         360       0.00      0.00      0.00         0\n",
      "         361       1.00      0.50      0.67         2\n",
      "         362       1.00      0.33      0.50         3\n",
      "         363       0.00      0.00      0.00         2\n",
      "         364       0.00      0.00      0.00         4\n",
      "         365       1.00      0.12      0.22         8\n",
      "         366       0.00      0.00      0.00         6\n",
      "         367       0.75      0.86      0.80        14\n",
      "         368       0.00      0.00      0.00         1\n",
      "         369       0.50      0.36      0.42        11\n",
      "         370       0.00      0.00      0.00         3\n",
      "         371       0.86      0.43      0.57        14\n",
      "         372       0.00      0.00      0.00         0\n",
      "         373       0.17      0.12      0.14         8\n",
      "         374       0.00      0.00      0.00         1\n",
      "         375       0.57      0.22      0.32        18\n",
      "         376       0.00      0.00      0.00         1\n",
      "         377       1.00      0.40      0.57         5\n",
      "         378       0.00      0.00      0.00         0\n",
      "         379       0.25      0.12      0.17         8\n",
      "         380       0.00      0.00      0.00         0\n",
      "         381       0.33      0.25      0.29         4\n",
      "         382       0.00      0.00      0.00         3\n",
      "         383       0.00      0.00      0.00         5\n",
      "         384       1.00      1.00      1.00         1\n",
      "         385       0.00      0.00      0.00         0\n",
      "         386       0.00      0.00      0.00         1\n",
      "         387       0.25      0.11      0.15         9\n",
      "         388       0.00      0.00      0.00         1\n",
      "         389       1.00      0.50      0.67         2\n",
      "         390       0.50      0.08      0.13        13\n",
      "         391       1.00      0.50      0.67         2\n",
      "         392       1.00      0.17      0.29         6\n",
      "         393       0.00      0.00      0.00         0\n",
      "         394       0.00      0.00      0.00         2\n",
      "         395       0.00      0.00      0.00         1\n",
      "         396       0.00      0.00      0.00        11\n",
      "         397       0.00      0.00      0.00         0\n",
      "         398       0.00      0.00      0.00         2\n",
      "         399       0.00      0.00      0.00         0\n",
      "         400       0.00      0.00      0.00         0\n",
      "         401       0.00      0.00      0.00         1\n",
      "         402       0.00      0.00      0.00         1\n",
      "         403       0.36      0.36      0.36        28\n",
      "         404       0.00      0.00      0.00         3\n",
      "         405       0.71      0.45      0.56        11\n",
      "         406       0.67      0.40      0.50         5\n",
      "         407       0.00      0.00      0.00         2\n",
      "         408       0.11      0.25      0.15         4\n",
      "         409       0.00      0.00      0.00         1\n",
      "         410       0.45      0.63      0.52        27\n",
      "         411       0.80      0.31      0.44        13\n",
      "         412       0.00      0.00      0.00         2\n",
      "         413       0.00      0.00      0.00         0\n",
      "         414       0.40      0.25      0.31         8\n",
      "         415       0.00      0.00      0.00         2\n",
      "         416       1.00      0.17      0.29         6\n",
      "         417       0.00      0.00      0.00         4\n",
      "         418       0.67      0.57      0.62        14\n",
      "         419       0.00      0.00      0.00         1\n",
      "         420       0.00      0.00      0.00         2\n",
      "         421       0.00      0.00      0.00         0\n",
      "         422       0.00      0.00      0.00         0\n",
      "         423       0.00      0.00      0.00         1\n",
      "         424       0.00      0.00      0.00         2\n",
      "         425       0.00      0.00      0.00         1\n",
      "         426       0.00      0.00      0.00         0\n",
      "         427       0.00      0.00      0.00         0\n",
      "         428       0.00      0.00      0.00         3\n",
      "         429       0.00      0.00      0.00         0\n",
      "         430       1.00      1.00      1.00         1\n",
      "         431       0.00      0.00      0.00         4\n",
      "         432       0.00      0.00      0.00         0\n",
      "         433       0.00      0.00      0.00         5\n",
      "         434       0.80      0.27      0.40        15\n",
      "         435       0.00      0.00      0.00         1\n",
      "         436       0.00      0.00      0.00         0\n",
      "         437       0.52      0.62      0.57       440\n",
      "         438       0.00      0.00      0.00         0\n",
      "         439       0.25      0.12      0.17         8\n",
      "         440       0.00      0.00      0.00         1\n",
      "         441       0.00      0.00      0.00         0\n",
      "         442       0.55      0.55      0.55        20\n",
      "         443       0.70      0.39      0.50        18\n",
      "         444       0.57      0.57      0.57        14\n",
      "         445       0.67      0.75      0.71        16\n",
      "         446       0.00      0.00      0.00         1\n",
      "         447       0.00      0.00      0.00         0\n",
      "         448       0.12      0.08      0.10        13\n",
      "         449       0.50      1.00      0.67         2\n",
      "         450       0.00      0.00      0.00         1\n",
      "         451       0.50      0.17      0.25         6\n",
      "         452       0.00      0.00      0.00         1\n",
      "         453       1.00      0.50      0.67         2\n",
      "         454       0.61      0.65      0.63        43\n",
      "         455       0.73      0.75      0.74        32\n",
      "         456       0.00      0.00      0.00         3\n",
      "         457       0.00      0.00      0.00         2\n",
      "         458       0.00      0.00      0.00         2\n",
      "         459       1.00      0.67      0.80         3\n",
      "         460       0.50      0.19      0.27        16\n",
      "         461       0.00      0.00      0.00         0\n",
      "         462       0.00      0.00      0.00         4\n",
      "         463       0.50      0.25      0.33        12\n",
      "         464       1.00      0.40      0.57         5\n",
      "         465       0.00      0.00      0.00         0\n",
      "         466       0.00      0.00      0.00         5\n",
      "         467       0.00      0.00      0.00         0\n",
      "         468       0.56      0.57      0.57       125\n",
      "         469       0.48      0.42      0.44        48\n",
      "         470       0.00      0.00      0.00         1\n",
      "         471       0.40      0.40      0.40         5\n",
      "         472       0.00      0.00      0.00         0\n",
      "         473       0.00      0.00      0.00         0\n",
      "         474       0.50      0.50      0.50         2\n",
      "         475       0.00      0.00      0.00         2\n",
      "         476       0.00      0.00      0.00         3\n",
      "         477       0.00      0.00      0.00         1\n",
      "         478       0.00      0.00      0.00         2\n",
      "         479       1.00      0.43      0.60         7\n",
      "         480       0.00      0.00      0.00        13\n",
      "         481       0.00      0.00      0.00         0\n",
      "         482       0.00      0.00      0.00         1\n",
      "         483       0.50      0.10      0.17        10\n",
      "         484       0.00      0.00      0.00         0\n",
      "         485       1.00      0.30      0.46        10\n",
      "         486       0.00      0.00      0.00         2\n",
      "         487       0.00      0.00      0.00         1\n",
      "         488       1.00      0.33      0.50         3\n",
      "         489       0.40      0.31      0.35        13\n",
      "         490       0.60      0.18      0.27        17\n",
      "         491       0.40      0.17      0.24        12\n",
      "         492       0.00      0.00      0.00         0\n",
      "         493       0.00      0.00      0.00         0\n",
      "         494       1.00      0.12      0.22         8\n",
      "         495       0.50      0.10      0.17        10\n",
      "         496       0.00      0.00      0.00         1\n",
      "         497       1.00      0.50      0.67         2\n",
      "         498       0.00      0.00      0.00         0\n",
      "         499       0.00      0.00      0.00         2\n",
      "         500       0.50      1.00      0.67         1\n",
      "         501       0.00      0.00      0.00         0\n",
      "         502       0.64      0.27      0.38        26\n",
      "         503       0.00      0.00      0.00         1\n",
      "         504       0.00      0.00      0.00         2\n",
      "         505       1.00      0.20      0.33         5\n",
      "         506       0.77      0.75      0.76        32\n",
      "         507       0.50      0.17      0.25         6\n",
      "         508       0.00      0.00      0.00         1\n",
      "         509       0.00      0.00      0.00         0\n",
      "         510       0.29      0.18      0.22        11\n",
      "         511       0.00      0.00      0.00         0\n",
      "         512       0.25      1.00      0.40         1\n",
      "         513       0.71      0.50      0.59        24\n",
      "         514       0.00      0.00      0.00         0\n",
      "         515       0.53      0.73      0.62        11\n",
      "         516       0.00      0.00      0.00         0\n",
      "         517       0.00      0.00      0.00         0\n",
      "         518       0.00      0.00      0.00         0\n",
      "         519       0.63      0.71      0.67        17\n",
      "         520       0.00      0.00      0.00         2\n",
      "         521       0.00      0.00      0.00         0\n",
      "         522       0.00      0.00      0.00         9\n",
      "         523       0.00      0.00      0.00         5\n",
      "         524       0.73      0.89      0.80         9\n",
      "         525       0.00      0.00      0.00         0\n",
      "         526       0.00      0.00      0.00         3\n",
      "         527       1.00      0.12      0.22         8\n",
      "         528       0.00      0.00      0.00         0\n",
      "         529       0.00      0.00      0.00         0\n",
      "         530       0.83      0.45      0.59        11\n",
      "         531       1.00      0.67      0.80         3\n",
      "         532       1.00      0.20      0.33         5\n",
      "         533       0.25      0.39      0.31       303\n",
      "         534       0.00      0.00      0.00         1\n",
      "         535       0.00      0.00      0.00         0\n",
      "         536       0.00      0.00      0.00         0\n",
      "         537       0.80      0.57      0.67         7\n",
      "         538       0.00      0.00      0.00         0\n",
      "         539       0.00      0.00      0.00         3\n",
      "         540       0.00      0.00      0.00         0\n",
      "         541       1.00      1.00      1.00         1\n",
      "         542       0.00      0.00      0.00         0\n",
      "         543       0.00      0.00      0.00         1\n",
      "         544       0.67      0.33      0.44         6\n",
      "         545       0.00      0.00      0.00         3\n",
      "         546       0.75      0.84      0.79        25\n",
      "         547       0.00      0.00      0.00         0\n",
      "         548       0.70      0.88      0.78         8\n",
      "         549       1.00      0.67      0.80         3\n",
      "         550       1.00      1.00      1.00         2\n",
      "         551       0.00      0.00      0.00         0\n",
      "         552       0.00      0.00      0.00         1\n",
      "         553       0.00      0.00      0.00         5\n",
      "         554       1.00      0.33      0.50         3\n",
      "         555       0.50      0.28      0.36        18\n",
      "         556       1.00      0.33      0.50         3\n",
      "         557       0.50      0.22      0.31         9\n",
      "         558       0.00      0.00      0.00         4\n",
      "         559       0.64      0.56      0.60        25\n",
      "         560       1.00      0.60      0.75         5\n",
      "         561       0.00      0.00      0.00         2\n",
      "         562       0.00      0.00      0.00         7\n",
      "         563       1.00      0.90      0.95        29\n",
      "         564       0.83      0.83      0.83         6\n",
      "         565       0.00      0.00      0.00         4\n",
      "         566       0.00      0.00      0.00         0\n",
      "         567       0.00      0.00      0.00         4\n",
      "         568       0.00      0.00      0.00         1\n",
      "         569       0.67      1.00      0.80         2\n",
      "         570       1.00      1.00      1.00         2\n",
      "         571       0.00      0.00      0.00         0\n",
      "         572       0.79      0.58      0.67        19\n",
      "         573       0.00      0.00      0.00         1\n",
      "         574       0.00      0.00      0.00         0\n",
      "         575       0.00      0.00      0.00         1\n",
      "         576       0.00      0.00      0.00         0\n",
      "         577       0.00      0.00      0.00         0\n",
      "         578       0.00      0.00      0.00         0\n",
      "         579       0.00      0.00      0.00         0\n",
      "         580       0.00      0.00      0.00         1\n",
      "         581       0.00      0.00      0.00         0\n",
      "         582       0.00      0.00      0.00         1\n",
      "         583       0.00      0.00      0.00         2\n",
      "         584       0.00      0.00      0.00         1\n",
      "         585       0.00      0.00      0.00         1\n",
      "         586       0.00      0.00      0.00         0\n",
      "         587       0.00      0.00      0.00         0\n",
      "         588       0.00      0.00      0.00         1\n",
      "         589       0.00      0.00      0.00         4\n",
      "         590       0.00      0.00      0.00         0\n",
      "         591       0.00      0.00      0.00         0\n",
      "         592       0.00      0.00      0.00         0\n",
      "         593       0.00      0.00      0.00         3\n",
      "         594       0.00      0.00      0.00         0\n",
      "         595       0.50      0.25      0.33         4\n",
      "         596       0.00      0.00      0.00         0\n",
      "         597       0.00      0.00      0.00         0\n",
      "         598       0.00      0.00      0.00         1\n",
      "         599       0.00      0.00      0.00         0\n",
      "         600       0.00      0.00      0.00         1\n",
      "         601       1.00      1.00      1.00         1\n",
      "         602       0.00      0.00      0.00         0\n",
      "         603       0.00      0.00      0.00         0\n",
      "         604       0.00      0.00      0.00         0\n",
      "         605       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.54      0.51      0.53      7488\n",
      "   macro avg       0.28      0.18      0.20      7488\n",
      "weighted avg       0.53      0.51      0.50      7488\n",
      " samples avg       0.50      0.53      0.51      7488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec le count vectorizer ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47206940222897664\n",
      "CPU times: user 29min 22s, sys: 10 s, total: 29min 32s\n",
      "Wall time: 29min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_, X_test_ =preprocess_2.fit_transform(X_train),preprocess_2.transform(X_test)\n",
    "clf = LinearSVC(class_weight='balanced')\n",
    "\n",
    "\n",
    "chains = [ClassifierChain(clf, order='random', random_state=i) for i in range(10)]\n",
    "\n",
    "for chain in chains:\n",
    "    chain.fit(X_train_, y_train)\n",
    "    \n",
    "y_pred_chains = np.array([chain.predict(X_test_) for chain in chains])\n",
    "\n",
    "chain_f1_scores = [f1_score(y_test, y_pred_chain, average='samples') for y_pred_chain in y_pred_chains]\n",
    "\n",
    "y_pred_ensemble = y_pred_chains.mean(axis=0)\n",
    "\n",
    "y_e = y_pred_ensemble>=0.4\n",
    "\n",
    "ensemble_f1_score = f1_score(y_test,y_e, average='samples')\n",
    "\n",
    "print(ensemble_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentaire\n",
    "Nous observons un changement de performance, significatif, l'approche ClassifierChain permet de prendre en compte les lien entre différents Labels\n",
    "## 3.  D'autres modèle de Machine Learning\n",
    "### 3.1 XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.8 s, sys: 40 ms, total: 3.84 s\n",
      "Wall time: 4.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import xgboost as xgb\n",
    "\n",
    "X_train_, X_test_ =preprocess.fit_transform(X_train),preprocess.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Done !\n",
      "Fitting the model...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from xgboost import XGBClassifier\n",
    "#binary:hinge\n",
    "#Objective candidate: multi:softmax\n",
    "#Objective candidate: multi:softprob\n",
    "\n",
    "\n",
    "print(\"Preprocessing...\")\n",
    "X_train_, X_test_ =preprocess.fit_transform(X_train),preprocess.transform(X_test)\n",
    "print(\"Done !\")\n",
    "\n",
    "param = {'alpha': 0.0012761794,\n",
    " 'booster': 'gbtree',\n",
    " 'eta': 0.0328162271,\n",
    " 'gamma': 0.0009178265,\n",
    " 'grow_policy': 'lossguide',\n",
    " 'lambda': 0.9976560286,\n",
    " 'max_depth': 7,\n",
    " 'n_estimators': 14,\n",
    " 'normalize_type': None,\n",
    " 'objective': 'binary:hinge',\n",
    " 'n_jobs':-1}\n",
    " \n",
    "\n",
    "clf = OneVsRestClassifier(XGBClassifier(**param))\n",
    "\n",
    "print(\"Fitting the model...\")\n",
    "clf.fit(X_train_,y_train)\n",
    "print(\"Done !\")\n",
    "print(\"Prediction..\")\n",
    "pred = clf.predict(X_test_)\n",
    "print(\"Done !\")\n",
    "f1 = f1_score(y_test,pred, average='samples')\n",
    "print(\"f1_score samples :\",f1 )\n",
    "                                                                         \n",
    "                                                                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from xgboost import XGBClassifier\n",
    "#binary:hinge\n",
    "#Objective candidate: multi:softmax\n",
    "#Objective candidate: multi:softprob\n",
    "\n",
    "\n",
    "print(\"Preprocessing...\")\n",
    "X_train_, X_test_ =preprocess.fit_transform(X_train),preprocess.transform(X_test)\n",
    "print(\"Done !\")\n",
    "\n",
    "param = {'eta': 0.1,\n",
    " 'max_depth': 7,\n",
    " 'n_estimators': 7,\n",
    " 'objective': 'binary:hinge',\n",
    " 'n_jobs':-1}\n",
    " \n",
    "\n",
    "clf = OneVsRestClassifier(XGBClassifier(**param))\n",
    "\n",
    "print(\"Fitting the model...\")\n",
    "clf.fit(X_train_,y_train)\n",
    "print(\"Done !\")\n",
    "print(\"Prediction..\")\n",
    "pred = clf.predict(X_test_)\n",
    "print(\"Done !\")\n",
    "f1 = f1_score(y_test,pred, average='samples')\n",
    "print(\"f1_score samples :\",f1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 Classifier Chain and Regularised gradient boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param = {'eta': 0.1,\n",
    " 'max_depth': 7,\n",
    " 'n_estimators': 7,\n",
    " 'objective': 'binary:hinge',\n",
    " 'n_jobs':-1}\n",
    " \n",
    "\n",
    "clf = XGBClassifier(**param)\n",
    "\n",
    "chains = [ClassifierChain(clf, order='random', random_state=i) for i in range(10)]\n",
    "\n",
    "for chain in chains:\n",
    "    chain.fit(X_train_, y_train)\n",
    "    \n",
    "y_pred_chains = np.array([chain.predict(X_test_) for chain in chains])\n",
    "\n",
    "chain_f1_scores = [f1_score(y_test, y_pred_chain, average='samples') for y_pred_chain in y_pred_chains]\n",
    "\n",
    "y_pred_ensemble = y_pred_chains.mean(axis=0)\n",
    "\n",
    "thresholds = [0.01,0.04,0.06,0.08,0.1,0.12,0.14,0.16,0.2,0.25,0.3,0.35,0.4,0.5,0.6,0.7]\n",
    "for val in thresholds:\n",
    "    print(\"For threshold: \", val)\n",
    "    pred=y_pred_ensemble.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "  \n",
    "    precision = precision_score(y_test, pred, average='samples')\n",
    "    recall = recall_score(y_test, pred, average='samples')\n",
    "    f1 = f1_score(y_test, pred, average='samples')\n",
    "   \n",
    "    print(\"Samples-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For threshold:  0.01\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.04\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.06\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.08\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.1\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.12\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.14\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.16\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.2\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.25\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.3\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.35\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.4\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.5\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6174, Recall: 0.6932, F1-measure: 0.6358\n",
      "For threshold:  0.6\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6097, Recall: 0.6450, F1-measure: 0.6137\n",
      "For threshold:  0.7\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6097, Recall: 0.6450, F1-measure: 0.6137\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding,SpatialDropout1D, Bidirectional, Flatten, LSTM, Conv1D, Conv2D, MaxPooling1D, Dropout, Activation,GlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_ =preprocess.fit_transform(X_train),preprocess.transform(X_test)\n",
    "X_train_= np.array(X_train_.todense())\n",
    "##\n",
    "X_test_= np.array(X_test_.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48min 9s, sys: 21min 35s, total: 1h 9min 44s\n",
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=1000)\n",
    "X_train_ = svd.fit_transform(X_train_)\n",
    "X_test_ = svd.transform(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = np.reshape(X_train_, (X_train_.shape[0], 1, X_train_.shape[1]))\n",
    "X_test_ = np.reshape(X_test_, (X_test_.shape[0], 1, X_test_.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21059 samples, validate on 5265 samples\n",
      "Epoch 1/5\n",
      "21059/21059 [==============================] - 11s 502us/step - loss: 0.0206 - categorical_accuracy: 0.5656 - val_loss: 0.0138 - val_categorical_accuracy: 0.5985\n",
      "Epoch 2/5\n",
      "21059/21059 [==============================] - 8s 381us/step - loss: 0.0150 - categorical_accuracy: 0.6196 - val_loss: 0.0125 - val_categorical_accuracy: 0.6370\n",
      "Epoch 3/5\n",
      "21059/21059 [==============================] - 9s 405us/step - loss: 0.0136 - categorical_accuracy: 0.6534 - val_loss: 0.0120 - val_categorical_accuracy: 0.6433\n",
      "Epoch 4/5\n",
      "21059/21059 [==============================] - 9s 427us/step - loss: 0.0127 - categorical_accuracy: 0.6658 - val_loss: 0.0117 - val_categorical_accuracy: 0.6473\n",
      "Epoch 5/5\n",
      "21059/21059 [==============================] - 9s 405us/step - loss: 0.0121 - categorical_accuracy: 0.6733 - val_loss: 0.0116 - val_categorical_accuracy: 0.6422\n",
      "6580/6580 [==============================] - 1s 111us/step\n",
      "loss :  0.012502517492869887\n",
      "categorical accuracy:  0.6524316072463989\n",
      "####################################\n",
      "For threshold:  0.01\n",
      "Samples-average quality numbers\n",
      "Precision: 0.2997, Recall: 0.9150, F1-measure: 0.4039\n",
      "For threshold:  0.04\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5410, Recall: 0.8305, F1-measure: 0.6148\n",
      "For threshold:  0.06\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5972, Recall: 0.7972, F1-measure: 0.6486\n",
      "For threshold:  0.08\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6322, Recall: 0.7724, F1-measure: 0.6637\n",
      "For threshold:  0.1\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6554, Recall: 0.7514, F1-measure: 0.6703\n",
      "For threshold:  0.12\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6666, Recall: 0.7312, F1-measure: 0.6687\n",
      "For threshold:  0.14\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6729, Recall: 0.7152, F1-measure: 0.6674\n",
      "For threshold:  0.16\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6697, Recall: 0.6977, F1-measure: 0.6603\n",
      "For threshold:  0.2\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6558, Recall: 0.6665, F1-measure: 0.6450\n",
      "For threshold:  0.25\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6360, Recall: 0.6377, F1-measure: 0.6267\n",
      "For threshold:  0.3\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6206, Recall: 0.6139, F1-measure: 0.6102\n",
      "For threshold:  0.35\n",
      "Samples-average quality numbers\n",
      "Precision: 0.6040, Recall: 0.5941, F1-measure: 0.5936\n",
      "For threshold:  0.4\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5868, Recall: 0.5746, F1-measure: 0.5768\n",
      "For threshold:  0.5\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5494, Recall: 0.5371, F1-measure: 0.5408\n",
      "For threshold:  0.6\n",
      "Samples-average quality numbers\n",
      "Precision: 0.5024, Recall: 0.4945, F1-measure: 0.4969\n",
      "For threshold:  0.7\n",
      "Samples-average quality numbers\n",
      "Precision: 0.4304, Recall: 0.4254, F1-measure: 0.4269\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(X_train_, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2)\n",
    "\n",
    "score,cat_acc = model.evaluate(X_test_,y_test)\n",
    "\n",
    "y_pred = model.predict(X_test_)\n",
    "\n",
    "print('loss : ', score)\n",
    "print('categorical accuracy: ',cat_acc)\n",
    "\n",
    "print('####################################')\n",
    "\n",
    "thresholds = [0.01,0.04,0.06,0.08,0.1,0.12,0.14,0.16,0.2,0.25,0.3,0.35,0.4,0.5,0.6,0.7]\n",
    "for val in thresholds:\n",
    "    print(\"For threshold: \", val)\n",
    "    pred=y_pred.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "  \n",
    "    precision = precision_score(y_test, pred, average='samples')\n",
    "    recall = recall_score(y_test, pred, average='samples')\n",
    "    f1 = f1_score(y_test, pred, average='samples')\n",
    "   \n",
    "    print(\"Samples-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 200)               960800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 273)               54873     \n",
      "=================================================================\n",
      "Total params: 1,015,673\n",
      "Trainable params: 1,015,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commentaire : \n",
    "En ajustant le seuil à 0.1, on obtient le meilleur résultat: \n",
    "\n",
    "**Samples-average quality numbers**\n",
    "- Precision: 0.6554, \n",
    "-  Recall: 0.7514, \n",
    "- F1-measure: 0.6703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 nbSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbsvm import NBSVMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_train_, X_test_ =preprocess.fit_transform(X_train),preprocess.transform(X_test)\n",
    "X_train_= np.array(X_train_.todense())\n",
    "##\n",
    "X_test_= np.array(X_test_.todense())\n",
    "\n",
    "svd = TruncatedSVD(n_components=300)\n",
    "X_train_ = svd.fit_transform(X_train_)\n",
    "X_test_ = svd.transform(X_test_)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_ = scaler.fit_transform(X_train_)\n",
    "X_test_ = scaler.fit_transform(X_test_)\n",
    "\n",
    "clf = OneVsRestClassifier(NBSVMClassifier(class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### prédiction \n",
    "clf.fit(X_train_,y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test_)\n",
    "f1 = f1_score(y_test , y_pred,average='samples')\n",
    "print('f1_score samples : ',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 K_train : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: text classification\n",
      "language: fr\n",
      "Word Counts: 21168\n",
      "Nrows: 26324\n",
      "26324 train sequences\n",
      "train sequence lengths:\n",
      "\tmean : 12\n",
      "\t95percentile : 39\n",
      "\t99percentile : 83\n",
      "x_train shape: (26324,350)\n",
      "y_train shape: (26324, 273)\n",
      "Is Multi-Label? True\n",
      "6580 test sequences\n",
      "test sequence lengths:\n",
      "\tmean : 11\n",
      "\t95percentile : 37\n",
      "\t99percentile : 70\n",
      "x_test shape: (6580,350)\n",
      "y_test shape: (6580, 273)\n"
     ]
    }
   ],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "encoder_TEF_ID = joblib.load('data_split/TEF_ID_encodeur.sav')\n",
    "\n",
    "features = ['ETAT_PATIENT','DESCRIPTION_INCIDENT']\n",
    "train_list = [elt[0] for elt in X_train[features].values.tolist()]\n",
    "test_list =  [elt[0] for elt in X_test[features].values.tolist()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trn, val, preproc = text.texts_from_array(x_train=train_list, y_train=y_train,\n",
    "                                          x_test=test_list, y_test=y_test,\n",
    "                                          class_names=encoder_TEF_ID.classes_.tolist(),\n",
    "                                          preprocess_mode='standard',maxlen=350)\n",
    "\n",
    "#t = text.Transformer(MODEL_NAME, maxlen=256)\n",
    "#trn = t.preprocess_train(train_list, y_train)\n",
    "#val = t.preprocess_test(test_list, y_test)\n",
    "#model = t.get_classifier('nbsvm', multilabel=True, class_names = encoder_TEF_ID.transform(encoder_TEF_ID.classes_))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? True\n",
      "compiling word ID features...\n",
      "maxlen is 350\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('nbsvm', train_data=trn, preproc=preproc,multilabel =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class f1_Evaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            val=0.5\n",
    "            y_pred[y_pred>=val]=1\n",
    "            y_pred[y_pred<val]=0\n",
    "            score = f1_score(self.y_val, y_pred,average='samples')\n",
    "            print(\"\\n f1 samples - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "            \n",
    "f1 = f1_Evaluation(validation_data=val, interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "Train on 26324 samples, validate on 6580 samples\n",
      "Epoch 1/4\n",
      "26270/26324 [============================>.] - ETA: 0s - loss: 0.6263 - accuracy: 0.6471\n",
      " f1 samples - epoch: 1 - score: 0.014942 \n",
      "\n",
      "26324/26324 [==============================] - 39s 1ms/sample - loss: 0.6260 - accuracy: 0.6475 - val_loss: 0.4845 - val_accuracy: 0.9272\n",
      "Epoch 2/4\n",
      "26290/26324 [============================>.] - ETA: 0s - loss: 0.2538 - accuracy: 0.9487\n",
      " f1 samples - epoch: 2 - score: 0.348176 \n",
      "\n",
      "26324/26324 [==============================] - 45s 2ms/sample - loss: 0.2537 - accuracy: 0.9487 - val_loss: 0.0694 - val_accuracy: 0.9951\n",
      "Epoch 3/4\n",
      "26290/26324 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9947\n",
      " f1 samples - epoch: 3 - score: 0.349797 \n",
      "\n",
      "26324/26324 [==============================] - 42s 2ms/sample - loss: 0.0570 - accuracy: 0.9947 - val_loss: 0.0276 - val_accuracy: 0.9951\n",
      "Epoch 4/4\n",
      "26290/26324 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9950\n",
      " f1 samples - epoch: 4 - score: 0.345137 \n",
      "\n",
      "26324/26324 [==============================] - 41s 2ms/sample - loss: 0.0355 - accuracy: 0.9950 - val_loss: 0.0242 - val_accuracy: 0.9951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f70181a5210>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=10)\n",
    "learner.lr_plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion : \n",
    "\n",
    "Les différents tests que nous avons menés nous permettent de conclure :\n",
    "- Le SVM + TFIDF reste un modèle qui nous propose une baseline solide avec une facilité de mise en oeuvre et déploiement.\n",
    "- Le XGboost et le LSTM permettent d'améliorer légerement les performance (0.65 et respectivement 0.67). D'autant plus que ces modèle possède de nombreux hyperparamètres à finetuner. Gràce à la librairie Optuna, nous allons le faire dans la suite de notre travail.\n",
    "- Le meilleur résultat est obtenu en utilisant ClassifierChain, cela signifie qu'l existe des relations entre nos différents Label. En appliquant un mapping de regroupement, les autres modèle devrait pouvoir concurencer ce modèle. Nous testerons également cette hypothèse dans la suite.\n",
    "\n",
    "Notre travail d'exploration des modèles nous a permis d'augmenter significativement nos performances. Le premier modèle que nous avions fait (actuellement dans l'application) avait un score f1-sample de 0.59, notre meilleur modèle est possède aujourd'hui un f1 sample de 0.68. C'est encouragenat pour la suite car nous avons encore beaucoup de finetuning à réaliser.\n",
    "\n",
    "Nous avons également pu comprendre que l'encodage par colonne était un vecteur pour mieux capturer l'information et donc augmenter les performances. De même que la réalisation d'une SVD s'accompagne souvent d'une baisse de performances.\n",
    "\n",
    "Enfin, nous avons remarqué que les embedding préentrainé fonctionné mal sur notre problème en comparaison de la tfidf.\n",
    "\n",
    "En dehors de ce Notebook, nous avons essayé l'ensemble des modèles accecible en CPu de la librairie ktrain, malheuresement ils ne nous permette pas d'augmenter nos performances de manière significatives : https://github.com/amaiya/ktrain/tree/master/examples#textclass\n",
    "\n",
    "Les travaux à réaliser pour la suite sont : \n",
    "- Finetuner XgBoost (https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst)\n",
    "- Finetuner le LSTM\n",
    "- Créer des LSTM avec un encodage séparé pour chaqune des colonnes :\n",
    "    - https://keras.io/examples/nlp/text_classification_from_scratch/\n",
    "- Tester de nouvelles architectures (Gru, biGru, BiLSTM etc.)\n",
    "- Essayer de rajouter une couche d'attention sur nos modèles de deep Learning car dans la litterature, elle est souvent synonyme d'une augmentation des performances\n",
    "- Un travail sur les Loss est également nécessaire car nous travaillons avec un corpus très désequilibré : https://www.dlology.com/blog/multi-class-classification-with-focal-loss-for-imbalanced-datasets/\n",
    "- Enfin, nous allons essayer les méthodes développées dans ces deux papiers sur la classification de texte (Extreme classification basée sur l'attention) : \n",
    "    - https://github.com/iliaschalkidis/lmtc-eurlex57k\n",
    "    - https://github.com/yourh/AttentionXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGS-env",
   "language": "python",
   "name": "dgs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
